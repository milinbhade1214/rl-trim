{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c95f335f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:14.589629Z",
     "start_time": "2024-06-11T04:34:14.581836Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "model_used = \"base\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f1d798",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "430e33e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:14.594648Z",
     "start_time": "2024-06-11T04:34:14.591877Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0044f05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:14.602875Z",
     "start_time": "2024-06-11T04:34:14.596480Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_template = True if model_used=='chat' else False\n",
    "use_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "122cebd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:14.607554Z",
     "start_time": "2024-06-11T04:34:14.604766Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "hf_llama_path = \"/data/home/milinbhade/LLaMa/hf_llama/\"\n",
    "hf_llama_chat_path = \"/data/home/milinbhade/LLaMa/hf_llama_chat/\"\n",
    "\n",
    "alpacha_dataset_path = \"/data/home/milinbhade/LLaMa/pretrain_data/alpaca/alpaca-cleaned-dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ffc0e2",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e24e0a0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:17.540746Z",
     "start_time": "2024-06-11T04:34:14.610422Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import fnmatch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import logging\n",
    "\n",
    "import json\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ba58004",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:17.610843Z",
     "start_time": "2024-06-11T04:34:17.543585Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6655d385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:17.705050Z",
     "start_time": "2024-06-11T04:34:17.612967Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f35d0a06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:17.881958Z",
     "start_time": "2024-06-11T04:34:17.707191Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer, AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fbc136",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c854fed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:17.892318Z",
     "start_time": "2024-06-11T04:34:17.884039Z"
    },
    "code_folding": [
     0,
     1,
     5,
     28
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "class TokenizerWrapper:\n",
    "    def __init__(self, input_ids):\n",
    "        self.input_ids = input_ids\n",
    "\n",
    "# Load and process wikitext2 dataset\n",
    "def get_wikitext2(nsamples, seed, seqlen, tokenizer):\n",
    "    # Load train and test datasets\n",
    "    traindata = load_dataset('wikitext', 'wikitext-2-raw-v1', split='train')\n",
    "    valdata = load_dataset('wikitext', 'wikitext-2-raw-v1', split='validation')\n",
    "    testdata = load_dataset('wikitext', 'wikitext-2-raw-v1', split='test')\n",
    "\n",
    "    # Encode datasets\n",
    "    trainenc = tokenizer(\" \".join(traindata['text']), return_tensors='pt')\n",
    "    valenc = tokenizer(\"\\n\\n\".join(valdata['text']), return_tensors='pt')\n",
    "    testenc = tokenizer(\"\\n\\n\".join(testdata['text']), return_tensors='pt')\n",
    "\n",
    "    # Generate samples from training set\n",
    "    random.seed(seed)\n",
    "    trainloader = []\n",
    "    for _ in range(nsamples):\n",
    "        i = random.randint(0, trainenc.input_ids.shape[1] - seqlen - 1)\n",
    "        j = i + seqlen\n",
    "        inp = trainenc.input_ids[:, i:j]\n",
    "        tar = inp.clone()\n",
    "        tar[:, :-1] = -100\n",
    "        trainloader.append((inp, tar))\n",
    "    return trainloader, valenc, testenc\n",
    "\n",
    "def get_loaders(name, nsamples=128, seed=0, seqlen=2048, tokenizer=None):\n",
    "    if 'wikitext2' in name:\n",
    "        return get_wikitext2(nsamples, seed, seqlen, tokenizer)\n",
    "    if \"c4\" in name:\n",
    "        return get_c4(nsamples, seed, seqlen, tokenizer)\n",
    "    if \"bookcorpus\" in name:\n",
    "        return get_book_corpus(nsamples, seed, seqlen, tokenizer)\n",
    "    if \"ptb\" in name:\n",
    "        return get_ptb(nsamples, seed, seqlen, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6338db",
   "metadata": {},
   "source": [
    "## Eval PPL on wikitext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a07075e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:17.911162Z",
     "start_time": "2024-06-11T04:34:17.894443Z"
    },
    "code_folding": [
     0,
     19
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Function to evaluate perplexity (ppl) on a specified model and tokenizer\n",
    "def eval_ppl(model, tokenizer, device=torch.device(\"cuda:0\")):\n",
    "    # Set dataset\n",
    "    dataset = \"wikitext2\"\n",
    "\n",
    "    # Print status\n",
    "    print(f\"evaluating on {dataset}\")\n",
    "\n",
    "    # Get the test loader\n",
    "    _, _, testloader = get_loaders(\n",
    "        dataset, seed=0, seqlen=model.seqlen, tokenizer=tokenizer \n",
    "    )\n",
    "\n",
    "    # Evaluate ppl in no grad context to avoid updating the model\n",
    "    with torch.no_grad():\n",
    "        ppl_test = eval_ppl_wikitext(model, testloader, 1, device)\n",
    "    return ppl_test \n",
    "\n",
    "# Function to evaluate perplexity (ppl) specifically on the wikitext dataset\n",
    "def eval_ppl_wikitext_train(model, trainloader, bs=1, device=None):\n",
    "    # Get input IDs\n",
    "    # testenc = testenc.input_ids\n",
    "\n",
    "    # Calculate number of samples\n",
    "    # nsamples = testenc.numel() // model.seqlen\n",
    "    nsamples = len(trainloader)\n",
    "\n",
    "    # List to store negative log likelihoods\n",
    "    nlls = []\n",
    "    print(f\"nsamples {nsamples}\")\n",
    "\n",
    "    # Loop through each batch\n",
    "    for i in range(0,nsamples,bs):\n",
    "        if i % 50 == 0:\n",
    "            print(f\"sample {i}\")\n",
    "\n",
    "        # Calculate end index\n",
    "        j = min(i+bs, nsamples)\n",
    "\n",
    "        # Prepare inputs and move to device\n",
    "        # inputs = testenc[:,(i * model.seqlen):(j * model.seqlen)].to(device)\n",
    "        inputs = trainloader[i][0].to(device)\n",
    "        inputs = inputs.reshape(j-i, model.seqlen)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        lm_logits = model(inputs).logits\n",
    "\n",
    "        # Shift logits and labels for next token prediction\n",
    "        shift_logits = lm_logits[:, :-1, :].contiguous()\n",
    "        shift_labels = inputs[:, 1:]\n",
    "\n",
    "        # Compute loss\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(shift_logits.reshape(-1, shift_logits.size(-1)), shift_labels.reshape(-1))\n",
    "\n",
    "        # Calculate negative log likelihood\n",
    "        neg_log_likelihood = loss.float() * model.seqlen * (j-i)\n",
    "\n",
    "        # Append to list of negative log likelihoods\n",
    "        nlls.append(neg_log_likelihood)\n",
    "\n",
    "    # Compute perplexity\n",
    "    ppl = torch.exp(torch.stack(nlls).sum() / (nsamples * model.seqlen))\n",
    "\n",
    "    # Empty CUDA cache to save memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return ppl.item()\n",
    "\n",
    "# Function to evaluate perplexity (ppl) specifically on the wikitext dataset\n",
    "def eval_ppl_wikitext(model, testenc, bs=1, device=None):\n",
    "    # Get input IDs\n",
    "    testenc = testenc.input_ids\n",
    "\n",
    "    # Calculate number of samples\n",
    "    # nsamples = testenc.numel() // model.seqlen\n",
    "    nsamples = 25\n",
    "\n",
    "    # List to store negative log likelihoods\n",
    "    nlls = []\n",
    "    print(f\"nsamples {nsamples}\")\n",
    "\n",
    "    # Loop through each batch\n",
    "    for i in tqdm(range(0,nsamples,bs), desc =\"WikiText Validation: \"):\n",
    "#         if i % 5 == 0:\n",
    "#             print(f\"sample {i}\")\n",
    "\n",
    "        # Calculate end index\n",
    "        j = min(i+bs, nsamples)\n",
    "\n",
    "        # Prepare inputs and move to device\n",
    "        inputs = testenc[:,(i * model.seqlen):(j * model.seqlen)].to(device)\n",
    "        inputs = inputs.reshape(j-i, model.seqlen)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        print(inputs.shape)\n",
    "        lm_logits = model(inputs).logits\n",
    "\n",
    "        # Shift logits and labels for next token prediction\n",
    "        shift_logits = lm_logits[:, :-1, :].contiguous()\n",
    "        shift_labels = inputs[:, 1:]\n",
    "\n",
    "        # Compute loss\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(shift_logits.reshape(-1, shift_logits.size(-1)), shift_labels.reshape(-1))\n",
    "\n",
    "        # Calculate negative log likelihood\n",
    "        neg_log_likelihood = loss.float() * model.seqlen * (j-i)\n",
    "\n",
    "        # Append to list of negative log likelihoods\n",
    "        nlls.append(neg_log_likelihood)\n",
    "\n",
    "    # Compute perplexity\n",
    "    ppl = torch.exp(torch.stack(nlls).sum() / (nsamples * model.seqlen))\n",
    "\n",
    "    # Empty CUDA cache to save memory\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"PPL: \", ppl.item())\n",
    "\n",
    "    return ppl.item()\n",
    "\n",
    "def eval_zero_shot(model_name, model, tokenizer, saved_dir, task_list=[\"boolq\",\"rte\",\"hellaswag\",\"winogrande\",\"arc_challenge\",\"arc_easy\",\"openbookqa\"], \n",
    "        num_fewshot=0, use_accelerate=False, add_special_tokens=False):\n",
    "    from lm_eval import tasks, evaluator \n",
    "    def pattern_match(patterns, source_list):\n",
    "        task_names = set()\n",
    "        for pattern in patterns:\n",
    "            for matching in fnmatch.filter(source_list, pattern):\n",
    "                task_names.add(matching)\n",
    "        return list(task_names)\n",
    "    \n",
    "    print(\"Model passed to evaluation: \", model)\n",
    "    task_names = pattern_match(task_list, tasks.get_task_dict([\"boolq\",\"rte\",\"hellaswag\",\"winogrande\",\"arc_challenge\",\"arc_easy\",\"openbookqa\"]).keys())\n",
    "    model_args = f\"pretrained={saved_dir}\"\n",
    "    limit = 100\n",
    "    if \"70b\" in model_name or \"65b\" in model_name:\n",
    "        limit = 2000\n",
    "    if use_accelerate:\n",
    "        model_args = f\"pretrained={model_path}, cache_dir={model_path},use_accelerate=True\"\n",
    "    results = evaluator.simple_evaluate(\n",
    "        model=\"huggingface\",\n",
    "        model_args=model_args,    ## This is responsible for taking the pruned model\n",
    "        tasks=task_names,\n",
    "        num_fewshot=num_fewshot,\n",
    "        # pretrained_model=model,\n",
    "        batch_size=None,\n",
    "        device=None,\n",
    "        limit=limit,\n",
    "    )\n",
    "\n",
    "    return results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d5a03c",
   "metadata": {},
   "source": [
    "## Pruning Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0141b850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:17.971991Z",
     "start_time": "2024-06-11T04:34:17.913235Z"
    },
    "code_folding": [
     0,
     2,
     6,
     28,
     64,
     99,
     122,
     145,
     173
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def find_pruneable_heads_and_indices(\n",
    "    heads, n_heads, head_size, already_pruned_heads = set()\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds the heads and their indices taking `already_pruned_heads` into account.\n",
    "\n",
    "    Args:\n",
    "        heads (`List[int]`): List of the indices of heads to prune.\n",
    "        n_heads (`int`): The number of heads in the model.\n",
    "        head_size (`int`): The size of each head.\n",
    "        already_pruned_heads (`Set[int]`): A set of already pruned heads.\n",
    "\n",
    "    Returns:\n",
    "        `Tuple[Set[int], torch.LongTensor]`: A tuple with the indices of heads to prune taking `already_pruned_heads`\n",
    "        into account and the indices of rows/columns to keep in the layer weight.\n",
    "    \"\"\"\n",
    "    mask = torch.ones(n_heads, head_size)\n",
    "    heads = set(heads) - already_pruned_heads  # Convert to set and remove already pruned heads\n",
    "    for head in heads:\n",
    "        # Compute how many pruned heads are before the head and move the index accordingly\n",
    "        head = head - sum(1 if h < head else 0 for h in already_pruned_heads)\n",
    "        mask[head] = 0\n",
    "    mask = mask.view(-1).contiguous().eq(1)\n",
    "    index: torch.LongTensor = torch.arange(len(mask))[mask].long()\n",
    "    return heads, index\n",
    "\n",
    "\n",
    "\n",
    "def prune_linear_by_mask(layer: nn.Linear, index: torch.LongTensor, dim: int = 0) -> nn.Linear:\n",
    "    \"\"\"\n",
    "    Masking based Pruning of linear layer, just make entries zeros\n",
    "    Not change size of the matrices\n",
    "\n",
    "    Used to remove heads.\n",
    "\n",
    "    Args:\n",
    "        layer (`torch.nn.Linear`): The layer to prune.\n",
    "        index (`torch.LongTensor`): The indices to keep in the layer.\n",
    "        dim (`int`, *optional*, defaults to 0): The dimension on which to keep the indices.\n",
    "\n",
    "    Returns:\n",
    "        `torch.nn.Linear`: The pruned layer as a new layer with `requires_grad=True`.\n",
    "    \"\"\"\n",
    "    index = index.to(layer.weight.device)\n",
    "    mask = torch.zeros_like(layer.weight)\n",
    "    if dim == 0:\n",
    "        mask[index] = 1\n",
    "    else:\n",
    "        mask[:, index] = 1\n",
    "\n",
    "    layer.weight.data *= mask\n",
    "    layer.weight.requires_grad = True\n",
    "\n",
    "    if layer.bias is not None:\n",
    "        bias_mask = torch.zeros_like(layer.bias)\n",
    "        if dim == 0:\n",
    "            bias_mask[index] = 1\n",
    "        else:\n",
    "            bias_mask = 1\n",
    "        layer.bias.data *= bias_mask\n",
    "        layer.bias.requires_grad = True\n",
    "\n",
    "    return layer\n",
    "\n",
    "def prune_linear_layer(layer: nn.Linear, index: torch.LongTensor, dim: int = 0) -> nn.Linear:\n",
    "    \"\"\"\n",
    "    Prune a linear layer to keep only entries in index.\n",
    "\n",
    "    Used to remove heads.\n",
    "\n",
    "    Args:\n",
    "        layer (`torch.nn.Linear`): The layer to prune.\n",
    "        index (`torch.LongTensor`): The indices to keep in the layer.\n",
    "        dim (`int`, *optional*, defaults to 0): The dimension on which to keep the indices.\n",
    "\n",
    "    Returns:\n",
    "        `torch.nn.Linear`: The pruned layer as a new layer with `requires_grad=True`.\n",
    "    \"\"\"\n",
    "    index = index.to(layer.weight.device)\n",
    "    assert max(index) < layer.weight.size(dim), \"Index out of bounds\"\n",
    "    W = layer.weight.index_select(dim, index).clone().detach()\n",
    "    if layer.bias is not None:\n",
    "        if dim == 1:\n",
    "            b = layer.bias.clone().detach()\n",
    "        else:\n",
    "            b = layer.bias[index].clone().detach()\n",
    "    new_size = list(layer.weight.size())\n",
    "    new_size[dim] = len(index)\n",
    "    new_layer = nn.Linear(new_size[1], new_size[0], bias=layer.bias is not None).to(layer.weight.device)\n",
    "    new_layer.weight.requires_grad = False\n",
    "    new_layer.weight.copy_(W.contiguous())\n",
    "    new_layer.weight.requires_grad = True\n",
    "    if layer.bias is not None:\n",
    "        new_layer.bias.requires_grad = False\n",
    "        new_layer.bias.copy_(b.contiguous())\n",
    "        new_layer.bias.requires_grad = True\n",
    "    return new_layer\n",
    "\n",
    "\n",
    "def get_heads_to_prune(model, importance_func, threshold):\n",
    "    import numpy as np\n",
    "    # Initialize dictionary to hold layers and heads to prune\n",
    "    heads_to_prune = {}\n",
    "\n",
    "    # Loop over each layer in the model\n",
    "    for i, layer in enumerate(model.model.layers):\n",
    "        # Calculate the importance of the weights of each head in the layer using the provided function\n",
    "        weights = layer.self_attn.q_proj.weight + layer.self_attn.k_proj.weight + layer.self_attn.v_proj.weight\n",
    "        head_importances = importance_func(weights.view(layer.self_attn.num_heads, -1), target=torch.zeros_like(weights.view(layer.self_attn.num_heads, -1)), reduction='none').sum(dim=-1)\n",
    "        head_importances = head_importances.detach().cpu().numpy()\n",
    "        \n",
    "        d_prime = int(np.ceil(layer.self_attn.num_heads * threshold))\n",
    "        print(d_prime)\n",
    "        sorted_idx = np.argsort(head_importances)\n",
    "        preserve_idx = sorted_idx[d_prime:]\n",
    "        prune_indices = sorted_idx[:d_prime]\n",
    "\n",
    "        # Add the layer and the heads to prune to the dictionary\n",
    "        heads_to_prune[i] = prune_indices\n",
    "\n",
    "    return heads_to_prune\n",
    "\n",
    "def get_heads_to_prune_layer(model, importance_func, threshold, layer_index):\n",
    "    import numpy as np\n",
    "    # Initialize dictionary to hold layers and heads to prune\n",
    "    heads_to_prune = {}\n",
    "\n",
    "    layers = model.model.layers\n",
    "    layer = layers[layer_index]\n",
    "    # Calculate the importance of the weights of each head in the layer using the provided function\n",
    "    weights = layer.self_attn.q_proj.weight + layer.self_attn.k_proj.weight + layer.self_attn.v_proj.weight\n",
    "    head_importances = importance_func(weights.view(layer.self_attn.num_heads, -1), target=torch.zeros_like(weights.view(layer.self_attn.num_heads, -1)), reduction='none').sum(dim=-1)\n",
    "    head_importances = head_importances.detach().cpu().numpy()\n",
    "    \n",
    "    d_prime = int(np.ceil(layer.self_attn.num_heads * threshold))\n",
    "    print(d_prime)\n",
    "    sorted_idx = np.argsort(head_importances)\n",
    "    preserve_idx = sorted_idx[d_prime:]\n",
    "    prune_indices = sorted_idx[:d_prime]\n",
    "\n",
    "    # Add the layer and the heads to prune to the dictionary\n",
    "\n",
    "    return prune_indices\n",
    "\n",
    "\n",
    "def get_inter_indices_to_keep(model, layer, importance_func, threshold):\n",
    "    # Type : LlamaMLP\n",
    "    if isinstance(layer, int):\n",
    "        inter_layer = list(model.modules())[layer]\n",
    "    else:\n",
    "        inter_layer = layer\n",
    "    print(type(inter_layer))\n",
    "    assert isinstance(inter_layer, LlamaMLP)\n",
    "    inter_dim = inter_layer.intermediate_size\n",
    "    d_prime = int(np.ceil(inter_dim *(1 - threshold)))\n",
    "    print(d_prime)\n",
    "                  \n",
    "    \n",
    "    gate_weights = inter_layer.gate_proj.weight.data.cpu().numpy() \n",
    "    up_weights = inter_layer.up_proj.weight.data.cpu().numpy() \n",
    "    down_weights= inter_layer.down_proj.weight.data.cpu().numpy()\n",
    "    down_weights = np.transpose(down_weights)\n",
    "    \n",
    "    ## Add importance function here \n",
    "    \n",
    "    importance = torch.from_numpy(np.abs(gate_weights) + np.abs(up_weights) + np.abs(down_weights)).sum(dim=1)\n",
    "    print(len(importance))\n",
    "    sorted_idx = np.argsort(-importance)\n",
    "    preserve_idx = sorted_idx[:d_prime]\n",
    "    print(preserve_idx)\n",
    "    prune_idx = sorted_idx[d_prime:]\n",
    "    return preserve_idx, importance\n",
    "\n",
    "def find_layers(module, layers=[nn.Linear], name=''):\n",
    "    \"\"\"\n",
    "    Recursively find the layers of a certain type in a module.\n",
    "\n",
    "    Args:\n",
    "        module (nn.Module): PyTorch module.\n",
    "        layers (list): List of layer types to find.\n",
    "        name (str): Name of the module.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of layers of the given type(s) within the module.\n",
    "    \"\"\"\n",
    "    if type(module) in layers:\n",
    "        return {name: module}\n",
    "    res = {}\n",
    "    for name1, child in module.named_children():\n",
    "        res.update(find_layers(\n",
    "            child, layers=layers, name=name + '.' + name1 if name != '' else name1\n",
    "        ))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae894f12",
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "269e710f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:17.990755Z",
     "start_time": "2024-06-11T04:34:17.983243Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "long_input = \"\"\"Provide a concise summary of the below passage.\n",
    "\n",
    "Hannah Arendt was one of the seminal political thinkers of the twentieth century. The power and originality of her thinking was evident in works such as The Origins of Totalitarianism, The Human Condition, On Revolution and The Life of the Mind. In these works and in numerous essays she grappled with the most crucial political events of her time, trying to grasp their meaning and historical import, and showing how they affected our categories of moral and political judgment. What was required, in her view, was a new framework that could enable us to come to terms with the twin horrors of the twentieth century, Nazism and Stalinism. She provided such framework in her book on totalitarianism, and went on to develop a new set of philosophical categories that could illuminate the human condition and provide a fresh perspective on the nature of political life.\n",
    "\n",
    "Although some of her works now belong to the classics of the Western tradition of political thought, she has always remained difficult to classify. Her political philosophy cannot be characterized in terms of the traditional categories of conservatism, liberalism, and socialism. Nor can her thinking be assimilated to the recent revival of communitarian political thought, to be found, for example, in the writings of A. MacIntyre, M. Sandel, C. Taylor and M. Walzer. Her name has been invoked by a number of critics of the liberal tradition, on the grounds that she presented a vision of politics that stood in opposition some key liberal principles. There are many strands of Arendt’s thought that could justify such a claim, in particular, her critique of representative democracy, her stress on civic engagement and political deliberation, her separation of morality from politics, and her praise of the revolutionary tradition. However, it would be a mistake to view Arendt as an anti-liberal thinker. Arendt was in fact a stern defender of constitutionalism and the rule of law, an advocate of fundamental human rights (among which she included not only the right to life, liberty, and freedom of expression, but also the right to action and to opinion), and a critic of all forms of political community based on traditional ties and customs, as well as those based on religious, ethnic, or racial identity.\n",
    "\n",
    "Arendt’s political thought cannot, in this sense, be identified either with the liberal tradition or with the claims advanced by a number of its critics. Arendt did not conceive of politics as a means for the satisfaction of individual preferences, nor as a way to integrate individuals around a shared conception of the good. Her conception of politics is based instead on the idea of active citizenship, that is, on the value and importance of civic engagement and collective deliberation about all matters affecting the political community. If there is a tradition of thought with which Arendt can be identified, it is the classical tradition of civic republicanism originating in Aristotle and embodied in the writings of Machiavelli, Montesquieu, Jefferson, and Tocqueville. According to this tradition politics finds its authentic expression whenever citizens gather together in a public space to deliberate and decide about matters of collective concern. Political activity is valued not because it may lead to agreement or to a shared conception of the good, but because it enables each citizen to exercise his or her powers of agency, to develop the capacities for judgment and to attain by concerted action some measure of political efficacy.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcd13b4",
   "metadata": {},
   "source": [
    "# Prompts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecfeb5c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:18.018302Z",
     "start_time": "2024-06-11T04:34:17.997887Z"
    },
    "code_folding": [],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "inputs_chat = [\n",
    "  \"Think of some family rules to promote a healthy family relationship\",\n",
    "  \"In the series A Song of Ice and Fire, who is the founder of House Karstark?\",\n",
    "  \"which weighs more, cold or hot water?\",\n",
    "  \"Write a short paragraph about why you should not have both a pet cat and a pet bird.\",\n",
    "  \"Is beauty objective or subjective?\",\n",
    "  \"What is SVM?\",\n",
    "  \"What is the current capital of Japan?\",\n",
    "  \"Name 10 colors\",\n",
    "  \"How should I invest my money?\",\n",
    "  \"What are some ways to improve the value of your home?\",\n",
    "  \"What does fasting mean?\",\n",
    "  \"What is cloud computing in simple terms?\",\n",
    "  \"What is the meaning of life?\",\n",
    "  \"What is Linux?\",\n",
    "  \"Why do people like gardening?\",\n",
    "  \"What makes for a good photograph?\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inputs_base = [\n",
    "    \"Gardening provides a sense of accomplishment and tranquility, as you nurture plants and watch them\",\n",
    "    \"Family traditions are passed down from generation to generation, creating a sense of continuity and belonging. Whether it's holiday celebrations, special recipes, or annual gatherings, these traditions foster\",\n",
    "    \"The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future\",\n",
    "    \n",
    "    \"Artificial intelligence is transforming the healthcare industry by enabling\",\n",
    "    \"Machine learning algorithms are increasingly being used to predict stock market trends. By analyzing historical data and identifying patterns, these models can\",\n",
    "    \"The integration of natural language processing with machine learning has opened up new possibilities in human-computer interaction. For instance, chatbots powered by sophisticated NLP algorithms can now understand and respond to user queries with remarkable accuracy. As these technologies continue to evolve, we can expect that\",\n",
    "    \n",
    "    \"Self-driving cars rely heavily on sensor data and advanced algorithms to navigate\",\n",
    "    \"One of the biggest challenges in developing AI systems is ensuring they are ethical and unbiased. Researchers are working on creating frameworks that can\",\n",
    "    \"In the field of computer vision, convolutional neural networks have revolutionized the way machines perceive visual information. By mimicking the human visual system, these networks can classify images, detect objects, and even perform image segmentation. This has significant applications in areas such as medical imaging, where AI can assist doctors in diagnosing conditions from X-rays and MRIs. As the technology advances, we may soon see AI systems that\",\n",
    "    \n",
    "    \"Reinforcement learning algorithms learn optimal behaviors through\",\n",
    "    \"Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could\",\n",
    "    \"The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that\",\n",
    "    \n",
    "    \"Transfer learning allows models trained on large datasets to be fine-tuned for specific tasks by\",\n",
    "    \"Explainable AI (XAI) is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to\",\n",
    "    \n",
    "    \"The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and\",\n",
    "    \"Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2f304a",
   "metadata": {},
   "source": [
    "# Generation Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64d4c46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T19:25:35.236887Z",
     "start_time": "2024-05-17T19:25:35.230980Z"
    }
   },
   "source": [
    "## Text Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73fe6980",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:18.038301Z",
     "start_time": "2024-06-11T04:34:18.021716Z"
    },
    "code_folding": [
     13,
     21
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"\"\"\n",
    "\n",
    "INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
    "PROMPT_FOR_GENERATION_FORMAT = \"\"\"\n",
    "<s>[INST]<<SYS>>\n",
    "{system_prompt}\n",
    "<</SYS>>\n",
    "\n",
    "{instruction}\n",
    "[/INST]\n",
    "\"\"\".format(\n",
    "    system_prompt=DEFAULT_SYSTEM_PROMPT,\n",
    "    instruction=\"{instruction}\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Define parameters to generate text\n",
    "def gen_text(prompts, pipeline, tokenizer, use_template=False, **kwargs):\n",
    "    if use_template:\n",
    "        full_prompts = [\n",
    "            PROMPT_FOR_GENERATION_FORMAT.format(instruction=prompt)\n",
    "            for prompt in prompts\n",
    "        ]\n",
    "    else:\n",
    "        full_prompts = prompts\n",
    "\n",
    "    if \"batch_size\" not in kwargs:\n",
    "        kwargs[\"batch_size\"] = 1\n",
    "    \n",
    "    # the default max length is pretty small (20), which would cut the generated output in the middle, so it's necessary to increase the threshold to the complete response\n",
    "    if \"max_new_tokens\" not in kwargs:\n",
    "        kwargs[\"max_new_tokens\"] = 512\n",
    "\n",
    "    # configure other text generation arguments, see common configurable args here: https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationConfig\n",
    "    kwargs.update(\n",
    "        {\n",
    "            \"pad_token_id\": tokenizer.eos_token_id,  # Hugging Face sets pad_token_id to eos_token_id by default; setting here to not see redundant message\n",
    "            \"eos_token_id\": tokenizer.eos_token_id,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    outputs = pipeline(full_prompts, **kwargs)\n",
    "    outputs = [out[0][\"generated_text\"] for out in outputs]\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "# results = gen_text([\"What is a large language model?\"])\n",
    "# print(results[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6693a24b",
   "metadata": {},
   "source": [
    "## Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52bb8b63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:18.044844Z",
     "start_time": "2024-06-11T04:34:18.041182Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_num_tokens(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    return inputs.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42ed36b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:18.055935Z",
     "start_time": "2024-06-11T04:34:18.047095Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_gen_text_throughput(prompt, pipeline, tokenizer, use_template=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Return tuple ( number of tokens / sec, num tokens, output ) of the generated tokens\n",
    "    \"\"\"\n",
    "    if use_template:\n",
    "        full_prompt = PROMPT_FOR_GENERATION_FORMAT.format(instruction=prompt)\n",
    "    else:\n",
    "        full_prompt = prompt\n",
    "\n",
    "    if \"max_new_tokens\" not in kwargs:\n",
    "        kwargs[\"max_new_tokens\"] = 512\n",
    "\n",
    "    kwargs.update(\n",
    "        {\n",
    "            \"do_sample\": True,\n",
    "            \"pad_token_id\": tokenizer.eos_token_id,\n",
    "            \"eos_token_id\": tokenizer.eos_token_id,\n",
    "            \"return_tensors\": True,  # make the pipeline return token ids instead of decoded text to get the number of generated tokens\n",
    "        }\n",
    "    )\n",
    "\n",
    "    num_input_tokens = get_num_tokens(full_prompt)\n",
    "\n",
    "    # measure the time it takes for text generation\n",
    "    start = time.time()\n",
    "    outputs = pipeline(full_prompt, **kwargs)\n",
    "    duration = time.time() - start\n",
    "\n",
    "    # get the number of generated tokens\n",
    "    n_tokens = len(outputs[0][\"generated_token_ids\"])\n",
    "\n",
    "    # show the generated text in logging\n",
    "    result = tokenizer.batch_decode(\n",
    "        outputs[0][\"generated_token_ids\"][num_input_tokens:], skip_special_tokens=True\n",
    "    )\n",
    "    result = \" \".join(result)\n",
    "\n",
    "    return (n_tokens / duration, n_tokens, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d26ee6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f6910fe",
   "metadata": {},
   "source": [
    "# Experiment Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13359b86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:31.422822Z",
     "start_time": "2024-06-11T04:34:18.058596Z"
    },
    "code_folding": [
     1
    ],
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 10:04:18.805070: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-11 10:04:18.857357: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-11 10:04:19.912321: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef9ff44cc8742cf80859a8831913831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(hf_llama_path, padding_side=\"left\", padding=True, truncation=True)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=hf_llama_path,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "#     revision=revision,\n",
    "    return_full_text=False\n",
    ")\n",
    "\n",
    "# Required tokenizer setting for batch inference\n",
    "pipeline.tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "model = pipeline.model\n",
    "model.seqlen = model.config.max_position_embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57f659c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:31.430286Z",
     "start_time": "2024-06-11T04:34:31.424937Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6738415616"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35897a49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:31.466242Z",
     "start_time": "2024-06-11T04:34:31.432119Z"
    },
    "code_folding": [
     2,
     7,
     27
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_output(output_text):\n",
    "    # Remove repeated sentences\n",
    "    unique_sentences = set()\n",
    "    cleaned_output = []\n",
    "    \n",
    "    for sentence in output_text.split('.'):\n",
    "        sentence = sentence.strip()\n",
    "        if sentence and sentence not in unique_sentences:\n",
    "            cleaned_output.append(sentence)\n",
    "            unique_sentences.add(sentence)\n",
    "    \n",
    "    # Remove garbage symbols\n",
    "#     cleaned_output = [re.sub(r'[^\\w\\s]', '', sentence) for sentence in cleaned_output]\n",
    "    \n",
    "    # Exclude the last sentence if it does not end with a period\n",
    "    if output_text[-1] != '.':\n",
    "        cleaned_output = cleaned_output[:-1]\n",
    "    \n",
    "    return \". \".join(cleaned_output) + \".\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "from transformers.models.llama.modeling_llama import LlamaAttention, LlamaDecoderLayer, LlamaMLP, LlamaConfig, LlamaDecoderLayer\n",
    "\n",
    "\n",
    "class ExperimentRunner:\n",
    "    def __init__(self, pipeline, tokenizer, pruning_dict, \n",
    "                 save_dir=None, output_dir=None, ignored_layers=None, \n",
    "                 use_template=False):\n",
    "        self.pipeline = pipeline\n",
    "        self.model = self.pipeline.model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pruning_dict = pruning_dict\n",
    "        self.save_dir = save_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.ignored_layers = ignored_layers\n",
    "        \n",
    "        self.use_template = use_template\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "        \n",
    "    \n",
    "    def get_head_inter_pruning_dict(self):\n",
    "        ## load pruning dict\n",
    "        if isinstance(self.pruning_dict,str):\n",
    "            pruning_dict_path = \"../pruning_dicts/\"  # replace with your directory\n",
    "            file_path = os.path.join(pruning_dict_path, self.pruning_dict)\n",
    "\n",
    "            with open(file_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "            self.pruning_dict = data\n",
    "        else:\n",
    "            if isinstance(self.pruning_dict, dict):\n",
    "                self.pruning_dict = pruning_dict\n",
    "            else:\n",
    "                raise ValueError(\"Pruning dict not valid\")\n",
    "        for i, ind in self.pruning_dict.items():\n",
    "            print(i, \"==> \",len(ind))\n",
    "    def prune_model(self, real):\n",
    "        modules = list(self.model.modules())\n",
    "        for idx, index in self.pruning_dict.items():\n",
    "            idx = int(idx)\n",
    "#             print(\"Pruning idx: {}, Type: {}\".format(idx, type(modules[idx])))\n",
    "            op = modules[idx]\n",
    "            if isinstance(op, LlamaAttention):\n",
    "                if real:\n",
    "                    op.q_proj = prune_linear_layer(op.q_proj, torch.LongTensor(index)).half()\n",
    "                    op.k_proj = prune_linear_layer(op.k_proj, torch.LongTensor(index)).half()\n",
    "                    op.v_proj = prune_linear_layer(op.v_proj, torch.LongTensor(index)).half()\n",
    "                    op.o_proj = prune_linear_layer(op.o_proj, torch.LongTensor(index), dim=1).half()\n",
    "                    \n",
    "                    op.num_heads = len(index)//op.head_dim\n",
    "                    op.num_key_value_heads = op.num_heads\n",
    "                    op.hidden_size = len(index)\n",
    "                else:\n",
    "                    op.q_proj = prune_linear_by_mask(op.q_proj, torch.LongTensor(index)).half()\n",
    "                    op.k_proj = prune_linear_by_mask(op.k_proj, torch.LongTensor(index)).half()\n",
    "                    op.v_proj = prune_linear_by_mask(op.v_proj, torch.LongTensor(index)).half()\n",
    "                    op.o_proj = prune_linear_by_mask(op.o_proj, torch.LongTensor(index), dim=1).half()\n",
    "            elif isinstance(op, LlamaMLP):\n",
    "                if real:\n",
    "                    op.gate_proj = prune_linear_layer(op.gate_proj, torch.LongTensor(index)).half()\n",
    "                    op.up_proj = prune_linear_layer(op.up_proj, torch.LongTensor(index)).half()\n",
    "                    op.down_proj = prune_linear_layer(op.down_proj, torch.LongTensor(index), dim=1).half()\n",
    "                    \n",
    "                    op.intermediate_size = len(index)\n",
    "                else:\n",
    "                    op.gate_proj = prune_linear_by_mask(op.gate_proj, torch.LongTensor(index)).half()\n",
    "                    op.up_proj = prune_linear_by_mask(op.up_proj, torch.LongTensor(index)).half()\n",
    "                    op.down_proj = prune_linear_by_mask(op.down_proj, torch.LongTensor(index), dim=1).half()\n",
    "                    \n",
    "            else: \n",
    "                raise ValueError(\"Got invalid Module\")\n",
    "            print(\"Model size after pruning: \", self.get_model_size())\n",
    "        \n",
    "    def prune_and_save_checkpoint(self, real=False):\n",
    "        # Prune the model\n",
    "        print(\"Pruning model\")\n",
    "        self.prune_model(real)\n",
    "        print(\"Saving model after pruning to checkpoint dir\")\n",
    "        # Save the model checkpoint\n",
    "        self.model.save_pretrained(self.save_dir)\n",
    "        self.tokenizer.save_pretrained(self.save_dir)\n",
    "        print(\"Model saved\")\n",
    "        \n",
    "    def save_checkpoint(self):\n",
    "        self.model.save_pretrained(self.save_dir)\n",
    "        self.tokenizer.save_pretrained(self.save_dir)\n",
    "        print(\"Model saved\")\n",
    "        \n",
    "    def remove_checkpoint(self):\n",
    "        import os\n",
    "        import glob\n",
    "\n",
    "        folder_path = self.save_dir # replace with your folder path\n",
    "        extension = '*safetensors'  # replace with your file extension\n",
    "\n",
    "        files = glob.glob(os.path.join(folder_path, extension))\n",
    "\n",
    "        for file in files:\n",
    "            os.remove(file)\n",
    "        \n",
    "    def get_model_size(self):\n",
    "        return self.model.get_memory_footprint()/10e8\n",
    "    \n",
    "    def evaluate_ppl(self):\n",
    "        # Evaluate the model on wikitext and zero shot\n",
    "        wikitext_results = eval_ppl(self.pipeline.model, self.tokenizer)\n",
    "        # Dump the results to json files\n",
    "        print(\"Perplexity on wikitext2: \", wikitext_results)\n",
    "        with open(os.path.join(self.output_dir, 'wikitext_results.json'), 'w') as f:\n",
    "            json.dump(wikitext_results, f, indent=4)\n",
    "        \n",
    "    def evaluate_zero_shot(self):\n",
    "        task_list = [\"boolq\", \"rte\",\"hellaswag\",\"winogrande\", \"arc_easy\",\"arc_challenge\", \"openbookqa\"]\n",
    "        num_shot = 0\n",
    "        print(\"Loading checkpoint from {}\".format(self.save_dir))\n",
    "        m = \"Llama-2-7b-hf\"\n",
    "        accelerate = False\n",
    "        results = eval_zero_shot(m, self.model, self.tokenizer, self.save_dir, task_list, num_shot, accelerate)\n",
    "\n",
    "        with open(os.path.join(self.output_dir, 'zero_shot_results.json'), 'w') as f:\n",
    "            json.dump(results['results'], f, indent=4)\n",
    "            \n",
    "        from prettytable import PrettyTable\n",
    "\n",
    "        # Create a PrettyTable object\n",
    "        table = PrettyTable()\n",
    "        # Add columns\n",
    "        table.field_names = [\"Alias\", \"Acc, None\", \"Acc StdErr, None\", \"Acc Norm, None\", \"Acc Norm StdErr, None\"]\n",
    "        # Add rows\n",
    "        for key, value in results['results'].items():\n",
    "            row = [value.get('alias'), value.get('acc,none'), value.get('acc_stderr,none'), value.get('acc_norm,none'), value.get('acc_norm_stderr,none')]\n",
    "            table.add_row(row)\n",
    "\n",
    "        print(table)\n",
    "    \n",
    "    def retrain(self, train_loader, epochs):\n",
    "        pass\n",
    "                \n",
    "    def get_throughput(self):\n",
    "        throughput, n_tokens, result = get_gen_text_throughput(\"What is ML?\",self.pipeline, self.tokenizer, \n",
    "                                                               max_new_tokens=512, use_template=self.use_template)\n",
    "\n",
    "        print(f\"Short Context: {throughput} tokens/sec, {n_tokens} tokens (including full prompt)\")\n",
    "\n",
    "        # COMMAND ----------\n",
    "\n",
    "        # When the context is long or the generated text is long, it takes longer to generate each token in average\n",
    "        throughput, n_tokens, result = get_gen_text_throughput(long_input, self.pipeline, self.tokenizer,\n",
    "                                                               max_new_tokens=512, use_template=self.use_template)\n",
    "\n",
    "        print(f\"Long Context: {throughput} tokens/sec, {n_tokens} tokens (including full prompt)\")\n",
    "        # print(result)\n",
    "\n",
    "        t = []\n",
    "        data = inputs_chat if self.use_template else inputs_base \n",
    "        for inp in data:\n",
    "            throughput, n_tokens, result = get_gen_text_throughput(inp, self.pipeline, \n",
    "                                                                   self.tokenizer, max_new_tokens=512, \n",
    "                                                                   use_template=self.use_template)\n",
    "            t.append(throughput)\n",
    "        print(f\"Average:  {sum(t)/len(t)} tokens/sec\")\n",
    "\n",
    "    def generate_from_prompts(self):\n",
    "        data = inputs_chat if self.use_template else inputs_base \n",
    " \n",
    "        with open(os.path.join(self.output_dir,'generation_using_prompts.txt'), 'w') as f:\n",
    "            for inp in data: \n",
    "                results = gen_text([inp], self.pipeline, self.tokenizer, temperature=0.6, use_template=self.use_template, batch_size=1)\n",
    "\n",
    "                print(\"***\" * 50)\n",
    "                f.write(\"***\" * 50 + '\\n')\n",
    "                print(\"Original: \")\n",
    "                f.write(\"Original: \" + '\\n')\n",
    "                print(\"Prompt:  \", end=\"\")\n",
    "                f.write(\"Prompt:  \")\n",
    "                print(\"\\033[1m {} \\033[0m\".format(inp), end=\"\")  # \\033[1m and \\033[0m are the ANSI escape sequences for start and end of bold respectively\n",
    "                f.write(\"\\033[1m {} \\033[0m\".format(inp))\n",
    "                print(\"\\033[91m{}\\033[0m\".format(results[0]))\n",
    "                f.write(\"\\033[91m{}\\033[0m\".format(results[0]) + '\\n')\n",
    "\n",
    "                print(\"---\" * 50)\n",
    "                f.write(\"---\" * 50 + '\\n')\n",
    "                print(\"Cleaned: \")\n",
    "                f.write(\"Cleaned: \" + '\\n')\n",
    "                print(\"Prompt:  \", end=\"\")\n",
    "                f.write(\"Prompt:  \")\n",
    "                print(\"\\033[1m {} \\033[0m\".format(inp), end=\"\")  # \\033[1m and \\033[0m are the ANSI escape sequences for start and end of bold respectively\n",
    "                f.write(\"\\033[1m {} \\033[0m\".format(inp))\n",
    "                print(\"\\033[91m{}\\033[0m\".format(clean_output(results[0])))\n",
    "                f.write(\"\\033[91m{}\\033[0m\".format(clean_output(results[0])) + '\\n')\n",
    "\n",
    "                print('\\n')\n",
    "                f.write('\\n')\n",
    "\n",
    "    def get_eval(self):\n",
    "        ## Eval on wikitext \n",
    "        self.evaluate_ppl()\n",
    "        ## Eval zero shot \n",
    "        self.evaluate_zero_shot()\n",
    "        ## Get generation on prompts\n",
    "        self.generate_from_prompts()\n",
    "        \n",
    "    def run(self, eval_orig_model=False):\n",
    "        print(\"*\" * 15, \"  Running Experiment  \", \"*\" * 15)\n",
    "        self.get_head_inter_pruning_dict()\n",
    "        if eval_orig_model:\n",
    "            get_eval()\n",
    "            \n",
    "        print(\"*\" * 15, \"  Pruning Model  \", \"*\" * 15)\n",
    "        self.prune_and_save_checkpoint(real=False)\n",
    "        \n",
    "        print(\"*\" * 15, \"  Model Pruned Successfully  \", \"*\" * 15)\n",
    "        print(\"Model Size after Pruning: \", self.get_model_size())\n",
    "        self.get_eval()\n",
    "        \n",
    "        self.prune_and_save_checkpoint(real=True)\n",
    "        print(\"Real Pruned Model\")\n",
    "        print(self.model)\n",
    "        \n",
    "        print(\"Real Pruned Model Size\")\n",
    "        print(self.get_model_size())\n",
    "        \n",
    "        self.get_throughput()\n",
    "        self.remove_checkpoint()\n",
    "        print(\"*\" * 15, \"  Experiment completed successfully Successfully  \", \"*\" * 15)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91940993",
   "metadata": {},
   "source": [
    "# Wanda Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972abbf0",
   "metadata": {},
   "source": [
    "## Pr=0.8, lb=0.7, lb=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "707fda56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T03:27:11.995887Z",
     "start_time": "2024-06-11T03:27:11.992316Z"
    }
   },
   "outputs": [],
   "source": [
    "pruning_dict = \"pruning_dict_1.0_0.7_1.0_chat_2640.json\"\n",
    "save_dir = \"/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/\"\n",
    "\n",
    "p = pruning_dict.split(\"_\")[-1].split(\".\")[-2]\n",
    "output_dir = \"/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints//\" + p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "968ad8ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T03:27:12.291553Z",
     "start_time": "2024-06-11T03:27:12.288249Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment = ExperimentRunner(pipeline, tokenizer, pruning_dict, \n",
    "                 save_dir=save_dir, output_dir=output_dir, ignored_layers=None, \n",
    "                 use_template=use_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f73ff1f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T03:56:01.393083Z",
     "start_time": "2024-06-11T03:27:12.795755Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************   Running Experiment   ***************\n",
      "61 ==>  4096\n",
      "67 ==>  10945\n",
      "75 ==>  4096\n",
      "81 ==>  10953\n",
      "89 ==>  4096\n",
      "95 ==>  10965\n",
      "103 ==>  4096\n",
      "109 ==>  10830\n",
      "117 ==>  4096\n",
      "123 ==>  10774\n",
      "131 ==>  4096\n",
      "137 ==>  10970\n",
      "145 ==>  4096\n",
      "151 ==>  10936\n",
      "159 ==>  4096\n",
      "165 ==>  10997\n",
      "173 ==>  4096\n",
      "179 ==>  10930\n",
      "187 ==>  4096\n",
      "193 ==>  9594\n",
      "201 ==>  2816\n",
      "207 ==>  7706\n",
      "215 ==>  2816\n",
      "221 ==>  7706\n",
      "229 ==>  2816\n",
      "235 ==>  7706\n",
      "243 ==>  2816\n",
      "249 ==>  7706\n",
      "257 ==>  2816\n",
      "263 ==>  7706\n",
      "271 ==>  2816\n",
      "277 ==>  7706\n",
      "285 ==>  2816\n",
      "291 ==>  7706\n",
      "299 ==>  2816\n",
      "305 ==>  7731\n",
      "313 ==>  2816\n",
      "319 ==>  7800\n",
      "327 ==>  2816\n",
      "333 ==>  7770\n",
      "341 ==>  2816\n",
      "347 ==>  7783\n",
      "355 ==>  2816\n",
      "361 ==>  7777\n",
      "369 ==>  2816\n",
      "375 ==>  7780\n",
      "383 ==>  2816\n",
      "389 ==>  7778\n",
      "397 ==>  2816\n",
      "403 ==>  7780\n",
      "411 ==>  2816\n",
      "417 ==>  7778\n",
      "425 ==>  2816\n",
      "431 ==>  7780\n",
      "***************   Pruning Model   ***************\n",
      "Pruning model\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Saving model after pruning to checkpoint dir\n",
      "Model saved\n",
      "***************   Model Pruned Successfully   ***************\n",
      "Model Size after Pruning:  13.476839424\n",
      "evaluating on wikitext2\n",
      "nsamples 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:   0%|                                                                                 | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WikiText Validation:   8%|█████▊                                                                   | 2/25 [00:01<00:11,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  12%|████████▊                                                                | 3/25 [00:01<00:10,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  16%|███████████▋                                                             | 4/25 [00:01<00:09,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  20%|██████████████▌                                                          | 5/25 [00:02<00:08,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  24%|█████████████████▌                                                       | 6/25 [00:02<00:08,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  28%|████████████████████▍                                                    | 7/25 [00:03<00:07,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  32%|███████████████████████▎                                                 | 8/25 [00:03<00:07,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  36%|██████████████████████████▎                                              | 9/25 [00:04<00:06,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  40%|████████████████████████████▊                                           | 10/25 [00:04<00:06,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  44%|███████████████████████████████▋                                        | 11/25 [00:04<00:05,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  48%|██████████████████████████████████▌                                     | 12/25 [00:05<00:05,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  52%|█████████████████████████████████████▍                                  | 13/25 [00:05<00:05,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  56%|████████████████████████████████████████▎                               | 14/25 [00:06<00:04,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  60%|███████████████████████████████████████████▏                            | 15/25 [00:06<00:04,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  64%|██████████████████████████████████████████████                          | 16/25 [00:06<00:03,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  68%|████████████████████████████████████████████████▉                       | 17/25 [00:07<00:03,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  72%|███████████████████████████████████████████████████▊                    | 18/25 [00:07<00:02,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  76%|██████████████████████████████████████████████████████▋                 | 19/25 [00:08<00:02,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  80%|█████████████████████████████████████████████████████████▌              | 20/25 [00:08<00:02,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  84%|████████████████████████████████████████████████████████████▍           | 21/25 [00:09<00:01,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  88%|███████████████████████████████████████████████████████████████▎        | 22/25 [00:09<00:01,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  92%|██████████████████████████████████████████████████████████████████▏     | 23/25 [00:09<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  96%|█████████████████████████████████████████████████████████████████████   | 24/25 [00:10<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WikiText Validation: 100%|████████████████████████████████████████████████████████████████████████| 25/25 [00:10<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPL:  8.154172897338867\n",
      "Perplexity on wikitext2:  8.154172897338867\n",
      "Loading checkpoint from /data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/\n",
      "Model passed to evaluation:  LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11:09:00:36,093 WARNING  [task.py:763] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-06-11:09:00:36,095 WARNING  [task.py:775] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2024-06-11:09:01:12,463 WARNING  [task.py:763] [Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-06-11:09:01:12,465 WARNING  [task.py:775] [Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for winogrande contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/winogrande\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2024-06-11:09:04:45,571 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-06-11:09:04:45,573 INFO     [evaluator.py:177] Initializing huggingface model, with arguments: {'pretrained': '/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/'}\n",
      "2024-06-11:09:04:45,584 WARNING  [logging.py:61] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "2024-06-11:09:04:45,585 INFO     [huggingface.py:163] Using device 'cuda'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a7b074f75440c5b821419fc7e8b842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11:09:04:58,648 WARNING  [task.py:763] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-06-11:09:04:58,650 WARNING  [task.py:775] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-06-11:09:05:34,636 WARNING  [task.py:763] [Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-06-11:09:05:34,638 WARNING  [task.py:775] [Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-06-11:09:08:54,024 WARNING  [evaluator.py:239] Overwriting default num_fewshot of openbookqa from None to 0\n",
      "2024-06-11:09:08:54,025 WARNING  [evaluator.py:239] Overwriting default num_fewshot of arc_easy from None to 0\n",
      "2024-06-11:09:08:54,026 WARNING  [evaluator.py:239] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2024-06-11:09:08:54,026 WARNING  [evaluator.py:239] Overwriting default num_fewshot of winogrande from None to 0\n",
      "2024-06-11:09:08:54,027 WARNING  [evaluator.py:239] Overwriting default num_fewshot of arc_challenge from None to 0\n",
      "2024-06-11:09:08:54,028 WARNING  [evaluator.py:239] Overwriting default num_fewshot of rte from None to 0\n",
      "2024-06-11:09:08:54,028 WARNING  [evaluator.py:239] Overwriting default num_fewshot of boolq from None to 0\n",
      "2024-06-11:09:08:54,033 INFO     [task.py:395] Building contexts for openbookqa on rank 0...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 125.64it/s]\n",
      "2024-06-11:09:08:54,839 INFO     [task.py:395] Building contexts for arc_easy on rank 0...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 904.88it/s]\n",
      "2024-06-11:09:08:54,961 INFO     [task.py:395] Building contexts for hellaswag on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 2152.07it/s]\n",
      "2024-06-11:09:08:55,031 INFO     [task.py:395] Building contexts for winogrande on rank 0...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 69396.16it/s]\n",
      "2024-06-11:09:08:55,039 INFO     [task.py:395] Building contexts for arc_challenge on rank 0...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 871.33it/s]\n",
      "2024-06-11:09:08:55,165 INFO     [task.py:395] Building contexts for rte on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1409.54it/s]\n",
      "2024-06-11:09:08:55,245 INFO     [task.py:395] Building contexts for boolq on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1361.15it/s]\n",
      "2024-06-11:09:08:55,335 INFO     [evaluator.py:379] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|█████████████████████████████████████████████████████████| 2199/2199 [01:46<00:00, 20.74it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "fatal: not a git repository (or any parent up to mount point /)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "|     Alias     | Acc, None |   Acc StdErr, None   | Acc Norm, None | Acc Norm StdErr, None |\n",
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "|   openbookqa  |    0.28   | 0.045126085985421276 |      0.41      |  0.049431107042371025 |\n",
      "|    arc_easy   |    0.69   | 0.04648231987117316  |      0.69      |  0.04648231987117316  |\n",
      "|   hellaswag   |    0.53   | 0.050161355804659205 |      0.63      |  0.04852365870939099  |\n",
      "|   winogrande  |    0.7    | 0.046056618647183814 |      None      |          None         |\n",
      "| arc_challenge |    0.4    | 0.049236596391733084 |      0.44      |  0.04988876515698589  |\n",
      "|      rte      |    0.68   | 0.04688261722621505  |      None      |          None         |\n",
      "|     boolq     |    0.77   | 0.04229525846816506  |      None      |          None         |\n",
      "+---------------+-----------+----------------------+----------------+-----------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Gardening provides a sense of accomplishment and tranquility, as you nurture plants and watch them \u001b[0m\u001b[91m grow.\n",
      "Gardening is a great way to get some exercise.\n",
      "Gardening is a great way to get some exercise. It is a good way to get your heart rate up and to stay in shape.\n",
      "Gardening is a great way to get some exercise. It is a good way to get your heart rate up and to stay in shape.\n",
      "Gardening is a great way to get some exercise. It is a good way to get your heart rate up and to stay in shape.\n",
      "Gardening is a great way to get some exercise. It is a good way to get your heart rate up and to stay in shape.\n",
      "Gardening is a great way to get some exercise. It is a good way to get your heart rate up and to stay in shape.\n",
      "Gardening is a great way to get some exercise. It is a good way to get your heart rate up and to stay in shape.\n",
      "Gardening is a great way to get some exercise. It is a good way to get your heart rate up and to stay in shape.\n",
      "Gardening is a great way to get some exercise. It is a good way to get your heart rate up and to stay in shape.\n",
      "Gardening is a great way to get some exercise. It is a good way to get your heart rate up and to stay in shape.\n",
      "Gardening is a great way to get some exercise. It is a good way to get your heart rate up and to stay in shape.\n",
      "Gardening is a great way to get some exercise. It is a good way to get your heart rate up and to stay in shape.\n",
      "Gardening is a great way to get some exercise. It is a good way to get your heart rate up and to stay in shape.\n",
      "Gardening is a great way to get some exercise. It is a good way to get your heart rate up and to stay in shape.\n",
      "Gardening is a great way to get some exercise. It is a good way to get your heart rate up and to stay in shape.\n",
      "Gardening is a great way to get some exercise. It is a good way to get your heart rate up and to stay in shape.\n",
      "Gardening is a great way to get some exercise. It is a good way to get your heart rate up and to stay in shape.\n",
      "Gardening is a great way to get some exercise. It is a good\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Gardening provides a sense of accomplishment and tranquility, as you nurture plants and watch them \u001b[0m\u001b[91mgrow. Gardening is a great way to get some exercise. It is a good way to get your heart rate up and to stay in shape.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Family traditions are passed down from generation to generation, creating a sense of continuity and belonging. Whether it's holiday celebrations, special recipes, or annual gatherings, these traditions foster \u001b[0m\u001b[91m a strong sense of identity and community.\n",
      "Family traditions are a valuable part of our lives. They help us to feel a sense of belonging and continuity. They also provide a valuable opportunity to spend time with our loved ones.\n",
      "Family traditions are a valuable part of our lives. They help us to feel a sense of belonging and continuity. They also provide a valuable opportunity to spend time with our loved ones.\n",
      "Family traditions are a valuable part of our lives. They help us to feel a sense of belonging and continuity. They also provide a valuable opportunity to spend time with our loved ones.\n",
      "Family traditions are a valuable part of our lives. They help us to feel a sense of belonging and continuity. They also provide a valuable opportunity to spend time with our loved ones.\n",
      "Family traditions are a valuable part of our lives. They help us to feel a sense of belonging and continuity. They also provide a valuable opportunity to spend time with our loved ones.\n",
      "Family traditions are a valuable part of our lives. They help us to feel a sense of belonging and continuity. They also provide a valuable opportunity to spend time with our loved ones.\n",
      "Family traditions are a valuable part of our lives. They help us to feel a sense of belonging and continuity. They also provide a valuable opportunity to spend time with our loved ones.\n",
      "Family traditions are a valuable part of our lives. They help us to feel a sense of belonging and continuity. They also provide a valuable opportunity to spend time with our loved ones.\n",
      "Family traditions are a valuable part of our lives. They help us to feel a sense of belonging and continuity. They also provide a valuable opportunity to spend time with our loved ones.\n",
      "Family traditions are a valuable part of our lives. They help us to feel a sense of belonging and continuity. They also provide a valuable opportunity to spend time with our loved ones.\n",
      "Family traditions are a valuable part of our lives. They help us to feel a sense of belonging and continuity. They also provide a valuable opportunity to spend time with our loved ones.\n",
      "Family traditions are a valuable part of our lives. They help us to feel a sense of belonging and continuity. They also provide a valuable opportunity to spend time with our loved ones.\n",
      "Family traditions are a valuable part of our lives. They help us to feel a sense of belonging and continuity. They also provide a valuable opportunity to spend time with our\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Family traditions are passed down from generation to generation, creating a sense of continuity and belonging. Whether it's holiday celebrations, special recipes, or annual gatherings, these traditions foster \u001b[0m\u001b[91ma strong sense of identity and community. Family traditions are a valuable part of our lives. They help us to feel a sense of belonging and continuity. They also provide a valuable opportunity to spend time with our loved ones.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future \u001b[0m\u001b[91m, fashion will evolve to reflect these changes, and we will see new trends and styles emerge.\n",
      "Fashion is a constantly evolving industry, and it is important to be aware of the latest trends. The latest trends in fashion include:\n",
      "1. Sustainability: Sustainability is becoming an increasingly important factor in the fashion industry. Many brands are now offering products made from sustainable materials, such as organic cotton.\n",
      "2. Digital Fashion Shows: Digital fashion shows are becoming more popular as they offer a convenient and cost-effective way to showcase new collections.\n",
      "3. Inclusivity: Inclusivity is becoming more important as brands are becoming more aware of the need to be more inclusive of all people, regardless of their age, race, or gender.\n",
      "4. Diversity: Diversity is becoming more important as brands are becoming more aware of the need to be more diverse in their products and services.\n",
      "5. Personalization: Personalization is becoming more important as brands are becoming more aware of the need to offer products that are tailored to the individual.\n",
      "6. Artificial Intelligence: Artificial intelligence is becoming more important as it offers a convenient and cost-effective way to analyze customer data and create personalized products.\n",
      "7. Virtual Reality: Virtual reality is becoming more popular as it offers a convenient and cost-effective way to experience new products.\n",
      "8. 3D Printing: 3D printing is becoming more popular as it offers a convenient and cost-effective way to create new products.\n",
      "9. Blockchain: Blockchain is becoming more popular as it offers a secure and efficient way to track products from their source to their destination.\n",
      "10. Smart Cities: Smart cities are becoming more popular as they offer a convenient and cost-effective way to track products from their source to their destination.\n",
      "11. Drones: Drones are becoming more popular as they offer a convenient and cost-effective way to track products from their source to their destination.\n",
      "12. 5G: 5G is becoming more popular as it offers a secure and efficient way to track products from their source to their destination.\n",
      "13. 6G: 6G is becoming more popular as it offers a secure and efficient way to track products from their source to their destination.\n",
      "14.\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future \u001b[0m\u001b[91m, fashion will evolve to reflect these changes, and we will see new trends and styles emerge. Fashion is a constantly evolving industry, and it is important to be aware of the latest trends. The latest trends in fashion include:\n",
      "1. Sustainability: Sustainability is becoming an increasingly important factor in the fashion industry. Many brands are now offering products made from sustainable materials, such as organic cotton. 2. Digital Fashion Shows: Digital fashion shows are becoming more popular as they offer a convenient and cost-effective way to showcase new collections. 3. Inclusivity: Inclusivity is becoming more important as brands are becoming more aware of the need to be more inclusive of all people, regardless of their age, race, or gender. 4. Diversity: Diversity is becoming more important as brands are becoming more aware of the need to be more diverse in their products and services. 5. Personalization: Personalization is becoming more important as brands are becoming more aware of the need to offer products that are tailored to the individual. 6. Artificial Intelligence: Artificial intelligence is becoming more important as it offers a convenient and cost-effective way to analyze customer data and create personalized products. 7. Virtual Reality: Virtual reality is becoming more popular as it offers a convenient and cost-effective way to experience new products. 8. 3D Printing: 3D printing is becoming more popular as it offers a convenient and cost-effective way to create new products. 9. Blockchain: Blockchain is becoming more popular as it offers a secure and efficient way to track products from their source to their destination. 10. Smart Cities: Smart cities are becoming more popular as they offer a convenient and cost-effective way to track products from their source to their destination. 11. Drones: Drones are becoming more popular as they offer a convenient and cost-effective way to track products from their source to their destination. 12. 5G: 5G is becoming more popular as it offers a secure and efficient way to track products from their source to their destination. 13. 6G: 6G is becoming more popular as it offers a secure and efficient way to track products from their source to their destination. 14.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Artificial intelligence is transforming the healthcare industry by enabling \u001b[0m\u001b[91m it to become more efficient and effective.\n",
      "The benefits of AI in healthcare are numerous. For example, it can be used to detect diseases early, reduce medical errors, and improve patient care.\n",
      "However, there are also some concerns about the potential for AI to be used maliciously.\n",
      "In this blog post, we will explore the benefits and concerns of AI in healthcare.\n",
      "The benefits of AI in healthcare are numerous. For example, it can be used to detect diseases early, reduce medical errors, and improve patient care.\n",
      "However, there are also some concerns about the potential for AI to be used maliciously. In this blog post, we will explore the benefits and concerns of AI in healthcare.\n",
      "The benefits of AI in healthcare are numerous. For example, it can be used to detect diseases early, reduce medical errors, and improve patient care. However, there are also some concerns about the potential for AI to be used maliciously. In this blog post, we will explore the benefits and concerns of AI in healthcare.\n",
      "The benefits of AI in healthcare are numerous. For example, it can be used to detect diseases early, reduce medical errors, and improve patient care. However, there are also some concerns about the potential for AI to be used maliciously. In this blog post, we will explore the benefits and concerns of AI in healthcare.\n",
      "The benefits of AI in healthcare are numerous. For example, it can be used to detect diseases early, reduce medical errors, and improve patient care. However, there are also some concerns about the potential for AI to be used maliciously. In this blog post, we will explore the benefits and concerns of AI in healthcare.\n",
      "The benefits of AI in healthcare are numerous. For example, it can be used to detect diseases early, reduce medical errors, and improve patient care. However, there are also some concerns about the potential for AI to be used maliciously. In this blog post, we will explore the benefits and concerns of AI in healthcare.\n",
      "The benefits of AI in healthcare are numerous. For example, it can be used to detect diseases early, reduce medical errors, and improve patient care. However, there are also some concerns about the potential for AI to be used maliciously. In this blog post, we will explore the\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Artificial intelligence is transforming the healthcare industry by enabling \u001b[0m\u001b[91mit to become more efficient and effective. The benefits of AI in healthcare are numerous. For example, it can be used to detect diseases early, reduce medical errors, and improve patient care. However, there are also some concerns about the potential for AI to be used maliciously. In this blog post, we will explore the benefits and concerns of AI in healthcare.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Machine learning algorithms are increasingly being used to predict stock market trends. By analyzing historical data and identifying patterns, these models can \u001b[0m\u001b[91m help to identify potential opportunities for investors.\n",
      "The benefits of using machine learning algorithms to predict stock market trends are numerous. First, they can help to identify potential opportunities for investors. Second, they can also be used to create more accurate forecasts of future prices. Third, they can be used to create more efficient trading strategies.\n",
      "The potential risks of using machine learning algorithms to predict stock market trends are also numerous. First, they can be used to create more inaccurate forecasts of future prices. Second, they can also be used to create more inefficient trading strategies. Third, they can be used to create more complex trading strategies.\n",
      "The potential benefits of using machine learning algorithms to predict stock market trends are numerous. First, they can help to identify potential opportunities for investors. Second, they can also be used to create more accurate forecasts of future prices. Third, they can be used to create more efficient trading strategies.\n",
      "The potential risks of using machine learning algorithms to predict stock market trends are also numerous. First, they can be used to create more inaccurate forecasts of future prices. Second, they can also be used to create more inefficient trading strategies. Third, they can be used to create more complex trading strategies.\n",
      "The potential benefits of using machine learning algorithms to predict stock market trends are numerous. First, they can help to identify potential opportunities for investors. Second, they can also be used to create more accurate forecasts of future prices. Third, they can be used to create more efficient trading strategies.\n",
      "The potential risks of using machine learning algorithms to predict stock market trends are also numerous. First, they can be used to create more inaccurate forecasts of future prices. Second, they can also be used to create more inefficient trading strategies. Third, they can be used to create more complex trading strategies.\n",
      "The potential benefits of using machine learning algorithms to predict stock market trends are numerous. First, they can help to identify potential opportunities for investors. Second, they can also be used to create more accurate forecasts of future prices. Third, they can be used to create more efficient trading strategies.\n",
      "The potential risks of using machine learning algorithms to predict stock market trends are also numerous. First, they can be used to create more inaccurate forec\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Machine learning algorithms are increasingly being used to predict stock market trends. By analyzing historical data and identifying patterns, these models can \u001b[0m\u001b[91mhelp to identify potential opportunities for investors. The benefits of using machine learning algorithms to predict stock market trends are numerous. First, they can help to identify potential opportunities for investors. Second, they can also be used to create more accurate forecasts of future prices. Third, they can be used to create more efficient trading strategies. The potential risks of using machine learning algorithms to predict stock market trends are also numerous. First, they can be used to create more inaccurate forecasts of future prices. Second, they can also be used to create more inefficient trading strategies. Third, they can be used to create more complex trading strategies. The potential benefits of using machine learning algorithms to predict stock market trends are numerous.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The integration of natural language processing with machine learning has opened up new possibilities in human-computer interaction. For instance, chatbots powered by sophisticated NLP algorithms can now understand and respond to user queries with remarkable accuracy. As these technologies continue to evolve, we can expect that \u001b[0m\u001b[91m they will become more intelligent and more capable of helping us to navigate our lives.\n",
      "The future of human-computer interaction is a bright one. With the help of artificial intelligence, we can expect to see more intelligent and intuitive interactions between humans and computers. This will allow us to focus on the things that really matter, while the computers take care of the rest.\n",
      "Previous articleThe Future of Human-Computer Interaction: AI and Machine Learning\n",
      "Next articleThe Future of Human-Computer Interaction: AI and Machine Learning\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The integration of natural language processing with machine learning has opened up new possibilities in human-computer interaction. For instance, chatbots powered by sophisticated NLP algorithms can now understand and respond to user queries with remarkable accuracy. As these technologies continue to evolve, we can expect that \u001b[0m\u001b[91mthey will become more intelligent and more capable of helping us to navigate our lives. The future of human-computer interaction is a bright one. With the help of artificial intelligence, we can expect to see more intelligent and intuitive interactions between humans and computers. This will allow us to focus on the things that really matter, while the computers take care of the rest.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Self-driving cars rely heavily on sensor data and advanced algorithms to navigate \u001b[0m\u001b[91m the world.\n",
      "The technology is still in its early stages, but it has the potential to revolutionize the automotive industry.\n",
      "The biggest challenge is the lack of a standardized system for data collection and processing.\n",
      "The lack of a standardized system for data collection and processing is a major challenge for the automotive industry.\n",
      "The industry is still in its early stages, but it has the potential to revolutionize the way we drive cars.\n",
      "The technology is still in its early stages, but it has the potential to revolutionize the automotive industry.\n",
      "The technology is still in its early stages, but it has the potential to revolutionize the automotive industry. The industry is still in its early stages, but it has the potential to revolutionize the automotive industry.\n",
      "The automotive industry is still in its early stages, but it has the potential to revolutionize the automotive industry. The industry is still in its early stages, but it has the potential to revolutionize the automotive industry. The industry is still in its early stages, but it has the potential to revolutionize the automotive industry. The industry is still in its early stages, but it has the potential to revolutionize the automotive industry. The industry is still in its early stages, but it has the potential to revolutionize the automotive industry. The industry is still in its early stages, but it has the potential to revolutionize the automotive industry. The industry is still in its early stages, but it has the potential to revolutionize the automotive industry. The industry is still in its early stages, but it has the potential to revolutionize the automotive industry. The industry is still in its early stages, but it has the potential to revolutionize the automotive industry. The industry is still in its early stages, but it has the potential to revolutionize the automotive industry. The industry is still in its early stages, but it has the potential to revolutionize the automotive industry. The industry is still in its early stages, but it has the potential to revolutionize the automotive industry. The industry is still in its early stages, but it has the potential to revolutionize the automotive industry. The industry is still in its early stages, but it has the potential to revolutionize the automotive industry. The industry is still in its early stages, but it has the potential to revolutionize the automotive industry\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Self-driving cars rely heavily on sensor data and advanced algorithms to navigate \u001b[0m\u001b[91mthe world. The technology is still in its early stages, but it has the potential to revolutionize the automotive industry. The biggest challenge is the lack of a standardized system for data collection and processing. The lack of a standardized system for data collection and processing is a major challenge for the automotive industry. The industry is still in its early stages, but it has the potential to revolutionize the way we drive cars. The industry is still in its early stages, but it has the potential to revolutionize the automotive industry.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m One of the biggest challenges in developing AI systems is ensuring they are ethical and unbiased. Researchers are working on creating frameworks that can \u001b[0m\u001b[91m be used to develop ethical AI systems.\n",
      "The future of AI is uncertain, but it is likely to be a major force in the development of the technology. As the technology continues to evolve, it is likely to become more powerful and more intelligent.\n",
      "The future of AI is also likely to be more accessible. As the technology becomes more affordable, it is likely to become more widely used.\n",
      "Finally, the future of AI is likely to be more secure. As the technology becomes more secure, it is likely to become more reliable.\n",
      "Overall, the future of AI is likely to be more powerful and more intelligent. As the technology continues to evolve, it is likely to become more accessible and more secure.\n",
      "The future of AI is a very interesting topic. It is hard to predict what will happen in the future, but it is certain that AI will continue to evolve.\n",
      "AI is a very powerful technology, and it is likely to become more powerful in the future. It is also likely to become more intelligent.\n",
      "AI is a very interesting technology, and it is hard to predict what will happen in the future. It is certain that AI will continue to evolve.\n",
      "The future of AI is a very interesting topic. It is hard to predict what will happen in the future, but it is certain that AI will continue to evolve.\n",
      "The future of AI is a very interesting topic. It is hard to predict what will happen in the future, but it is certain that AI will continue to evolve. It is also hard to predict what will happen in the future, but it is certain that AI will continue to evolve.\n",
      "The future of AI is a very interesting topic. It is hard to predict what will happen in the future, but it is certain that AI will continue to evolve. It is also hard to predict what will happen in the future, but it is certain that AI will continue to evolve. It is hard to predict what will happen in the future, but it is certain that AI will continue to evolve.\n",
      "The future of AI is a very interesting topic. It is hard to predict what will happen in the future, but it is certain that AI will continue to evolve. It is also hard to predict what will happen in the future, but it is certain that AI will continue to evolve. It is hard to predict\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m One of the biggest challenges in developing AI systems is ensuring they are ethical and unbiased. Researchers are working on creating frameworks that can \u001b[0m\u001b[91mbe used to develop ethical AI systems. The future of AI is uncertain, but it is likely to be a major force in the development of the technology. As the technology continues to evolve, it is likely to become more powerful and more intelligent. The future of AI is also likely to be more accessible. As the technology becomes more affordable, it is likely to become more widely used. Finally, the future of AI is likely to be more secure. As the technology becomes more secure, it is likely to become more reliable. Overall, the future of AI is likely to be more powerful and more intelligent. As the technology continues to evolve, it is likely to become more accessible and more secure. The future of AI is a very interesting topic. It is hard to predict what will happen in the future, but it is certain that AI will continue to evolve. AI is a very powerful technology, and it is likely to become more powerful in the future. It is also likely to become more intelligent. AI is a very interesting technology, and it is hard to predict what will happen in the future. It is certain that AI will continue to evolve. It is also hard to predict what will happen in the future, but it is certain that AI will continue to evolve.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m In the field of computer vision, convolutional neural networks have revolutionized the way machines perceive visual information. By mimicking the human visual system, these networks can classify images, detect objects, and even perform image segmentation. This has significant applications in areas such as medical imaging, where AI can assist doctors in diagnosing conditions from X-rays and MRIs. As the technology advances, we may soon see AI systems that \u001b[0m\u001b[91m can not only identify diseases but also provide treatment recommendations.\n",
      "In the field of robotics, AI is also making significant progress. Robots are becoming more intelligent and capable of performing complex tasks. For example, robots are being used in manufacturing plants to perform repetitive tasks, such as welding and assembling products. These robots are becoming more intelligent and capable of making decisions on their own.\n",
      "In the field of healthcare, AI is also making significant progress. AI is being used to detect diseases, such as cancer, and to provide treatment recommendations. For example, AI is being used to analyze medical images, such as X-rays and MRIs, to detect tumors and other diseases.\n",
      "In the field of transportation, AI is also making significant progress. AI is being used to develop autonomous vehicles, such as cars and trucks. These vehicles are becoming more intelligent and capable of making decisions on their own.\n",
      "In the field of education, AI is also making significant progress. AI is being used to develop intelligent teaching assistants, such as chatbots. These assistants can provide students with the information they need to succeed in their studies.\n",
      "In the field of entertainment, AI is also making significant progress. AI is being used to develop intelligent entertainment systems, such as video games. These systems are becoming more intelligent and capable of making decisions on their own.\n",
      "In the field of security, AI is also making significant progress. AI is being used to develop intelligent security systems, such as facial recognition systems. These systems are becoming more intelligent and capable of making decisions on their own.\n",
      "In the field of agriculture, AI is also making significant progress. AI is being used to develop intelligent agricultural systems, such as drones. These systems are becoming more intelligent and capable of making decisions on their own.\n",
      "In the field of space exploration, AI is also making significant progress. AI is being used to develop intelligent space exploration systems, such as robots. These systems are becoming more intelligent and capable of making decisions on their own.\n",
      "In the field of defense, AI is also making significant progress. AI is being used to develop intelligent defense systems, such as drones. These systems are becoming more intelligent and capable of making\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m In the field of computer vision, convolutional neural networks have revolutionized the way machines perceive visual information. By mimicking the human visual system, these networks can classify images, detect objects, and even perform image segmentation. This has significant applications in areas such as medical imaging, where AI can assist doctors in diagnosing conditions from X-rays and MRIs. As the technology advances, we may soon see AI systems that \u001b[0m\u001b[91mcan not only identify diseases but also provide treatment recommendations. In the field of robotics, AI is also making significant progress. Robots are becoming more intelligent and capable of performing complex tasks. For example, robots are being used in manufacturing plants to perform repetitive tasks, such as welding and assembling products. These robots are becoming more intelligent and capable of making decisions on their own. In the field of healthcare, AI is also making significant progress. AI is being used to detect diseases, such as cancer, and to provide treatment recommendations. For example, AI is being used to analyze medical images, such as X-rays and MRIs, to detect tumors and other diseases. In the field of transportation, AI is also making significant progress. AI is being used to develop autonomous vehicles, such as cars and trucks. These vehicles are becoming more intelligent and capable of making decisions on their own. In the field of education, AI is also making significant progress. AI is being used to develop intelligent teaching assistants, such as chatbots. These assistants can provide students with the information they need to succeed in their studies. In the field of entertainment, AI is also making significant progress. AI is being used to develop intelligent entertainment systems, such as video games. These systems are becoming more intelligent and capable of making decisions on their own. In the field of security, AI is also making significant progress. AI is being used to develop intelligent security systems, such as facial recognition systems. In the field of agriculture, AI is also making significant progress. AI is being used to develop intelligent agricultural systems, such as drones. In the field of space exploration, AI is also making significant progress. AI is being used to develop intelligent space exploration systems, such as robots. In the field of defense, AI is also making significant progress. AI is being used to develop intelligent defense systems, such as drones.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Reinforcement learning algorithms learn optimal behaviors through \u001b[0m\u001b[91m the process of trial and error.\n",
      "The most important thing to remember is that the term “learning” is a bit of a misnomer.\n",
      "The term “learning” is a bit of a misnomer.\n",
      "The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer. The term “learning\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Reinforcement learning algorithms learn optimal behaviors through \u001b[0m\u001b[91mthe process of trial and error. The most important thing to remember is that the term “learning” is a bit of a misnomer. The term “learning” is a bit of a misnomer.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could \u001b[0m\u001b[91m potentially break the security of many cryptographic systems.\n",
      "However, there are several challenges to overcome before quantum computing becomes a reality. These include the need for more powerful hardware and the development of new algorithms.\n",
      "Despite these challenges, quantum computing is an exciting field of research that has the potential to change the way we think about computing.\n",
      "The Future of Quantum Computing: A Guide to the Future of Quantum Computing\n",
      "Quantum computing is a new and emerging field of study that is changing the way we think about computing. It is a form of computing that is based on the principles of quantum physics.\n",
      "Quantum computing is a new and emerging field of study that is changing the way we think about computing. It is a form of computing that is based on the principles of quantum physics. Quantum computing is a new and emerging field of study that is changing the way we think about computing. It is a form of computing that is based on the principles of quantum physics.\n",
      "Quantum computing is a new and emerging field of study that is changing the way we think about computing. It is a form of computing that is based on the principles of quantum physics. Quantum computing is a new and emerging field of study that is changing the way we think about computing. It is a form of computing that is based on the principles of quantum physics. Quantum computing is a new and emerging field of study that is changing the way we think about computing. It is a form of computing that is based on the principles of quantum physics. Quantum computing is a new and emerging field of study that is changing the way we think about computing. It is a form of computing that is based on the principles of quantum physics. Quantum computing is a new and emerging field of study that is changing the way we think about computing. It is a form of computing that is based on the principles of quantum physics. Quantum computing is a new and emerging field of study that is changing the way we think about computing. It is a form of computing that is based on the principles of quantum physics. Quantum computing is a new and emerging field of study that is changing the way we think about computing. It is a form of computing that is based on the principles of quantum physics. Quantum computing is a new and emerging field of study that is changing the way we think about computing. It is a form of computing that is based on the principles of quantum physics.\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could \u001b[0m\u001b[91mpotentially break the security of many cryptographic systems. However, there are several challenges to overcome before quantum computing becomes a reality. These include the need for more powerful hardware and the development of new algorithms. Despite these challenges, quantum computing is an exciting field of research that has the potential to change the way we think about computing. The Future of Quantum Computing: A Guide to the Future of Quantum Computing\n",
      "Quantum computing is a new and emerging field of study that is changing the way we think about computing. It is a form of computing that is based on the principles of quantum physics. Quantum computing is a new and emerging field of study that is changing the way we think about computing.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that \u001b[0m\u001b[91m can be used to improve our lives.\n",
      "The Future of AI: What to Expect\n",
      "The future of AI is a topic that has been the subject of much debate. Some believe that it will be a threat to humanity, while others believe that it will be a great benefit.\n",
      "The future of AI is a topic that has been the subject of much debate. Some believe that it will be a threat to humanity, while others believe that it will be a great benefit. The future of AI is also a topic that has been the subject of much debate. Some believe that it will be a threat to humanity, while others believe that it will be a great benefit.\n",
      "The future of AI is a topic that has been the subject of much debate. Some believe that it will be a threat to humanity, while others believe that it will be a great benefit. The future of AI is also a topic that has been the subject of much debate. Some believe that it will be a threat to humanity, while others believe that it will be a great benefit. The future of AI is a topic that has been the subject of much debate. Some believe that it will be a threat to humanity, while others believe that it will be a great benefit. The future of AI is a topic that has been the subject of much debate. Some believe that it will be a threat to humanity, while others believe that it will be a great benefit. The future of AI is a topic that has been the subject of much debate. Some believe that it will be a threat to humanity, while others believe that it will be a great benefit. The future of AI is a topic that has been the subject of much debate. Some believe that it will be a threat to humanity, while others believe that it will be a great benefit. The future of AI is a topic that has been the subject of much debate. Some believe that it will be a threat to humanity, while others believe that it will be a great benefit. The future of AI is a topic that has been the subject of much debate. Some believe that it will be a threat to humanity, while others believe that it will be a great benefit. The future of AI is a topic that has been the subject of much debate. Some believe that it will be a threat to humanity, while others believe that it will be a great benefit. The future of AI is a topic\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that \u001b[0m\u001b[91mcan be used to improve our lives. The Future of AI: What to Expect\n",
      "The future of AI is a topic that has been the subject of much debate. Some believe that it will be a threat to humanity, while others believe that it will be a great benefit. The future of AI is a topic that has been the subject of much debate. The future of AI is also a topic that has been the subject of much debate.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Transfer learning allows models trained on large datasets to be fine-tuned for specific tasks by \u001b[0m\u001b[91m using the model’s pre-trained parameters.\n",
      "\n",
      "\\subsection{Transferring knowledge from the source domain to the target}\n",
      "\n",
      "\\subsubsection{Knowledge distillation}\n",
      "\n",
      "Knowledge distillation (KD) is a technique that allows the transfer of knowledge from a large, well-trained model to a smaller, more efficient model. The goal of KD is to reduce the size of the model by using the parameters of the large model to train the smaller model.\n",
      "\n",
      "\\subsubsection{Supervised learning}\n",
      "\n",
      "Supervised learning is a technique that allows the transfer of knowledge from the source to the target. The goal of supervised learning is to use the parameters of the large model to train the smaller model.\n",
      "\n",
      "\\subsubsection{Unsupervised learning}\n",
      "\n",
      "Unsupervised learning is a technique that allows the transfer of knowledge from the source to the target. The goal of unsupervised learning is to use the parameters of the large model to train the smaller model.\n",
      "\n",
      "\\subsubsection{Inverse transfer learning}\n",
      "\n",
      "Inverse transfer learning is a technique that allows the transfer of knowledge from the target to the source. The goal of inverse transfer learning is to use the parameters of the smaller model to train the larger model.\n",
      "\n",
      "\\subsubsection{Transfer learning}\n",
      "\n",
      "Transfer learning is a technique that allows the transfer of knowledge from the source to the target. The goal of transfer learning is to use the parameters of the large model to train the smaller model.\n",
      "\n",
      "\\subsection{Transferring knowledge from the target to the source}\n",
      "\n",
      "\\subsubsection{Knowledge distillation}\n",
      "\n",
      "Knowledge distillation (KD) is a technique that allows the transfer of knowledge from the target to the source. The goal of KD is to reduce the size of the model by using the parameters of the large model to train the smaller model.\n",
      "\n",
      "\\subsubsection{Supervised learning}\n",
      "\n",
      "Supervised learning is a technique that allows the transfer of knowledge from the target to the source. The goal of supervised learning is to use the parameters of the large model to train the smaller model.\n",
      "\n",
      "\\subsubsection{Unsupervised learning}\n",
      "\n",
      "Unsupervised learning is a technique that allows the transfer of knowledge from the target to the source. The goal of unsupervised learning is to use the parameters of the large model to train the smaller model.\n",
      "\n",
      "\\subsubsection{Inverse transfer learning}\n",
      "\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Transfer learning allows models trained on large datasets to be fine-tuned for specific tasks by \u001b[0m\u001b[91musing the model’s pre-trained parameters. \\subsection{Transferring knowledge from the source domain to the target}\n",
      "\n",
      "\\subsubsection{Knowledge distillation}\n",
      "\n",
      "Knowledge distillation (KD) is a technique that allows the transfer of knowledge from a large, well-trained model to a smaller, more efficient model. The goal of KD is to reduce the size of the model by using the parameters of the large model to train the smaller model. \\subsubsection{Supervised learning}\n",
      "\n",
      "Supervised learning is a technique that allows the transfer of knowledge from the source to the target. The goal of supervised learning is to use the parameters of the large model to train the smaller model. \\subsubsection{Unsupervised learning}\n",
      "\n",
      "Unsupervised learning is a technique that allows the transfer of knowledge from the source to the target. The goal of unsupervised learning is to use the parameters of the large model to train the smaller model. \\subsubsection{Inverse transfer learning}\n",
      "\n",
      "Inverse transfer learning is a technique that allows the transfer of knowledge from the target to the source. The goal of inverse transfer learning is to use the parameters of the smaller model to train the larger model. \\subsubsection{Transfer learning}\n",
      "\n",
      "Transfer learning is a technique that allows the transfer of knowledge from the source to the target. The goal of transfer learning is to use the parameters of the large model to train the smaller model. \\subsection{Transferring knowledge from the target to the source}\n",
      "\n",
      "\\subsubsection{Knowledge distillation}\n",
      "\n",
      "Knowledge distillation (KD) is a technique that allows the transfer of knowledge from the target to the source. \\subsubsection{Supervised learning}\n",
      "\n",
      "Supervised learning is a technique that allows the transfer of knowledge from the target to the source. \\subsubsection{Unsupervised learning}\n",
      "\n",
      "Unsupervised learning is a technique that allows the transfer of knowledge from the target to the source.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Explainable AI (XAI) is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to \u001b[0m\u001b[91m increase transparency and trust.\n",
      "However, the implementation of XAI is not without its challenges. In this article, we will explore the challenges of implementing XAI and offer some solutions.\n",
      "The challenges of implementing XAI include:\n",
      "1. Data scarcity:\n",
      "Data scarcity is a major challenge in implementing XAI. Without sufficient data, it is difficult to obtain accurate results.\n",
      "2. Data imbalance:\n",
      "Data imbalance is another major challenge in implementing XAI. When one class of data is underrepresented, it becomes difficult to obtain accurate results.\n",
      "3. Data inconsistency:\n",
      "Data inconsistency is another major challenge in implementing XAI. When data is inconsistent, it becomes difficult to obtain accurate results.\n",
      "4. Data incompleteness:\n",
      "Data incompleteness is another major challenge in implementing XAI. When data is incomplete, it becomes difficult to obtain accurate results.\n",
      "5. Data uncertainty:\n",
      "Data uncertainty is another major challenge in implementing XAI. When data is uncertain, it becomes difficult to obtain accurate results.\n",
      "6. Data variability:\n",
      "Data variability is another major challenge in implementing XAI. When data is variable, it becomes difficult to obtain accurate results.\n",
      "7. Data variability:\n",
      "Data variability is another major challenge in implementing XAI. When data is variable, it becomes difficult to obtain accurate results.\n",
      "8. Data variability:\n",
      "Data variability is another major challenge in implementing XAI. When data is variable, it becomes difficult to obtain accurate results.\n",
      "9. Data variability:\n",
      "Data variability is another major challenge in implementing XAI. When data is variable, it becomes difficult to obtain accurate results.\n",
      "10. Data variability:\n",
      "Data variability is another major challenge in implementing XAI. When data is variable, it becomes difficult to obtain accurate results.\n",
      "11. Data variability:\n",
      "Data variability is another major challenge in implementing XAI. When data is variable, it becomes difficult to obtain accurate results.\n",
      "12. Data variability:\n",
      "Data variability is another major challenge in implementing XAI. When data is variable, it becomes difficult to obtain accurate results.\n",
      "13. Data variability:\n",
      "Data variability is another major challenge in implementing XAI. When data is variable, it becomes difficult to obtain accurate results.\n",
      "14. Data variability:\n",
      "Data variability is another major challenge\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Explainable AI (XAI) is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to \u001b[0m\u001b[91mincrease transparency and trust. However, the implementation of XAI is not without its challenges. In this article, we will explore the challenges of implementing XAI and offer some solutions. The challenges of implementing XAI include:\n",
      "1. Data scarcity:\n",
      "Data scarcity is a major challenge in implementing XAI. Without sufficient data, it is difficult to obtain accurate results. 2. Data imbalance:\n",
      "Data imbalance is another major challenge in implementing XAI. When one class of data is underrepresented, it becomes difficult to obtain accurate results. 3. Data inconsistency:\n",
      "Data inconsistency is another major challenge in implementing XAI. When data is inconsistent, it becomes difficult to obtain accurate results. 4. Data incompleteness:\n",
      "Data incompleteness is another major challenge in implementing XAI. When data is incomplete, it becomes difficult to obtain accurate results. 5. Data uncertainty:\n",
      "Data uncertainty is another major challenge in implementing XAI. When data is uncertain, it becomes difficult to obtain accurate results. 6. Data variability:\n",
      "Data variability is another major challenge in implementing XAI. When data is variable, it becomes difficult to obtain accurate results. 7. 8. 9. 10. 11. 12. 13. 14.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and \u001b[0m\u001b[91m the sun disappears.\n",
      "The best time to see the sunset is between 12:00 and 13:00.\n",
      "The best time to see the sunset is between 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12:00 and 13:00. The sun sets at 12\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and \u001b[0m\u001b[91mthe sun disappears. The best time to see the sunset is between 12:00 and 13:00. The sun sets at 12:00 and 13:00.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of \u001b[0m\u001b[91m their way of life.\n",
      "Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of their way of life.\n",
      "Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of their way of life.\n",
      "Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of their way of life.\n",
      "Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of their way of life.\n",
      "Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of their way of life.\n",
      "Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of their way of life.\n",
      "Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of their way of life.\n",
      "Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of their way of life.\n",
      "Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of their way of life.\n",
      "Traveling to new countries allows you to experience diverse cultures and traditions.\n",
      "Traveling to new countries allows you to experience diverse cultures and traditions. Walking through\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of \u001b[0m\u001b[91mtheir way of life. Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of their way of life.\u001b[0m\n",
      "\n",
      "\n",
      "Pruning model\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.475291136\n",
      "Model size after pruning:  13.475291136\n",
      "Model size after pruning:  13.473939456\n",
      "Model size after pruning:  13.473939456\n",
      "Model size after pruning:  13.472882688\n",
      "Model size after pruning:  13.472882688\n",
      "Model size after pruning:  13.46850816\n",
      "Model size after pruning:  13.46850816\n",
      "Model size after pruning:  13.462757376\n",
      "Model size after pruning:  13.462757376\n",
      "Model size after pruning:  13.461823488\n",
      "Model size after pruning:  13.461823488\n",
      "Model size after pruning:  13.460054016\n",
      "Model size after pruning:  13.460054016\n",
      "Model size after pruning:  13.45978368\n",
      "Model size after pruning:  13.45978368\n",
      "Model size after pruning:  13.457866752\n",
      "Model size after pruning:  13.457866752\n",
      "Model size after pruning:  13.423116288\n",
      "Model size after pruning:  13.381173248\n",
      "Model size after pruning:  13.300023296\n",
      "Model size after pruning:  13.258080256\n",
      "Model size after pruning:  13.176930304\n",
      "Model size after pruning:  13.134987264\n",
      "Model size after pruning:  13.053837312\n",
      "Model size after pruning:  13.011894272\n",
      "Model size after pruning:  12.93074432\n",
      "Model size after pruning:  12.88880128\n",
      "Model size after pruning:  12.807651328\n",
      "Model size after pruning:  12.765708288\n",
      "Model size after pruning:  12.684558336\n",
      "Model size after pruning:  12.642615296\n",
      "Model size after pruning:  12.561465344\n",
      "Model size after pruning:  12.519522304\n",
      "Model size after pruning:  12.438986752\n",
      "Model size after pruning:  12.397043712\n",
      "Model size after pruning:  12.318203904\n",
      "Model size after pruning:  12.276260864\n",
      "Model size after pruning:  12.196683776\n",
      "Model size after pruning:  12.154740736\n",
      "Model size after pruning:  12.075483136\n",
      "Model size after pruning:  12.033540096\n",
      "Model size after pruning:  11.95413504\n",
      "Model size after pruning:  11.912192\n",
      "Model size after pruning:  11.832860672\n",
      "Model size after pruning:  11.790917632\n",
      "Model size after pruning:  11.711537152\n",
      "Model size after pruning:  11.669594112\n",
      "Model size after pruning:  11.590262784\n",
      "Model size after pruning:  11.548319744\n",
      "Model size after pruning:  11.468939264\n",
      "Model size after pruning:  11.426996224\n",
      "Model size after pruning:  11.347664896\n",
      "Saving model after pruning to checkpoint dir\n",
      "Model saved\n",
      "Real Pruned Model\n",
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (4): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10945, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10945, bias=False)\n",
      "          (down_proj): Linear(in_features=10945, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (5): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10953, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10953, bias=False)\n",
      "          (down_proj): Linear(in_features=10953, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (6): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10965, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10965, bias=False)\n",
      "          (down_proj): Linear(in_features=10965, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (7): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10830, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10830, bias=False)\n",
      "          (down_proj): Linear(in_features=10830, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (8): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10774, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10774, bias=False)\n",
      "          (down_proj): Linear(in_features=10774, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (9): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10970, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10970, bias=False)\n",
      "          (down_proj): Linear(in_features=10970, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (10): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10936, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10936, bias=False)\n",
      "          (down_proj): Linear(in_features=10936, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (11): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10997, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10997, bias=False)\n",
      "          (down_proj): Linear(in_features=10997, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (12): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10930, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10930, bias=False)\n",
      "          (down_proj): Linear(in_features=10930, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (13): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=9594, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=9594, bias=False)\n",
      "          (down_proj): Linear(in_features=9594, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (14-20): 7 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7706, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7706, bias=False)\n",
      "          (down_proj): Linear(in_features=7706, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (21): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7731, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7731, bias=False)\n",
      "          (down_proj): Linear(in_features=7731, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (22): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7800, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7800, bias=False)\n",
      "          (down_proj): Linear(in_features=7800, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (23): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7770, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7770, bias=False)\n",
      "          (down_proj): Linear(in_features=7770, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (24): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7783, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7783, bias=False)\n",
      "          (down_proj): Linear(in_features=7783, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (25): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7777, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7777, bias=False)\n",
      "          (down_proj): Linear(in_features=7777, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (26): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
      "          (down_proj): Linear(in_features=7780, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (27): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7778, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7778, bias=False)\n",
      "          (down_proj): Linear(in_features=7778, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (28): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
      "          (down_proj): Linear(in_features=7780, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (29): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7778, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7778, bias=False)\n",
      "          (down_proj): Linear(in_features=7778, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (30): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
      "          (down_proj): Linear(in_features=7780, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (31): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n",
      "Real Pruned Model Size\n",
      "11.347664896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short Context: 18.720634692112867 tokens/sec, 516 tokens (including full prompt)\n",
      "Long Context: 47.54139760489992 tokens/sec, 1288 tokens (including full prompt)\n",
      "Average:  24.983545910972545 tokens/sec\n",
      "***************   Experiment completed successfully Successfully   ***************\n"
     ]
    }
   ],
   "source": [
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cda6423e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T03:56:01.403806Z",
     "start_time": "2024-06-11T03:56:01.397261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5673828352"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad149c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9d65f8f",
   "metadata": {},
   "source": [
    "## Pr=0.7, lb=0.6, lb=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82cfe0be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T03:56:51.182731Z",
     "start_time": "2024-06-11T03:56:51.179400Z"
    }
   },
   "outputs": [],
   "source": [
    "pruning_dict = \"pruning_dict_1.0_0.6_1.0_chat_2641.json\"\n",
    "save_dir = \"/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/\"\n",
    "\n",
    "p = pruning_dict.split(\"_\")[-1].split(\".\")[-2]\n",
    "output_dir = \"/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints//\" + p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aacf485a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T03:56:51.558036Z",
     "start_time": "2024-06-11T03:56:51.554823Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment = ExperimentRunner(pipeline, tokenizer, pruning_dict, \n",
    "                 save_dir=save_dir, output_dir=output_dir, ignored_layers=None, \n",
    "                 use_template=use_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6414e0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:23:58.104594Z",
     "start_time": "2024-06-11T03:56:52.044744Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************   Running Experiment   ***************\n",
      "61 ==>  3968\n",
      "67 ==>  10990\n",
      "75 ==>  4096\n",
      "81 ==>  10864\n",
      "89 ==>  4096\n",
      "95 ==>  10953\n",
      "103 ==>  4096\n",
      "109 ==>  10921\n",
      "117 ==>  3968\n",
      "123 ==>  10946\n",
      "131 ==>  4096\n",
      "137 ==>  10589\n",
      "145 ==>  4096\n",
      "151 ==>  10971\n",
      "159 ==>  3456\n",
      "165 ==>  7790\n",
      "173 ==>  2432\n",
      "179 ==>  6605\n",
      "187 ==>  2432\n",
      "193 ==>  6605\n",
      "201 ==>  2432\n",
      "207 ==>  6605\n",
      "215 ==>  2432\n",
      "221 ==>  6605\n",
      "229 ==>  2432\n",
      "235 ==>  6605\n",
      "243 ==>  2432\n",
      "249 ==>  6605\n",
      "257 ==>  2432\n",
      "263 ==>  6605\n",
      "271 ==>  2432\n",
      "277 ==>  6605\n",
      "285 ==>  2432\n",
      "291 ==>  6605\n",
      "299 ==>  2432\n",
      "305 ==>  6605\n",
      "313 ==>  2432\n",
      "319 ==>  6605\n",
      "327 ==>  2432\n",
      "333 ==>  6605\n",
      "341 ==>  2432\n",
      "347 ==>  6606\n",
      "355 ==>  2432\n",
      "361 ==>  6666\n",
      "369 ==>  2432\n",
      "375 ==>  6625\n",
      "383 ==>  2432\n",
      "389 ==>  6652\n",
      "397 ==>  2432\n",
      "403 ==>  6635\n",
      "411 ==>  2432\n",
      "417 ==>  6646\n",
      "425 ==>  2432\n",
      "431 ==>  6638\n",
      "***************   Pruning Model   ***************\n",
      "Pruning model\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Saving model after pruning to checkpoint dir\n",
      "Model saved\n",
      "***************   Model Pruned Successfully   ***************\n",
      "Model Size after Pruning:  13.476839424\n",
      "evaluating on wikitext2\n",
      "nsamples 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:   0%|                                                                                 | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WikiText Validation:   8%|█████▊                                                                   | 2/25 [00:01<00:11,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  12%|████████▊                                                                | 3/25 [00:01<00:10,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  16%|███████████▋                                                             | 4/25 [00:02<00:09,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  20%|██████████████▌                                                          | 5/25 [00:02<00:08,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  24%|█████████████████▌                                                       | 6/25 [00:02<00:08,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  28%|████████████████████▍                                                    | 7/25 [00:03<00:07,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  32%|███████████████████████▎                                                 | 8/25 [00:03<00:07,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  36%|██████████████████████████▎                                              | 9/25 [00:04<00:06,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  40%|████████████████████████████▊                                           | 10/25 [00:04<00:06,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  44%|███████████████████████████████▋                                        | 11/25 [00:04<00:05,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  48%|██████████████████████████████████▌                                     | 12/25 [00:05<00:05,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  52%|█████████████████████████████████████▍                                  | 13/25 [00:05<00:04,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  56%|████████████████████████████████████████▎                               | 14/25 [00:06<00:04,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  60%|███████████████████████████████████████████▏                            | 15/25 [00:06<00:04,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  64%|██████████████████████████████████████████████                          | 16/25 [00:06<00:03,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  68%|████████████████████████████████████████████████▉                       | 17/25 [00:07<00:03,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  72%|███████████████████████████████████████████████████▊                    | 18/25 [00:07<00:02,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  76%|██████████████████████████████████████████████████████▋                 | 19/25 [00:08<00:02,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  80%|█████████████████████████████████████████████████████████▌              | 20/25 [00:08<00:02,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  84%|████████████████████████████████████████████████████████████▍           | 21/25 [00:09<00:01,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  88%|███████████████████████████████████████████████████████████████▎        | 22/25 [00:09<00:01,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  92%|██████████████████████████████████████████████████████████████████▏     | 23/25 [00:09<00:00,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  96%|█████████████████████████████████████████████████████████████████████   | 24/25 [00:10<00:00,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WikiText Validation: 100%|████████████████████████████████████████████████████████████████████████| 25/25 [00:10<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPL:  11.052111625671387\n",
      "Perplexity on wikitext2:  11.052111625671387\n",
      "Loading checkpoint from /data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/\n",
      "Model passed to evaluation:  LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11:09:30:25,308 WARNING  [task.py:763] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-06-11:09:30:25,310 WARNING  [task.py:775] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2024-06-11:09:31:01,835 WARNING  [task.py:763] [Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-06-11:09:31:01,836 WARNING  [task.py:775] [Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for winogrande contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/winogrande\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2024-06-11:09:34:34,248 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-06-11:09:34:34,250 INFO     [evaluator.py:177] Initializing huggingface model, with arguments: {'pretrained': '/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/'}\n",
      "2024-06-11:09:34:34,270 WARNING  [logging.py:61] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "2024-06-11:09:34:34,271 INFO     [huggingface.py:163] Using device 'cuda'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e43820378b45e489dd1d8efda4a515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11:09:35:24,428 WARNING  [task.py:763] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-06-11:09:35:24,430 WARNING  [task.py:775] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-06-11:09:36:35,181 WARNING  [task.py:763] [Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-06-11:09:36:35,183 WARNING  [task.py:775] [Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-06-11:09:38:50,410 WARNING  [evaluator.py:239] Overwriting default num_fewshot of arc_challenge from None to 0\n",
      "2024-06-11:09:38:50,411 WARNING  [evaluator.py:239] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2024-06-11:09:38:50,412 WARNING  [evaluator.py:239] Overwriting default num_fewshot of openbookqa from None to 0\n",
      "2024-06-11:09:38:50,412 WARNING  [evaluator.py:239] Overwriting default num_fewshot of rte from None to 0\n",
      "2024-06-11:09:38:50,413 WARNING  [evaluator.py:239] Overwriting default num_fewshot of arc_easy from None to 0\n",
      "2024-06-11:09:38:50,414 WARNING  [evaluator.py:239] Overwriting default num_fewshot of boolq from None to 0\n",
      "2024-06-11:09:38:50,414 WARNING  [evaluator.py:239] Overwriting default num_fewshot of winogrande from None to 0\n",
      "2024-06-11:09:38:50,419 INFO     [task.py:395] Building contexts for arc_challenge on rank 0...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 124.57it/s]\n",
      "2024-06-11:09:38:51,235 INFO     [task.py:395] Building contexts for hellaswag on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1861.33it/s]\n",
      "2024-06-11:09:38:51,319 INFO     [task.py:395] Building contexts for openbookqa on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1414.49it/s]\n",
      "2024-06-11:09:38:51,433 INFO     [task.py:395] Building contexts for rte on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1429.18it/s]\n",
      "2024-06-11:09:38:51,515 INFO     [task.py:395] Building contexts for arc_easy on rank 0...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 876.71it/s]\n",
      "2024-06-11:09:38:51,643 INFO     [task.py:395] Building contexts for boolq on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1590.29it/s]\n",
      "2024-06-11:09:38:51,714 INFO     [task.py:395] Building contexts for winogrande on rank 0...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 64786.90it/s]\n",
      "2024-06-11:09:38:51,723 INFO     [evaluator.py:379] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|█████████████████████████████████████████████████████████| 2199/2199 [01:44<00:00, 21.09it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "fatal: not a git repository (or any parent up to mount point /)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "|     Alias     | Acc, None |   Acc StdErr, None   | Acc Norm, None | Acc Norm StdErr, None |\n",
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "| arc_challenge |    0.29   | 0.045604802157206845 |      0.38      |  0.04878317312145632  |\n",
      "|   hellaswag   |    0.47   | 0.05016135580465919  |      0.65      |   0.0479372485441102  |\n",
      "|   openbookqa  |    0.18   | 0.03861229196653694  |      0.35      |  0.047937248544110196 |\n",
      "|      rte      |    0.49   | 0.05024183937956912  |      None      |          None         |\n",
      "|    arc_easy   |    0.58   | 0.049604496374885836 |      0.53      |  0.050161355804659205 |\n",
      "|     boolq     |    0.72   | 0.04512608598542127  |      None      |          None         |\n",
      "|   winogrande  |    0.62   | 0.04878317312145633  |      None      |          None         |\n",
      "+---------------+-----------+----------------------+----------------+-----------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Gardening provides a sense of accomplishment and tranquility, as you nurture plants and watch them \u001b[0m\u001b[91m grow.\n",
      "The benefits of gardening include a range of physical and mental benefits.\n",
      "Gardening can have a positive impact on mental health.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a number of ways.\n",
      "Gardening can have a positive impact on mental health in a\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Gardening provides a sense of accomplishment and tranquility, as you nurture plants and watch them \u001b[0m\u001b[91mgrow. The benefits of gardening include a range of physical and mental benefits. Gardening can have a positive impact on mental health. Gardening can have a positive impact on mental health in a number of ways.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Family traditions are passed down from generation to generation, creating a sense of continuity and belonging. Whether it's holiday celebrations, special recipes, or annual gatherings, these traditions foster \u001b[0m\u001b[91m a feeling of connection and provide a way to connect with the past.\n",
      "Overall, the importance of family traditions in the world of media and communication can provide a sense of stability and stability, and can bring a sense of connection to the world.\n",
      "The importance of family traditions in media and communication can provide a sense of stability and security, and can bring a sense of connection to the world.\n",
      "The importance of family traditions in media and communication can provide a sense of continuity and can create a feeling of belonging.\n",
      "The importance of family traditions in media and communication can provide a sense of connection to the world.\n",
      "The importance of family traditions in media and communication can provide a sense of continuity and can create a feeling of belonging.\n",
      "The importance of family traditions in media and communication can provide a sense of connection to the world.\n",
      "The importance of family traditions in media and communication can provide a sense of continuity and can create a feeling of belonging.\n",
      "The importance of family traditions in media and communication can provide a sense of connection to the world.\n",
      "The importance of family traditions in media and communication can provide a sense of continuity and can create a feeling of belonging.\n",
      "The importance of family traditions in media and communication can provide a sense of connection to the world.\n",
      "The importance of family traditions in media and communication can provide a sense of continuity and can create a feeling of belonging.\n",
      "The importance of family traditions in media and communication can provide a sense of connection to the world.\n",
      "The importance of family traditions in media and communication can provide a sense of continuity and can create a feeling of belonging.\n",
      "The importance of family trends in media and communication can provide a sense of connection to the world.\n",
      "The importance of family trends in media and communication can provide a sense of continuity and can create a feeling of belonging.\n",
      "The importance of family trends in media and communication can provide a sense of connection to the world.\n",
      "The importance of family trends in media and communication can provide a sense of continuity and can create a feeling of belonging.\n",
      "The importance of family trends in media and communication can provide a sense of connection to the world.\n",
      "The importance of family trends in media and communication can provide a sense of continuity and can create a feeling of belonging.\n",
      "The importance of family trends in media and communication can provide a sense of connection to the world.\n",
      "The importance of family trends\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Family traditions are passed down from generation to generation, creating a sense of continuity and belonging. Whether it's holiday celebrations, special recipes, or annual gatherings, these traditions foster \u001b[0m\u001b[91ma feeling of connection and provide a way to connect with the past. Overall, the importance of family traditions in the world of media and communication can provide a sense of stability and stability, and can bring a sense of connection to the world. The importance of family traditions in media and communication can provide a sense of stability and security, and can bring a sense of connection to the world. The importance of family traditions in media and communication can provide a sense of continuity and can create a feeling of belonging. The importance of family traditions in media and communication can provide a sense of connection to the world. The importance of family trends in media and communication can provide a sense of connection to the world. The importance of family trends in media and communication can provide a sense of continuity and can create a feeling of belonging.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future \u001b[0m\u001b[91m, fashion will continue to evolve, bringing with it new opportunities for creativity and innovation, and shaping our world through its influence on culture and society.\n",
      "A few of the examples of such websites are listed below:\n",
      "1. The New York Times:\n",
      "The New York Times is a website that offers a range of to provide, such, such as.\n",
      "The:, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future \u001b[0m\u001b[91m, fashion will continue to evolve, bringing with it new opportunities for creativity and innovation, and shaping our world through its influence on culture and society. A few of the examples of such websites are listed below:\n",
      "1. The New York Times:\n",
      "The New York Times is a website that offers a range of to provide, such, such as.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Artificial intelligence is transforming the healthcare industry by enabling \u001b[0m\u001b[91m it to become more efficient and effective.\n",
      "AI is being used to analyze and analyze data to identify patterns and predictive of the future. This can help in identifying the best ways to treat and prevent disease.\n",
      "One of the most significant benefits of using AI in healthcare is the ability to detect and detect the disease. This can help in identifying the best ways to treat and prevent.\n",
      "This can help in saving the cost of treatment.\n",
      "The use of AI in healthcare can also help in the detection of the disease. This can help in the detection of the disease.\n",
      "This can help in the detection of the disease. This can help in the detection of the disease.\n",
      "The use of A AI in healthcare can also help in the detection of the disease. This can help in the detection of the disease.\n",
      "The use of A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Artificial intelligence is transforming the healthcare industry by enabling \u001b[0m\u001b[91mit to become more efficient and effective. AI is being used to analyze and analyze data to identify patterns and predictive of the future. This can help in identifying the best ways to treat and prevent disease. One of the most significant benefits of using AI in healthcare is the ability to detect and detect the disease. This can help in identifying the best ways to treat and prevent. This can help in saving the cost of treatment. The use of AI in healthcare can also help in the detection of the disease. This can help in the detection of the disease. The use of A AI in healthcare can also help in the detection of the disease.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Machine learning algorithms are increasingly being used to predict stock market trends. By analyzing historical data and identifying patterns, these models can \u001b[0m\u001b[91m help to provide a better understanding of the factors that can affect and can help to provide a better understanding of the factors that can help to provide a.\n",
      "The.\n",
      "The world is constantly changing and\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly changing and the.\n",
      "The world is constantly\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Machine learning algorithms are increasingly being used to predict stock market trends. By analyzing historical data and identifying patterns, these models can \u001b[0m\u001b[91mhelp to provide a better understanding of the factors that can affect and can help to provide a better understanding of the factors that can help to provide a. The. The world is constantly changing and\n",
      "The world is constantly changing and the. The world is constantly changing and the\n",
      "The world is constantly changing and the. The world is constantly changing and the.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The integration of natural language processing with machine learning has opened up new possibilities in human-computer interaction. For instance, chatbots powered by sophisticated NLP algorithms can now understand and respond to user queries with remarkable accuracy. As these technologies continue to evolve, we can expect that \u001b[0m\u001b[91m they will play a significant role in shaping the future of communication and collaboration.\n",
      "The power of AI: A comprehensive guide to understanding the impact of technology\n",
      "The AOI is a comprehacious, and the understanding of the impact of technology on AOI.\n",
      "AOI is a comprehacious, and the understanding of the impact of technology on AOI.\n",
      "AOI is a comprehacious, and the understanding of the impact of technology on AOI.\n",
      "AOI is a comprehacious, and the understanding of the impact of technology on AOI. AOI is a comprehacious, and the understanding of the impact of technology on AOI.\n",
      "AOI is a comprehacious, and the understanding of the impact of technology on AOI. AOI is a comprehacious, and the understanding of the impact of technology on AOI. AOI is a comprehacious, and the understanding of the impact of technology on AOI. AOI is a comprehacious, and the understanding of the impact of technology on AOI. AOI is a comprehacious, and the understanding of the impact of technology on AOI. AOI is a comprehacious, and the understanding of the impact of technology on AOI. AOI is a comprehacious, and the understanding of the impact of technology on AOI. AOI is a comprehacious, and the understanding of the impact of technology on AOI. AOI is a comprehacious, and the understanding of the impact of technology on AOI. AOI is a comprehacious, and the understanding of the impact of technology on AOI. AOI is a comprehacious, and the understanding of the impact of technology on AOI. AOI is a comprehacious, and the understanding of the impact of technology on AOI. AOI is a comprehacious, and the understanding of the impact of technology on AOI. AOI is a comprehacious, and the understanding of the impact of technology on AOI. AOI is a comprehacious, and the understanding of the impact of technology on AOI. AOI is a comprehacious, and the understanding of the impact of technology on AOI. AOI is a comprehacious, and the\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The integration of natural language processing with machine learning has opened up new possibilities in human-computer interaction. For instance, chatbots powered by sophisticated NLP algorithms can now understand and respond to user queries with remarkable accuracy. As these technologies continue to evolve, we can expect that \u001b[0m\u001b[91mthey will play a significant role in shaping the future of communication and collaboration. The power of AI: A comprehensive guide to understanding the impact of technology\n",
      "The AOI is a comprehacious, and the understanding of the impact of technology on AOI. AOI is a comprehacious, and the understanding of the impact of technology on AOI.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Self-driving cars rely heavily on sensor data and advanced algorithms to navigate \u001b[0m\u001b[91m the world.\n",
      "Their ability to drive safely and safely is largely dependent on the quality of the sensor data.\n",
      "The sensor data is collected by the sensor data collection process.\n",
      "The sensor data collection process is the process of collecting sensor data from the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\n",
      "The sensor data collection process is the sensor data collection process.\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Self-driving cars rely heavily on sensor data and advanced algorithms to navigate \u001b[0m\u001b[91mthe world. Their ability to drive safely and safely is largely dependent on the quality of the sensor data. The sensor data is collected by the sensor data collection process. The sensor data collection process is the process of collecting sensor data from the sensor data collection process. The sensor data collection process is the sensor data collection process.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m One of the biggest challenges in developing AI systems is ensuring they are ethical and unbiased. Researchers are working on creating frameworks that can \u001b[0m\u001b[91m identify and address the potential impact of AI on society.\n",
      "Overall, AI can provide a range of benefits for businesses, but it requires careful consideration and respect for the human aspects of life.\n",
      "The Future of AI:\n",
      "The future of AI is a world where we can use technology to help us make better decisions, and to provide us with the tools to achieve our goals.\n",
      "AOI is a powerful tool that can help us to understand the world and to make better decisions.\n",
      "AOI is a way to help us to understand the world and to make better decisions.\n",
      "AOI is a way to help us to understand the world and to make better decisions.\n",
      "AOI is a way to help us to understand the world and to make better decisions.\n",
      "AOI is a way to help us to understand the world and to make better decisions.\n",
      "AOI is a way to help us to understand the world and to make better decisions.\n",
      "AOI is a way to help us to understand the world and to make better decisions.\n",
      "AOI is a way to help us to understand the world and to make better decisions.\n",
      "AOI is a way to help us to understand the world and to make better decisions.\n",
      "AOI is a way to help us to understand the world and to make better decisions.\n",
      "AOI is a way to help us to understand the world and to make better decisions.\n",
      "AOI is a way to help us to understand the world and to make better decisions.\n",
      "AOI is a way to help us to understand the world and to make better decisions.\n",
      "AOI is a way to help us to understand the world and to make better decisions.\n",
      "AOI is a way to help us to understand the world and to make better decisions.\n",
      "AOI is a way to help us to understand the world and to make better decisions.\n",
      "AOI is a way to help us to understand the world and to make better decisions.\n",
      "AOI is a way to help us to understand the world and to make better decisions.\n",
      "AOI is a way to help us to understand the world and to make better decisions.\n",
      "AOI is a way to help us to understand the world and to make better decisions.\n",
      "AOI is a way\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m One of the biggest challenges in developing AI systems is ensuring they are ethical and unbiased. Researchers are working on creating frameworks that can \u001b[0m\u001b[91midentify and address the potential impact of AI on society. Overall, AI can provide a range of benefits for businesses, but it requires careful consideration and respect for the human aspects of life. The Future of AI:\n",
      "The future of AI is a world where we can use technology to help us make better decisions, and to provide us with the tools to achieve our goals. AOI is a powerful tool that can help us to understand the world and to make better decisions. AOI is a way to help us to understand the world and to make better decisions.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m In the field of computer vision, convolutional neural networks have revolutionized the way machines perceive visual information. By mimicking the human visual system, these networks can classify images, detect objects, and even perform image segmentation. This has significant applications in areas such as medical imaging, where AI can assist doctors in diagnosing conditions from X-rays and MRIs. As the technology advances, we may soon see AI systems that \u001b[0m\u001b[91m can truly understand the world around us, providing us with the tools to shape our future.\n",
      "The power of AI: A comprehensive guide to understanding the world of technology\n",
      "The A: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The: The::: The: The:::::: The: The: The::::: The:::::::::::: The:::::: The::::::::::::::::::::::::::::: The:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m In the field of computer vision, convolutional neural networks have revolutionized the way machines perceive visual information. By mimicking the human visual system, these networks can classify images, detect objects, and even perform image segmentation. This has significant applications in areas such as medical imaging, where AI can assist doctors in diagnosing conditions from X-rays and MRIs. As the technology advances, we may soon see AI systems that \u001b[0m\u001b[91mcan truly understand the world around us, providing us with the tools to shape our future.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Reinforcement learning algorithms learn optimal behaviors through \u001b[0m\u001b[91m the process of rewards and punishment.\n",
      "Their goal is to predict the future.\n",
      "Their goal is to predict the future. They are not designed to be used in the same way.\n",
      "Their goal is to predict the future. They are not designed to be used in the same way. They are not designed to be used in the same way.\n",
      "Their goal is to predict the future. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way.\n",
      "Their goal is to predict the future. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the same way. They are not designed to be used in the\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Reinforcement learning algorithms learn optimal behaviors through \u001b[0m\u001b[91mthe process of rewards and punishment. Their goal is to predict the future. They are not designed to be used in the same way.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could \u001b[0m\u001b[91m provide a new level of security.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The ability to solve problems quickly and efficiently is a key to the success of quantum computing.\n",
      "The impact of quantum computing on the world of cryptography is a real threat to the security of our digital.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The impact of quantum computing on the world of cryptography is a real threat to the security of our digital.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a real threat to the security of our digital world.\n",
      "The challenge of quantum computing is a\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could \u001b[0m\u001b[91mprovide a new level of security. The challenge of quantum computing is a real threat to the security of our digital world. The ability to solve problems quickly and efficiently is a key to the success of quantum computing. The impact of quantum computing on the world of cryptography is a real threat to the security of our digital.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that \u001b[0m\u001b[91m can bring even greater benefits to the world.\n",
      "Previous ArticleThe Power of AI:\n",
      "The A:\n",
      "Over...\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that \u001b[0m\u001b[91mcan bring even greater benefits to the world. Previous ArticleThe Power of AI:\n",
      "The A:\n",
      "Over.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Transfer learning allows models trained on large datasets to be fine-tuned for specific tasks by \u001b[0m\u001b[91m using a few examples.\n",
      "\n",
      "\\begin{figure}[t]\n",
      "\\centering\n",
      "\\includegraphics[width=0{.9\\textwidth}]{figures/overview_v2.png}\n",
      "\\caption{Overview of the proposed method.}\n",
      "\\label{fig:overview}\n",
      "\\end{figure\n",
      "\n",
      "\\section{Proposed method}\n",
      "\n",
      "\\subsection{Motivation}\n",
      "\n",
      "\\subsubsection{Motivation 1: The importance of the dataset}\n",
      "\n",
      "The first motivation is that the dataset is the most important factor in the field of computer vision.\n",
      "\n",
      "\\subsubsection{Motivation 2: The importance of the dataset}\n",
      "\n",
      "The second motivation is that the dataset is the most important factor in the field of computer vision.\n",
      "\n",
      "\\subsubsection{M\n",
      "\n",
      "The third motivation is that the dataset is the most important factor in the field of computer vision.\n",
      "\n",
      "\\end{document}\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Transfer learning allows models trained on large datasets to be fine-tuned for specific tasks by \u001b[0m\u001b[91musing a few examples. \\begin{figure}[t]\n",
      "\\centering\n",
      "\\includegraphics[width=0{. 9\\textwidth}]{figures/overview_v2. png}\n",
      "\\caption{Overview of the proposed method. }\n",
      "\\label{fig:overview}\n",
      "\\end{figure\n",
      "\n",
      "\\section{Proposed method}\n",
      "\n",
      "\\subsection{Motivation}\n",
      "\n",
      "\\subsubsection{Motivation 1: The importance of the dataset}\n",
      "\n",
      "The first motivation is that the dataset is the most important factor in the field of computer vision. \\subsubsection{Motivation 2: The importance of the dataset}\n",
      "\n",
      "The second motivation is that the dataset is the most important factor in the field of computer vision. \\subsubsection{M\n",
      "\n",
      "The third motivation is that the dataset is the most important factor in the field of computer vision.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Explainable AI (XAI) is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to \u001b[0m\u001b[91m help users understand the limitations of AI and make it easier for them to adjust to the changes brought by AI.\n",
      "The benefits of AI are becoming increasingly apparent, and they are being used in a wide range of industries. As AI continues to evolve, it will become more important for us to understand the limitations of AI and to be able to adjust to the changes brought by AE.\n",
      "The benefits of AI are becoming increasingly apparent, and they are being used in a wide range of industries. As AI continues to evolve, it will become more important for us to understand the limitations of AI and to be able to adjust to the changes brought by AE.\n",
      "The benefits of AI are becoming increasingly apparent, and they are being used in a wide range of industries. As AI continues to evolve, it will become more important for us to understand the limitations of AI and to be able to adjust to the changes brought by AE.\n",
      "The benefits of AI are becoming increasingly apparent, and they are being used in a wide range of industries. As AI continues to evolve, it will become more important for us to understand the limitations of AI and to be able to adjust to the changes brought by AE.\n",
      "The benefits of AI are becoming increasingly apparent, and they are being used in a wide range of industries. As AI continues to evolve, it will become more important for us to understand the limitations of AI and to be able to adjust to the changes brought by AE.\n",
      "The benefits of AI are becoming increasingly apparent, and they are being used in a wide range of industries. As AI continues to evolve, it will become more important for us to understand the limitations of AI and to be able to adjust to the changes brought by AE.\n",
      "The benefits of AI are becoming increasingly apparent, and they are being used in a wide range of industries. As AI continues to evolve, it will become more important for us to understand the limitations of AI and to be able to adjust to the changes brought by AE.\n",
      "The benefits of AI are becoming increasingly apparent, and they are being used in a wide range of industries. As AI continues to evolve, it will become more important for us to understand the limitations of AI and to be able to adjust to the changes brought by AE.\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Explainable AI (XAI) is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to \u001b[0m\u001b[91mhelp users understand the limitations of AI and make it easier for them to adjust to the changes brought by AI. The benefits of AI are becoming increasingly apparent, and they are being used in a wide range of industries. As AI continues to evolve, it will become more important for us to understand the limitations of AI and to be able to adjust to the changes brought by AE.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and \u001b[0m\u001b[91m the sun begins to set.\n",
      "The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and the sun begins to set.\n",
      "The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and the sun begins to set.\n",
      "The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and the sun begins to set.\n",
      "The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and the sun begins to set.\n",
      "The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and the sun begins to set.\n",
      "The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and the sun begins to set.\n",
      "The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and the sun begins to set.\n",
      "The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and the sun begins to set.\n",
      "The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and the sun begins to set.\n",
      "The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and the sun begins to set.\n",
      "The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and the sun begins to set.\n",
      "The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and the sun begins to set.\n",
      "The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and the sun begins to set.\n",
      "The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and the sun begins to set.\n",
      "The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and the sun\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and \u001b[0m\u001b[91mthe sun begins to set. The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and the sun begins to set.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of \u001b[0m\u001b[91m the world’s diversity.\n",
      "Overall, traveling to new countries can offer a range of benefits, from cultural, to social, to economic, to physical health.\n",
      "What are the benefits of traveling to new countries?\n",
      "What can traveling to new countries offer?\n",
      "What can traveling to new countries provide?\n",
      "What can traveling to new countries offer\n",
      "What can traveling to new countries provide\n",
      "What can traveling to new countries offer\n",
      "What can traveling to new countries provide\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of \u001b[0m\u001b[91mthe world’s diversity. Overall, traveling to new countries can offer a range of benefits, from cultural, to social, to economic, to physical health.\u001b[0m\n",
      "\n",
      "\n",
      "Pruning model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size after pruning:  13.47264512\n",
      "Model size after pruning:  13.472202752\n",
      "Model size after pruning:  13.472202752\n",
      "Model size after pruning:  13.468663808\n",
      "Model size after pruning:  13.468663808\n",
      "Model size after pruning:  13.467312128\n",
      "Model size after pruning:  13.467312128\n",
      "Model size after pruning:  13.465174016\n",
      "Model size after pruning:  13.460979712\n",
      "Model size after pruning:  13.459456\n",
      "Model size after pruning:  13.459456\n",
      "Model size after pruning:  13.449158656\n",
      "Model size after pruning:  13.449158656\n",
      "Model size after pruning:  13.448249344\n",
      "Model size after pruning:  13.427277824\n",
      "Model size after pruning:  13.348192256\n",
      "Model size after pruning:  13.293666304\n",
      "Model size after pruning:  13.185458176\n",
      "Model size after pruning:  13.130932224\n",
      "Model size after pruning:  13.022724096\n",
      "Model size after pruning:  12.968198144\n",
      "Model size after pruning:  12.859990016\n",
      "Model size after pruning:  12.805464064\n",
      "Model size after pruning:  12.697255936\n",
      "Model size after pruning:  12.642729984\n",
      "Model size after pruning:  12.534521856\n",
      "Model size after pruning:  12.479995904\n",
      "Model size after pruning:  12.371787776\n",
      "Model size after pruning:  12.317261824\n",
      "Model size after pruning:  12.209053696\n",
      "Model size after pruning:  12.154527744\n",
      "Model size after pruning:  12.046319616\n",
      "Model size after pruning:  11.991793664\n",
      "Model size after pruning:  11.883585536\n",
      "Model size after pruning:  11.829059584\n",
      "Model size after pruning:  11.720851456\n",
      "Model size after pruning:  11.666325504\n",
      "Model size after pruning:  11.558117376\n",
      "Model size after pruning:  11.503591424\n",
      "Model size after pruning:  11.395383296\n",
      "Model size after pruning:  11.340857344\n",
      "Model size after pruning:  11.232673792\n",
      "Model size after pruning:  11.17814784\n",
      "Model size after pruning:  11.071438848\n",
      "Model size after pruning:  11.016912896\n",
      "Model size after pruning:  10.909196288\n",
      "Model size after pruning:  10.854670336\n",
      "Model size after pruning:  10.74761728\n",
      "Model size after pruning:  10.693091328\n",
      "Model size after pruning:  10.58562048\n",
      "Model size after pruning:  10.531094528\n",
      "Model size after pruning:  10.423894016\n",
      "Model size after pruning:  10.369368064\n",
      "Model size after pruning:  10.261970944\n",
      "Saving model after pruning to checkpoint dir\n",
      "Model saved\n",
      "Real Pruned Model\n",
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (4): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (o_proj): Linear(in_features=3968, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10990, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10990, bias=False)\n",
      "          (down_proj): Linear(in_features=10990, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (5): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10864, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10864, bias=False)\n",
      "          (down_proj): Linear(in_features=10864, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (6): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10953, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10953, bias=False)\n",
      "          (down_proj): Linear(in_features=10953, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (7): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10921, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10921, bias=False)\n",
      "          (down_proj): Linear(in_features=10921, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (8): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (o_proj): Linear(in_features=3968, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10946, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10946, bias=False)\n",
      "          (down_proj): Linear(in_features=10946, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (9): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10589, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10589, bias=False)\n",
      "          (down_proj): Linear(in_features=10589, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (10): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10971, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10971, bias=False)\n",
      "          (down_proj): Linear(in_features=10971, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (11): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3456, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3456, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3456, bias=False)\n",
      "          (o_proj): Linear(in_features=3456, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7790, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7790, bias=False)\n",
      "          (down_proj): Linear(in_features=7790, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (12-23): 12 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (o_proj): Linear(in_features=2432, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=6605, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=6605, bias=False)\n",
      "          (down_proj): Linear(in_features=6605, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (24): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (o_proj): Linear(in_features=2432, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=6606, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=6606, bias=False)\n",
      "          (down_proj): Linear(in_features=6606, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (25): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (o_proj): Linear(in_features=2432, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=6666, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=6666, bias=False)\n",
      "          (down_proj): Linear(in_features=6666, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (26): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (o_proj): Linear(in_features=2432, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=6625, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=6625, bias=False)\n",
      "          (down_proj): Linear(in_features=6625, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (27): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (o_proj): Linear(in_features=2432, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=6652, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=6652, bias=False)\n",
      "          (down_proj): Linear(in_features=6652, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (28): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (o_proj): Linear(in_features=2432, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=6635, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=6635, bias=False)\n",
      "          (down_proj): Linear(in_features=6635, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (29): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (o_proj): Linear(in_features=2432, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=6646, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=6646, bias=False)\n",
      "          (down_proj): Linear(in_features=6646, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (30): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (o_proj): Linear(in_features=2432, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=6638, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=6638, bias=False)\n",
      "          (down_proj): Linear(in_features=6638, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (31): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n",
      "Real Pruned Model Size\n",
      "10.261970944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short Context: 19.266940263982573 tokens/sec, 362 tokens (including full prompt)\n",
      "Long Context: 50.05337300840934 tokens/sec, 1288 tokens (including full prompt)\n",
      "Average:  45.906952071512855 tokens/sec\n",
      "***************   Experiment completed successfully Successfully   ***************\n"
     ]
    }
   ],
   "source": [
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "becd68ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:23:58.116119Z",
     "start_time": "2024-06-11T04:23:58.108725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5130981376"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c30945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4aa0b3ff",
   "metadata": {},
   "source": [
    "## Pr=0.9, lb=0.8, lb=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "deada637",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:33.260925Z",
     "start_time": "2024-06-11T04:34:33.257278Z"
    }
   },
   "outputs": [],
   "source": [
    "pruning_dict = \"pruning_dict_1.0_0.8_1.0_chat_2639.json\"\n",
    "save_dir = \"/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/\"\n",
    "\n",
    "p = pruning_dict.split(\"_\")[-1].split(\".\")[-2]\n",
    "output_dir = \"/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints//\" + p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c97166c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:33.687478Z",
     "start_time": "2024-06-11T04:34:33.681277Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment = ExperimentRunner(pipeline, tokenizer, pruning_dict, \n",
    "                 save_dir=save_dir, output_dir=output_dir, ignored_layers=None, \n",
    "                 use_template=use_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7aa21bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T05:03:24.199157Z",
     "start_time": "2024-06-11T04:34:33.985513Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************   Running Experiment   ***************\n",
      "61 ==>  3328\n",
      "67 ==>  8806\n",
      "75 ==>  3328\n",
      "81 ==>  8806\n",
      "89 ==>  3328\n",
      "95 ==>  10973\n",
      "103 ==>  3328\n",
      "109 ==>  8806\n",
      "117 ==>  3328\n",
      "123 ==>  8806\n",
      "131 ==>  3328\n",
      "137 ==>  9539\n",
      "145 ==>  3328\n",
      "151 ==>  10370\n",
      "159 ==>  3328\n",
      "165 ==>  8806\n",
      "173 ==>  3328\n",
      "179 ==>  9644\n",
      "187 ==>  3584\n",
      "193 ==>  10059\n",
      "201 ==>  3328\n",
      "207 ==>  8815\n",
      "215 ==>  4096\n",
      "221 ==>  8806\n",
      "229 ==>  3328\n",
      "235 ==>  8806\n",
      "243 ==>  3328\n",
      "249 ==>  8806\n",
      "257 ==>  3328\n",
      "263 ==>  8806\n",
      "271 ==>  3328\n",
      "277 ==>  8806\n",
      "285 ==>  3840\n",
      "291 ==>  8806\n",
      "299 ==>  3328\n",
      "305 ==>  8806\n",
      "313 ==>  3328\n",
      "319 ==>  9285\n",
      "327 ==>  3328\n",
      "333 ==>  8806\n",
      "341 ==>  3328\n",
      "347 ==>  8806\n",
      "355 ==>  3584\n",
      "361 ==>  9692\n",
      "369 ==>  3328\n",
      "375 ==>  8806\n",
      "383 ==>  3328\n",
      "389 ==>  8806\n",
      "397 ==>  3328\n",
      "403 ==>  8806\n",
      "411 ==>  3840\n",
      "417 ==>  8806\n",
      "425 ==>  3328\n",
      "431 ==>  10968\n",
      "***************   Pruning Model   ***************\n",
      "Pruning model\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Saving model after pruning to checkpoint dir\n",
      "Model saved\n",
      "***************   Model Pruned Successfully   ***************\n",
      "Model Size after Pruning:  13.476839424\n",
      "evaluating on wikitext2\n",
      "nsamples 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:   0%|                                                                                 | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WikiText Validation:   8%|█████▊                                                                   | 2/25 [00:01<00:12,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  12%|████████▊                                                                | 3/25 [00:01<00:10,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  16%|███████████▋                                                             | 4/25 [00:02<00:09,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  20%|██████████████▌                                                          | 5/25 [00:02<00:08,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  24%|█████████████████▌                                                       | 6/25 [00:02<00:08,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  28%|████████████████████▍                                                    | 7/25 [00:03<00:07,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  32%|███████████████████████▎                                                 | 8/25 [00:03<00:07,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  36%|██████████████████████████▎                                              | 9/25 [00:04<00:06,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  40%|████████████████████████████▊                                           | 10/25 [00:04<00:06,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  44%|███████████████████████████████▋                                        | 11/25 [00:04<00:05,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  48%|██████████████████████████████████▌                                     | 12/25 [00:05<00:05,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  52%|█████████████████████████████████████▍                                  | 13/25 [00:05<00:04,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  56%|████████████████████████████████████████▎                               | 14/25 [00:06<00:04,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  60%|███████████████████████████████████████████▏                            | 15/25 [00:06<00:04,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  64%|██████████████████████████████████████████████                          | 16/25 [00:07<00:03,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  68%|████████████████████████████████████████████████▉                       | 17/25 [00:07<00:03,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  72%|███████████████████████████████████████████████████▊                    | 18/25 [00:07<00:02,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  76%|██████████████████████████████████████████████████████▋                 | 19/25 [00:08<00:02,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  80%|█████████████████████████████████████████████████████████▌              | 20/25 [00:08<00:02,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  84%|████████████████████████████████████████████████████████████▍           | 21/25 [00:09<00:01,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  88%|███████████████████████████████████████████████████████████████▎        | 22/25 [00:09<00:01,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  92%|██████████████████████████████████████████████████████████████████▏     | 23/25 [00:09<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  96%|█████████████████████████████████████████████████████████████████████   | 24/25 [00:10<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WikiText Validation: 100%|████████████████████████████████████████████████████████████████████████| 25/25 [00:10<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPL:  9.715262413024902\n",
      "Perplexity on wikitext2:  9.715262413024902\n",
      "Loading checkpoint from /data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/\n",
      "Model passed to evaluation:  LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11:10:07:58,019 WARNING  [task.py:763] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-06-11:10:07:58,021 WARNING  [task.py:775] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2024-06-11:10:08:34,871 WARNING  [task.py:763] [Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-06-11:10:08:34,872 WARNING  [task.py:775] [Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for winogrande contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/winogrande\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2024-06-11:10:12:14,899 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-06-11:10:12:14,900 INFO     [evaluator.py:177] Initializing huggingface model, with arguments: {'pretrained': '/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/'}\n",
      "2024-06-11:10:12:14,912 WARNING  [logging.py:61] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "2024-06-11:10:12:14,913 INFO     [huggingface.py:163] Using device 'cuda'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd8e5277c1c4bc7a79346d80ad5083b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11:10:12:28,271 WARNING  [task.py:763] [Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-06-11:10:12:28,273 WARNING  [task.py:775] [Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-06-11:10:14:13,057 WARNING  [task.py:763] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-06-11:10:14:13,059 WARNING  [task.py:775] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-06-11:10:16:25,225 WARNING  [evaluator.py:239] Overwriting default num_fewshot of arc_easy from None to 0\n",
      "2024-06-11:10:16:25,226 WARNING  [evaluator.py:239] Overwriting default num_fewshot of arc_challenge from None to 0\n",
      "2024-06-11:10:16:25,227 WARNING  [evaluator.py:239] Overwriting default num_fewshot of winogrande from None to 0\n",
      "2024-06-11:10:16:25,227 WARNING  [evaluator.py:239] Overwriting default num_fewshot of boolq from None to 0\n",
      "2024-06-11:10:16:25,228 WARNING  [evaluator.py:239] Overwriting default num_fewshot of openbookqa from None to 0\n",
      "2024-06-11:10:16:25,228 WARNING  [evaluator.py:239] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2024-06-11:10:16:25,229 WARNING  [evaluator.py:239] Overwriting default num_fewshot of rte from None to 0\n",
      "2024-06-11:10:16:25,234 INFO     [task.py:395] Building contexts for arc_easy on rank 0...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 116.05it/s]\n",
      "2024-06-11:10:16:26,108 INFO     [task.py:395] Building contexts for arc_challenge on rank 0...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 907.41it/s]\n",
      "2024-06-11:10:16:26,229 INFO     [task.py:395] Building contexts for winogrande on rank 0...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 65896.37it/s]\n",
      "2024-06-11:10:16:26,239 INFO     [task.py:395] Building contexts for boolq on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1584.45it/s]\n",
      "2024-06-11:10:16:26,316 INFO     [task.py:395] Building contexts for openbookqa on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1715.01it/s]\n",
      "2024-06-11:10:16:26,386 INFO     [task.py:395] Building contexts for hellaswag on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 2020.88it/s]\n",
      "2024-06-11:10:16:26,460 INFO     [task.py:395] Building contexts for rte on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1419.45it/s]\n",
      "2024-06-11:10:16:26,548 INFO     [evaluator.py:379] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|█████████████████████████████████████████████████████████████████| 2199/2199 [01:39<00:00, 22.00it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "fatal: not a git repository (or any parent up to mount point /)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "|     Alias     | Acc, None |   Acc StdErr, None   | Acc Norm, None | Acc Norm StdErr, None |\n",
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "|    arc_easy   |    0.64   | 0.04824181513244218  |      0.66      |  0.04760952285695237  |\n",
      "| arc_challenge |    0.31   | 0.04648231987117316  |      0.35      |  0.047937248544110196 |\n",
      "|   winogrande  |    0.65   | 0.047937248544110196 |      None      |          None         |\n",
      "|     boolq     |    0.71   | 0.045604802157206845 |      None      |          None         |\n",
      "|   openbookqa  |    0.16   | 0.03684529491774709  |      0.38      |  0.048783173121456316 |\n",
      "|   hellaswag   |    0.47   | 0.05016135580465919  |      0.65      |  0.047937248544110196 |\n",
      "|      rte      |    0.53   | 0.05016135580465919  |      None      |          None         |\n",
      "+---------------+-----------+----------------------+----------------+-----------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Gardening provides a sense of accomplishment and tranquility, as you nurture plants and watch them \u001b[0m\u001b[91m grow.\n",
      "Gardening is a great way to get some exercise. It’s a low-impact activity that can be done anywhere, and it’s a great way to get some fresh air.\n",
      "Gardening is a great way to get some fresh air and exercise. It’s a low-impact activity that can be done anywhere, and it’s a great way to meet new people.\n",
      "Gardening is a great way to get some fresh air and exercise. It’s a low-impact activity that can be done anywhere, and it’s a great way to meet new people.\n",
      "Gardening is a great way to get some fresh air and exercise. It’s a low-impact activity that can be done anywhere, and it’s a great way to meet new people.\n",
      "Gardening is a great way to get some fresh air and exercise. It’s a low-impact activity that can be done anywhere, and it’s a great way to meet new people.\n",
      "Gardening is a great way to get some fresh air and exercise. It’s a low-impact activity that can be done anywhere, and it’s a great way to meet new people.\n",
      "Gardening is a great way to get some fresh air and exercise. It’s a low-impact activity that can be done anywhere, and it’s a great way to meet new people.\n",
      "Gardening is a great way to get some fresh air and exercise. It’s a low-impact activity that can be done anywhere, and it’s a great way to meet new people.\n",
      "Gardening is a great way to get some fresh air and exercise. It’s a low-impact activity that can be done anywhere, and it’s a great way to meet new people.\n",
      "Gardening is a great way to get some fresh air and exercise. It’s a low-impact activity that can be done anywhere, and it’s a great way to meet new people.\n",
      "Gardening is a great way to get some fresh air and exercise. It’s a low-impact activity that can be done anywhere, and it’s a great way to meet new people.\n",
      "Gardening is a great way to get some fresh air and exercise. It’s a low-impact activity that can be done anywhere, and it’s a great way to\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Gardening provides a sense of accomplishment and tranquility, as you nurture plants and watch them \u001b[0m\u001b[91mgrow. Gardening is a great way to get some exercise. It’s a low-impact activity that can be done anywhere, and it’s a great way to get some fresh air. Gardening is a great way to get some fresh air and exercise. It’s a low-impact activity that can be done anywhere, and it’s a great way to meet new people.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Family traditions are passed down from generation to generation, creating a sense of continuity and belonging. Whether it's holiday celebrations, special recipes, or annual gatherings, these traditions foster \u001b[0m\u001b[91m a sense of community and connection, providing a sense of comfort and security that is essential for our well-being.\n",
      "In conclusion, family traditions are an essential part of our lives, providing a sense of continuity and connection that is essential for our well-being. They help us to feel a sense of belonging and security, and they provide a sense of comfort and stability that is essential for our mental and emotional health.\n",
      "Family traditions are an essential part of our lives, providing a sense of continuity and connection that is essential for our well-being. They help us to feel a sense of belonging and security, and they provide a sense of comfort and stability that is essential for our mental and emotional health.\n",
      "In conclusion, family traditions are an essential part of our lives, providing a sense of continuity and connection that is essential for our well-being. They help us to feel a sense of belonging and security, and they provide a sense of comfort and stability that is essential for our mental and emotional health.\n",
      "In conclusion, family traditions are an essential part of our lives, providing a sense of continuity and connection that is essential for our well-being. They help us to feel a sense of belonging and security, and they provide a sense of comfort and stability that is essential for our mental and emotional health.\n",
      "In conclusion, family traditions are an essential part of our lives, providing a sense of continuity and connection that is essential for our well-being. They help us to feel a sense of belonging and security, and they provide a sense of comfort and stability that is essential for our mental and emotional health.\n",
      "In conclusion, family traditions are an essential part of our lives, providing a sense of continuity and connection that is essential for our well-being. They help us to feel a sense of belonging and security, and they provide a sense of comfort and stability that is essential for our mental and emotional health.\n",
      "In conclusion, family traditions are an essential part of our lives, providing a sense of continuity and connection that is essential for our well-being. They help us to feel a sense of belonging and security, and they provide a sense of comfort and stability that is essential for our mental and emotional health.\n",
      "In conclusion, family traditions are an essential part of our lives, providing a sense of continuity and connection that is essential for our well-being. They help us\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Family traditions are passed down from generation to generation, creating a sense of continuity and belonging. Whether it's holiday celebrations, special recipes, or annual gatherings, these traditions foster \u001b[0m\u001b[91ma sense of community and connection, providing a sense of comfort and security that is essential for our well-being. In conclusion, family traditions are an essential part of our lives, providing a sense of continuity and connection that is essential for our well-being. They help us to feel a sense of belonging and security, and they provide a sense of comfort and stability that is essential for our mental and emotional health. Family traditions are an essential part of our lives, providing a sense of continuity and connection that is essential for our well-being.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future \u001b[0m\u001b[91m, fashion will continue to evolve and adapt to the changing needs of society and culture, ensuring that it remains a form of self-expression and a form of art.\n",
      "Previous articleThe Future of Fashion: How Technology is Changing the Way We Dress\n",
      "Next articleThe Future of Fashion: How Technology is Changing the Way We Dress\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future \u001b[0m\u001b[91m, fashion will continue to evolve and adapt to the changing needs of society and culture, ensuring that it remains a form of self-expression and a form of art.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Artificial intelligence is transforming the healthcare industry by enabling \u001b[0m\u001b[91m doctors to make more accurate diagnoses and treatments.\n",
      "Artificial intelligence is transforming the healthcare industry by enabling doctors to make more accurate diagnoses and treatments.\n",
      "Artificial intelligence is transforming the healthcare industry by enabling doctors to make more accurate diagnoses and treatments.\n",
      "Artificial intelligence is transforming the healthcare industry by enabling doctors to make more accurate diagnoses and treatments.\n",
      "Artificial intelligence is transforming the healthcare industry by enabling doctors to make more accurate diagnoses and treatments.\n",
      "Artificial intelligence is transforming the healthcare industry by enabling doctors to make more accurate diagnoses and treatments.\n",
      "Artificial intelligence is transforming the healthcare industry by enabling doctors to make more accurate diagnoses and treatments.\n",
      "Artificial intelligence is transforming the healthcare industry by enabling doctors to make more accurate diagnoses and treatments.\n",
      "Artificial intelligence is transforming the healthcare industry by enabling doctors to make more accurate diagnoses and treatments.\n",
      "Artificial intelligence is transforming the healthcare industry by enabling doctors to make more accurate diagnoses and treatments.\n",
      "Artificial intelligence is transforming the healthcare industry by enabling doctors to make more accurate diagnoses and treatments.\n",
      "Artificial intelligence is transforming the healthcare industry by enabling doctors to make more accurate diagnoses and treatments.\n",
      "Artificial intelligence is transforming the healthcare industry by enabling doctors to make more accurate diagnoses and treatments.\n",
      "Artificial intelligence is transforming the healthcare industry by enabling doctors to make more accurate diagnoses and treatments.\n",
      "Artificial intelligence is transforming the healthcare industry by enabling doctors to make more accurate diagnoses and treatments.\n",
      "Artificial intelligence is transforming the healthcare industry by enabling doctors to make more accurate diagnoses and treatments.\n",
      "Artificial intelligence is transforming the healthcare industry by enabling doctors to make more accurate diagnoses and treatments.\n",
      "Artificial intelligence is transforming the healthcare industry by enabling doctors to make more accurate diagnoses and treatments.\n",
      "Artificial intelligence is transforming the healthcare industry by enabling doctors to make more accurate diagnoses and treatments.\n",
      "Artificial intelligence is transforming the healthcare industry by en\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Artificial intelligence is transforming the healthcare industry by enabling \u001b[0m\u001b[91mdoctors to make more accurate diagnoses and treatments. Artificial intelligence is transforming the healthcare industry by enabling doctors to make more accurate diagnoses and treatments.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Machine learning algorithms are increasingly being used to predict stock market trends. By analyzing historical data and identifying patterns, these models can \u001b[0m\u001b[91m help investors make more informed decisions about when to buy or sell stocks.\n",
      "Investors should always be aware of the risks associated with any investment, and this is especially true when it comes to stock market trends. By understanding the risks involved, investors can make more informed decisions about when to buy or sell stocks.\n",
      "Investors should always be aware of the risks associated with any investment, and this is especially true when it comes to stock market trends. By understanding the risks involved, investors can make more informed decisions about when to buy or sell stocks.\n",
      "Investors should always be aware of the risks associated with any investment, and this is especially true when it comes to stock market trends. By understanding the risks involved, investors can make more informed decisions about when to buy or sell stocks.\n",
      "Investors should always be aware of the risks associated with any investment, and this is especially true when it comes to stock market trends. By understanding the risks involved, investors can make more informed decisions about when to buy or sell stocks.\n",
      "Investors should always be aware of the risks associated with any investment, and this is especially true when it comes to stock market trends. By understanding the risks involved, investors can make more informed decisions about when to buy or sell stocks.\n",
      "Investors should always be aware of the risks associated with any investment, and this is especially true when it comes to stock market trends. By understanding the risks involved, investors can make more informed decisions about when to buy or sell stocks.\n",
      "Investors should always be aware of the risks associated with any investment, and this is especially true when it comes to stock market trends. By understanding the risks involved, investors can make more informed decisions about when to buy or sell stocks.\n",
      "Investors should always be aware of the risks associated with any investment, and this is especially true when it comes to stock market trends. By understanding the risks involved, investors can make more informed decisions about when to buy or sell stocks.\n",
      "Investors should always be aware of the risks associated with any investment, and this is especially true when it comes to stock market trends. By understanding the risks involved, investors can make more informed decisions\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Machine learning algorithms are increasingly being used to predict stock market trends. By analyzing historical data and identifying patterns, these models can \u001b[0m\u001b[91mhelp investors make more informed decisions about when to buy or sell stocks. Investors should always be aware of the risks associated with any investment, and this is especially true when it comes to stock market trends. By understanding the risks involved, investors can make more informed decisions about when to buy or sell stocks.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The integration of natural language processing with machine learning has opened up new possibilities in human-computer interaction. For instance, chatbots powered by sophisticated NLP algorithms can now understand and respond to user queries with remarkable accuracy. As these technologies continue to evolve, we can expect that \u001b[0m\u001b[91m they will become even more useful and intuitive for everyday life.\n",
      "What are the benefits of using natural language processing in human-computer interaction?\n",
      "Natural language processing (NLP) is a field of computer science that deals with the development of algorithms and techniques for understanding and responding to user queries. NLP has many benefits for human-computer interaction, including the ability to understand and respond to user queries more quickly and accurately, the ability to provide more personalized and intuitive interfaces, and the ability to provide more efficient and effective communication between users and their computers.\n",
      "What are the limitations of using natural language processing in human-computer interaction?\n",
      "Natural language processing (NLP) is a field of computer science that deals with the development of algorithms and techniques for understanding and responding to user queries. NLP has many benefits for human-computer interaction, including the ability to provide more personalized and intuitive interfaces, the ability to provide more efficient and effective communication between users and their computers, and the ability to provide more accurate and reliable information. However, NLP also has its limitations, including the ability to provide more personalized and intuitive interfaces, the ability to provide more efficient and effective communication between users and their computers, and the ability to provide more accurate and reliable information.\n",
      "What are the future prospects for using natural language processing in human-computer interaction?\n",
      "Natural language processing (NLP) is a field of computer science that deals with the development of algorithms and techniques for understanding and responding to user queries. NLP has many benefits for human-computer interaction, including the ability to provide more personalized and intuitive interfaces, the ability to provide more efficient and effective communication between users and their computers, and the ability to provide more accurate and reliable information.\n",
      "What are the future prospects for using natural language processing in human-computer interaction?\n",
      "Natural language processing (NLP) is a field of computer science that deals with the development of algorithms and techniques for understanding and responding to user queries. NLP has many benefits for human-computer interaction, including the ability to provide more personalized and intuitive interfaces, the ability to provide more efficient and effective communication between users and their computers, and the ability to provide more accurate and reliable information.\n",
      "What are the future prospects for using natural language processing in human-computer interaction?\n",
      "Natural language processing (NLP) is a field of computer\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The integration of natural language processing with machine learning has opened up new possibilities in human-computer interaction. For instance, chatbots powered by sophisticated NLP algorithms can now understand and respond to user queries with remarkable accuracy. As these technologies continue to evolve, we can expect that \u001b[0m\u001b[91mthey will become even more useful and intuitive for everyday life. What are the benefits of using natural language processing in human-computer interaction?\n",
      "Natural language processing (NLP) is a field of computer science that deals with the development of algorithms and techniques for understanding and responding to user queries. NLP has many benefits for human-computer interaction, including the ability to understand and respond to user queries more quickly and accurately, the ability to provide more personalized and intuitive interfaces, and the ability to provide more efficient and effective communication between users and their computers. What are the limitations of using natural language processing in human-computer interaction?\n",
      "Natural language processing (NLP) is a field of computer science that deals with the development of algorithms and techniques for understanding and responding to user queries. NLP has many benefits for human-computer interaction, including the ability to provide more personalized and intuitive interfaces, the ability to provide more efficient and effective communication between users and their computers, and the ability to provide more accurate and reliable information. However, NLP also has its limitations, including the ability to provide more personalized and intuitive interfaces, the ability to provide more efficient and effective communication between users and their computers, and the ability to provide more accurate and reliable information. What are the future prospects for using natural language processing in human-computer interaction?\n",
      "Natural language processing (NLP) is a field of computer science that deals with the development of algorithms and techniques for understanding and responding to user queries.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Self-driving cars rely heavily on sensor data and advanced algorithms to navigate \u001b[0m\u001b[91m the road safely and efficiently. However, the development of these technologies has been slowed by the lack of a standardized framework for their deployment. This has resulted in a situation where different companies are using different technologies and standards, which can lead to confusion and inefficiency.\n",
      "To address this problem, the National Highway Traffic Safety Administration (NHTSA) has proposed a standardized framework for the deployment of self-driving cars. This framework will include a standardized set of rules and regulations that all companies must follow in order to ensure the safety of their customers and the public.\n",
      "The first step in the development of self-driving cars is to create a standardized set of rules and regulations that all companies must follow. This will include a standardized set of rules and regulations that all companies must follow in order to ensure the safety of their customers and the public.\n",
      "The second step in the development of self-driving cars is to create a standardized set of rules and regulations that all companies must follow. This will include a standardized set of rules and regulations that all companies must follow in order to ensure the safety of their customers and the public.\n",
      "The third step in the development of self-driving cars is to create a standardized set of rules and regulations that all companies must follow. This will include a standardized set of rules and regulations that all companies must follow in order to ensure the safety of their customers and the public.\n",
      "The fourth step in the development of self-driving cars is to create a standardized set of rules and regulations that all companies must follow. This will include a standardized set of rules and regulations that all companies must follow in order to ensure the safety of their customers and the public.\n",
      "The fifth step in the development of self-driving cars is to create a standardized set of rules and regulations that all companies must follow. This will include a standardized set of rules and regulations that all companies must follow in order to ensure the safety of their customers and the public.\n",
      "The sixth step in the development of self-driving cars is to create a standardized set of rules and regulations that all companies must follow. This will include a standardized set of rules and regulations that all companies must follow in order to ensure the safety of their customers and the public.\n",
      "The seventh step in the development of self-driving cars\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Self-driving cars rely heavily on sensor data and advanced algorithms to navigate \u001b[0m\u001b[91mthe road safely and efficiently. However, the development of these technologies has been slowed by the lack of a standardized framework for their deployment. This has resulted in a situation where different companies are using different technologies and standards, which can lead to confusion and inefficiency. To address this problem, the National Highway Traffic Safety Administration (NHTSA) has proposed a standardized framework for the deployment of self-driving cars. This framework will include a standardized set of rules and regulations that all companies must follow in order to ensure the safety of their customers and the public. The first step in the development of self-driving cars is to create a standardized set of rules and regulations that all companies must follow. This will include a standardized set of rules and regulations that all companies must follow in order to ensure the safety of their customers and the public. The second step in the development of self-driving cars is to create a standardized set of rules and regulations that all companies must follow. The third step in the development of self-driving cars is to create a standardized set of rules and regulations that all companies must follow. The fourth step in the development of self-driving cars is to create a standardized set of rules and regulations that all companies must follow. The fifth step in the development of self-driving cars is to create a standardized set of rules and regulations that all companies must follow. The sixth step in the development of self-driving cars is to create a standardized set of rules and regulations that all companies must follow.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m One of the biggest challenges in developing AI systems is ensuring they are ethical and unbiased. Researchers are working on creating frameworks that can \u001b[0m\u001b[91m help ensure this is the case.\n",
      "One of the most important aspects of AI is that it can be used to create a more efficient and effective society. This is especially true when it comes to the development of AI systems.\n",
      "AI systems can be used to create a more efficient and effective society. This is especially true when it comes to the development of AI systems.\n",
      "AI systems can be used to create a more efficient and effective society. This is especially true when it comes to the development of AI systems.\n",
      "AI systems can be used to create a more efficient and effective society. This is especially true when it comes to the development of AI systems.\n",
      "AI systems can be used to create a more efficient and effective society. This is especially true when it comes to the development of AI systems.\n",
      "AI systems can be used to create a more efficient and effective society. This is especially true when it comes to the development of AI systems.\n",
      "AI systems can be used to create a more efficient and effective society. This is especially true when it comes to the development of AI systems.\n",
      "AI systems can be used to create a more efficient and effective society. This is especially true when it comes to the development of AI systems.\n",
      "AI systems can be used to create a more efficient and effective society. This is especially true when it comes to the development of AI systems.\n",
      "AI systems can be used to create a more efficient and effective society. This is especially true when it comes to the development of AI systems.\n",
      "AI systems can be used to create a more efficient and effective society. This is especially true when it comes to the development of AI systems.\n",
      "AI systems can be used to create a more efficient and effective society. This is especially true when it comes to the development of AI systems.\n",
      "AI systems can be used to create a more efficient and effective society. This is especially true when it comes to the development of AI systems.\n",
      "AI systems can be used to create a more efficient and effective society. This is especially true when it comes to the development of AI systems.\n",
      "AI systems can be used to create a more efficient and effective society. This is especially true when it comes to the development of AI systems.\n",
      "AI systems can be used to create a more efficient and effective society. This is especially true when it comes to the development of AI systems.\n",
      "AI systems can be used to create a more efficient and effective society.\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m One of the biggest challenges in developing AI systems is ensuring they are ethical and unbiased. Researchers are working on creating frameworks that can \u001b[0m\u001b[91mhelp ensure this is the case. One of the most important aspects of AI is that it can be used to create a more efficient and effective society. This is especially true when it comes to the development of AI systems. AI systems can be used to create a more efficient and effective society.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m In the field of computer vision, convolutional neural networks have revolutionized the way machines perceive visual information. By mimicking the human visual system, these networks can classify images, detect objects, and even perform image segmentation. This has significant applications in areas such as medical imaging, where AI can assist doctors in diagnosing conditions from X-rays and MRIs. As the technology advances, we may soon see AI systems that \u001b[0m\u001b[91m can not only see, but also think and act like humans.\n",
      "The future of AI is exciting and full of possibilities. As the technology advances, we may see AI systems that can not only see, but also think and act like humans. This will have a significant impact on the way we interact with the world around us, and it will be exciting to see what the future holds.\n",
      "Previous articleThe Best AI-Powered Tools for Your Business\n",
      "Next articleThe Best AI-Powered Tools for Your Business\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m In the field of computer vision, convolutional neural networks have revolutionized the way machines perceive visual information. By mimicking the human visual system, these networks can classify images, detect objects, and even perform image segmentation. This has significant applications in areas such as medical imaging, where AI can assist doctors in diagnosing conditions from X-rays and MRIs. As the technology advances, we may soon see AI systems that \u001b[0m\u001b[91mcan not only see, but also think and act like humans. The future of AI is exciting and full of possibilities. As the technology advances, we may see AI systems that can not only see, but also think and act like humans. This will have a significant impact on the way we interact with the world around us, and it will be exciting to see what the future holds.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Reinforcement learning algorithms learn optimal behaviors through \u001b[0m\u001b[91m the process of trial and error.\n",
      "The most common application of reinforcement learning is in the field of robotics.\n",
      "Reinforcement learning algorithms are used to teach robots how to perform tasks such as walking, walking, and walking.\n",
      "The most common application of reinforcement learning is in the field of robotics.\n",
      "Reinforcement learning algorithms are used to teach robots how to perform tasks such as walking, walking, and walking.\n",
      "The most common application of reinforcement learning is in the field of robotics.\n",
      "Reinforcement learning algorithms are used to teach robots how to perform tasks such as walking, walking, and walking.\n",
      "The most common application of reinforcement learning is in the field of robotics.\n",
      "Reinforcement learning algorithms are used to teach robots how to perform tasks such as walking, walking, and walking.\n",
      "The most common application of reinforcement learning is in the field of robotics.\n",
      "Reinforcement learning algorithms are used to teach robots how to perform tasks such as walking, walking, and walking.\n",
      "The most common application of reinforcement learning is in the field of robotics.\n",
      "Reinforcement learning algorithms are used to teach robots how to perform tasks such as walking, walking, and walking.\n",
      "The most common application of reinforcement learning is in the field of robotics.\n",
      "Reinforcement learning algorithms are used to teach robots how to perform tasks such as walking, walking, and walking.\n",
      "The most common application of reinforcement learning is in the field of robotics.\n",
      "Reinforcement learning algorithms are used to teach robots how to perform tasks such as walking, walking, and walking.\n",
      "The most common application of reinforcement learning is in the field of robotics.\n",
      "Reinforcement learning algorithms are used to teach robots how to perform tasks such as walking, walking, and walking.\n",
      "The most common application of reinforcement learning is in the field of robotics.\n",
      "Reinforcement learning algorithms are used to teach robots how to perform tasks such as walking, walking, and walking.\n",
      "The most common application of reinforcement learning is in the field of robotics.\n",
      "Reinforcement learning algorithms are used to teach robots how to perform tasks such as walking, walking, and walking.\n",
      "The most common application of reinforcement learning is in the field of robotics.\n",
      "Rein\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Reinforcement learning algorithms learn optimal behaviors through \u001b[0m\u001b[91mthe process of trial and error. The most common application of reinforcement learning is in the field of robotics. Reinforcement learning algorithms are used to teach robots how to perform tasks such as walking, walking, and walking.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could \u001b[0m\u001b[91m potentially crack the most secure codes and ciphers. This would have a major impact on the way we communicate and do business online.\n",
      "The future of cryptography is uncertain, but one thing is for sure: quantum computing will have a major impact on the way we communicate and do business online. With the ability to solve complex problems much faster than classical computers, quantum algorithms could potentially crack the most secure codes and ciphers. This would have a major impact on the way we communicate and do business online.\n",
      "Cryptography is a fascinating and important field, and its future is uncertain. With the advent of quantum computing, it is possible that cryptography will be revolutionized in a way that we cannot even imagine today. This will have a major impact on the way we communicate and do business online.\n",
      "Cryptography is a fascinating and important field, and its future is uncertain. With the advent of quantum computing, it is possible that cryptography will be revolutionized in a way that we cannot even imagine today. This will have a major impact on the way we communicate and do business online.\n",
      "Cryptography is a fascinating and important field, and its future is uncertain. With the advent of quantum computing, it is possible that cryptography will be revolutionized in a way that we cannot even imagine today. This will have a major impact on the way we communicate and do business online.\n",
      "Cryptography is a fascinating and important field, and its future is uncertain. With the advent of quantum computing, it is possible that cryptography will be revolutionized in a way that we cannot even imagine today. This will have a major impact on the way we communicate and do business online.\n",
      "Cryptography is a fascinating and important field, and its future is uncertain. With the advent of quantum computing, it is possible that cryptography will be revolutionized in a way that we cannot even imagine today. This will have a major impact on the way we communicate and do business online.\n",
      "Cryptography is a fascinating and important field, and its future is uncertain. With the advent of quantum computing, it is possible that cryptography will be revolutionized in a way that we cannot even imagine today. This will have a major impact on the way we communicate and do business online.\n",
      "Cryptography is a fascinating and important field, and its future is uncertain. With the advent of quantum computing, it is possible that cryptography will be revolutionized in\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could \u001b[0m\u001b[91mpotentially crack the most secure codes and ciphers. This would have a major impact on the way we communicate and do business online. The future of cryptography is uncertain, but one thing is for sure: quantum computing will have a major impact on the way we communicate and do business online. With the ability to solve complex problems much faster than classical computers, quantum algorithms could potentially crack the most secure codes and ciphers. Cryptography is a fascinating and important field, and its future is uncertain. With the advent of quantum computing, it is possible that cryptography will be revolutionized in a way that we cannot even imagine today. This will have a major impact on the way we communicate and do business online.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that \u001b[0m\u001b[91m can help us make better decisions.\n",
      "The future of AI is still being written, but one thing is certain: that it will continue to evolve and become more powerful and secure. With the help of these new techniques, we can look forward to a world where AI is truly a force for good.\n",
      "The future of AI is still being written, but one thing is certain: that it will continue to evolve and become more powerful and secure. With the help of these new techniques, we can look forward to a world where AI is truly a force for good.\n",
      "The future of AI is still being written, but one thing is certain: that it will continue to evolve and become more powerful and secure. With the help of these new techniques, we can look forward to a world where AI is truly a force for good.\n",
      "The future of AI is still being written, but one thing is certain: that it will continue to evolve and become more powerful and secure. With the help of these new techniques, we can look forward to a world where AI is truly a force for good.\n",
      "The future of AI is still being written, but one thing is certain: that it will continue to evolve and become more powerful and secure. With the help of these new techniques, we can look forward to a world where AI is truly a force for good.\n",
      "The future of AI is still being written, but one thing is certain: that it will continue to evolve and become more powerful and secure. With the help of these new techniques, we can look forward to a world where AI is truly a force for good.\n",
      "The future of AI is still being written, but one thing is certain: that it will continue to evolve and become more powerful and secure. With the help of these new techniques, we can look forward to a world where AI is truly a force for good.\n",
      "The future of AI is still being written, but one thing is certain: that it will continue to evolve and become more powerful and secure. With the help of these new techniques, we can look forward to a world where AI is truly a force for good.\n",
      "The future of AI is still being written, but one thing is certain: that it will continue to evolve and become more powerful and secure. With the help of these new techniques, we can look forward to a world where AI is truly a force for good.\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that \u001b[0m\u001b[91mcan help us make better decisions. The future of AI is still being written, but one thing is certain: that it will continue to evolve and become more powerful and secure. With the help of these new techniques, we can look forward to a world where AI is truly a force for good.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Transfer learning allows models trained on large datasets to be fine-tuned for specific tasks by \u001b[0m\u001b[91m simply changing the input and output variables.\n",
      "The most common use of transfer learning is to train a model on a large dataset and then to fine-tune it for specific tasks. This can be done by simply changing the input and output variables.\n",
      "For example, if you want to train a model on a large dataset and then to fine-tune it for specific tasks, you can do so by simply changing the input and output variables. This can be done by simply changing the input and output variables.\n",
      "This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by simply changing the input and output variables. This can be done by\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Transfer learning allows models trained on large datasets to be fine-tuned for specific tasks by \u001b[0m\u001b[91msimply changing the input and output variables. The most common use of transfer learning is to train a model on a large dataset and then to fine-tune it for specific tasks. This can be done by simply changing the input and output variables. For example, if you want to train a model on a large dataset and then to fine-tune it for specific tasks, you can do so by simply changing the input and output variables.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Explainable AI (XAI) is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to \u001b[0m\u001b[91m help users understand and improve the performance of their AI systems.\n",
      "XAI is a field of study that focuses on the development of artificial intelligence (AI) systems that are able to understand and interact with their environment. XAI systems are designed to be more efficient and effective than traditional AI systems, and they are becoming increasingly popular in a variety of industries.\n",
      "XAI systems are typically divided into two categories: those that are designed to be more efficient and those that are designed to be more effective. In the first category, XAI systems are designed to be more efficient and to interact with their environment. In the second category, XAI systems are designed to be more effective and to interact with their environment. In the first category, XAI systems are typically used in a variety of industries, such as healthcare, manufacturing, and transportation. In the second category, XAI systems are typically used in a variety of industries, such as healthcare, manufacturing, and transportation. In the first category, XAI systems are typically used in a variety of industries, such as healthcare, manufacturing, and transportation. In the second category, XAI systems are typically used in a variety of industries, such as healthcare, manufacturing, and transportation. In the first category, XAI systems are typically used in a variety of industries, such as healthcare, manufacturing, and transportation. In the second category, XAI systems are typically used in a variety of industries, such as healthcare, manufacturing, and transportation. In the first category, XAI systems are typically used in a variety of industries, such as healthcare, manufacturing, and transportation. In the second category, XAI systems are typically used in a variety of industries, such as healthcare, manufacturing, and transportation. In the first category, XAI systems are typically used in a variety of industries, such as healthcare, manufacturing, and transportation. In the second category, XAI systems are typically used in a variety of industries, such as healthcare, manufacturing, and transportation. In the first category, XAI systems are typically used in a variety of industries, such as healthcare, manufacturing, and transportation. In the second category, XAI systems are typically used in a variety of industries, such as healthcare, manufacturing, and transportation. In the first category,\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Explainable AI (XAI) is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to \u001b[0m\u001b[91mhelp users understand and improve the performance of their AI systems. XAI is a field of study that focuses on the development of artificial intelligence (AI) systems that are able to understand and interact with their environment. XAI systems are designed to be more efficient and effective than traditional AI systems, and they are becoming increasingly popular in a variety of industries. XAI systems are typically divided into two categories: those that are designed to be more efficient and those that are designed to be more effective. In the first category, XAI systems are designed to be more efficient and to interact with their environment. In the second category, XAI systems are designed to be more effective and to interact with their environment. In the first category, XAI systems are typically used in a variety of industries, such as healthcare, manufacturing, and transportation. In the second category, XAI systems are typically used in a variety of industries, such as healthcare, manufacturing, and transportation.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and \u001b[0m\u001b[91m the water turns a darker shade of blue.\n",
      "The best time to see a sunset over the ocean is usually around 7:00 or 8:00 p.m. This is when the sun is at its highest point in the sky, and the light is at its brightest. The best time to see a sunset over the ocean is also usually when the tide is at its lowest point, and the water is at its clearest.\n",
      "The best time to see a sunset over the ocean is usually around 7:00 or 8:00 p.m. This is when the sun is at its highest point in the sky, and the light is at its brightest. The best time to see a sunset over the ocean is also usually when the tide is at its lowest point, and the water is at its clearest.\n",
      "The best time to see a sunset over the ocean is usually around 7:00 or 8:00 p.m. This is when the sun is at its highest point in the sky, and the light is at its brightest. The best time to see a sunset over the ocean is also usually when the tide is at its lowest point, and the water is at its clearest.\n",
      "The best time to see a sunset over the ocean is usually around 7:00 or 8:00 p.m. This is when the sun is at its highest point in the sky, and the light is at its brightest. The best time to see a sunset over the ocean is also usually when the tide is at its lowest point, and the water is at its clearest.\n",
      "The best time to see a sunset over the ocean is usually around 7:00 or 8:00 p.m. This is when the sun is at its highest point in the sky, and the light is at its brightest. The best time to see a sunset over the ocean is also usually when the tide is at its lowest point, and the water is at its clearest.\n",
      "The best time to see a sunset over the ocean is usually around 7:00 or 8:00 p.m. This is when the sun is at its highest point in the sky, and the light is at its brightest. The best time to see a sunset over the ocean is also usually when the tide\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and \u001b[0m\u001b[91mthe water turns a darker shade of blue. The best time to see a sunset over the ocean is usually around 7:00 or 8:00 p. m. This is when the sun is at its highest point in the sky, and the light is at its brightest. The best time to see a sunset over the ocean is also usually when the tide is at its lowest point, and the water is at its clearest.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of \u001b[0m\u001b[91m the world around you.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Travel\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of \u001b[0m\u001b[91mthe world around you. Traveling to new countries allows you to experience different cultures and traditions.\u001b[0m\n",
      "\n",
      "\n",
      "Pruning model\n",
      "Model size after pruning:  13.4516736\n",
      "Model size after pruning:  13.397557248\n",
      "Model size after pruning:  13.372391424\n",
      "Model size after pruning:  13.318275072\n",
      "Model size after pruning:  13.293109248\n",
      "Model size after pruning:  13.292249088\n",
      "Model size after pruning:  13.267083264\n",
      "Model size after pruning:  13.212966912\n",
      "Model size after pruning:  13.187801088\n",
      "Model size after pruning:  13.133684736\n",
      "Model size after pruning:  13.108518912\n",
      "Model size after pruning:  13.072416768\n",
      "Model size after pruning:  13.047250944\n",
      "Model size after pruning:  13.031571456\n",
      "Model size after pruning:  13.006405632\n",
      "Model size after pruning:  12.95228928\n",
      "Model size after pruning:  12.927123456\n",
      "Model size after pruning:  12.893601792\n",
      "Model size after pruning:  12.876824576\n",
      "Model size after pruning:  12.853501952\n",
      "Model size after pruning:  12.828336128\n",
      "Model size after pruning:  12.77444096\n",
      "Model size after pruning:  12.77444096\n",
      "Model size after pruning:  12.720324608\n",
      "Model size after pruning:  12.695158784\n",
      "Model size after pruning:  12.641042432\n",
      "Model size after pruning:  12.615876608\n",
      "Model size after pruning:  12.561760256\n",
      "Model size after pruning:  12.536594432\n",
      "Model size after pruning:  12.48247808\n",
      "Model size after pruning:  12.457312256\n",
      "Model size after pruning:  12.403195904\n",
      "Model size after pruning:  12.394807296\n",
      "Model size after pruning:  12.340690944\n",
      "Model size after pruning:  12.31552512\n",
      "Model size after pruning:  12.261408768\n",
      "Model size after pruning:  12.236242944\n",
      "Model size after pruning:  12.193898496\n",
      "Model size after pruning:  12.168732672\n",
      "Model size after pruning:  12.11461632\n",
      "Model size after pruning:  12.089450496\n",
      "Model size after pruning:  12.035334144\n",
      "Model size after pruning:  12.018556928\n",
      "Model size after pruning:  11.986214912\n",
      "Model size after pruning:  11.961049088\n",
      "Model size after pruning:  11.906932736\n",
      "Model size after pruning:  11.881766912\n",
      "Model size after pruning:  11.82765056\n",
      "Model size after pruning:  11.802484736\n",
      "Model size after pruning:  11.748368384\n",
      "Model size after pruning:  11.739979776\n",
      "Model size after pruning:  11.685863424\n",
      "Model size after pruning:  11.6606976\n",
      "Model size after pruning:  11.65971456\n",
      "Saving model after pruning to checkpoint dir\n",
      "Model saved\n",
      "Real Pruned Model\n",
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (4-5): 2 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (o_proj): Linear(in_features=3328, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (down_proj): Linear(in_features=8806, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (6): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (o_proj): Linear(in_features=3328, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10973, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10973, bias=False)\n",
      "          (down_proj): Linear(in_features=10973, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (7-8): 2 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (o_proj): Linear(in_features=3328, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (down_proj): Linear(in_features=8806, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (9): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (o_proj): Linear(in_features=3328, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=9539, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=9539, bias=False)\n",
      "          (down_proj): Linear(in_features=9539, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (10): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (o_proj): Linear(in_features=3328, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10370, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10370, bias=False)\n",
      "          (down_proj): Linear(in_features=10370, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (11): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (o_proj): Linear(in_features=3328, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (down_proj): Linear(in_features=8806, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (12): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (o_proj): Linear(in_features=3328, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=9644, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=9644, bias=False)\n",
      "          (down_proj): Linear(in_features=9644, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (13): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "          (o_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10059, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10059, bias=False)\n",
      "          (down_proj): Linear(in_features=10059, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (14): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (o_proj): Linear(in_features=3328, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=8815, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=8815, bias=False)\n",
      "          (down_proj): Linear(in_features=8815, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (15): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (down_proj): Linear(in_features=8806, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (16-19): 4 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (o_proj): Linear(in_features=3328, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (down_proj): Linear(in_features=8806, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (20): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (o_proj): Linear(in_features=3840, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (down_proj): Linear(in_features=8806, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (21): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (o_proj): Linear(in_features=3328, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (down_proj): Linear(in_features=8806, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (22): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (o_proj): Linear(in_features=3328, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=9285, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=9285, bias=False)\n",
      "          (down_proj): Linear(in_features=9285, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (23-24): 2 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (o_proj): Linear(in_features=3328, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (down_proj): Linear(in_features=8806, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (25): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "          (o_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=9692, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=9692, bias=False)\n",
      "          (down_proj): Linear(in_features=9692, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (26-28): 3 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (o_proj): Linear(in_features=3328, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (down_proj): Linear(in_features=8806, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (29): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (o_proj): Linear(in_features=3840, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (down_proj): Linear(in_features=8806, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (30): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (o_proj): Linear(in_features=3328, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10968, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10968, bias=False)\n",
      "          (down_proj): Linear(in_features=10968, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (31): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n",
      "Real Pruned Model Size\n",
      "11.65971456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short Context: 19.93542221243748 tokens/sec, 172 tokens (including full prompt)\n",
      "Long Context: 48.06337878481866 tokens/sec, 1288 tokens (including full prompt)\n",
      "Average:  22.81481191153255 tokens/sec\n",
      "***************   Experiment completed successfully Successfully   ***************\n"
     ]
    }
   ],
   "source": [
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f175e787",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T05:03:24.211041Z",
     "start_time": "2024-06-11T05:03:24.203355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5829853184"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d32f490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41ce8bf9",
   "metadata": {},
   "source": [
    "## Pr=0.6, lb=0.5, lb=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "634bd15c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T02:25:31.289727Z",
     "start_time": "2024-06-11T02:25:31.286397Z"
    }
   },
   "outputs": [],
   "source": [
    "pruning_dict = \"pruning_dict_1.0_0.5_1.0_chat_2642.json\"\n",
    "save_dir = \"/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/\"\n",
    "\n",
    "p = pruning_dict.split(\"_\")[-1].split(\".\")[-2]\n",
    "output_dir = \"/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints//\" + p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c52af6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T02:25:32.107248Z",
     "start_time": "2024-06-11T02:25:32.094972Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment = ExperimentRunner(pipeline, tokenizer, pruning_dict, \n",
    "                 save_dir=save_dir, output_dir=output_dir, ignored_layers=None, \n",
    "                 use_template=use_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eff50791",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T02:54:23.857881Z",
     "start_time": "2024-06-11T02:25:32.452573Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************   Running Experiment   ***************\n",
      "61 ==>  3968\n",
      "67 ==>  10916\n",
      "75 ==>  3968\n",
      "81 ==>  10473\n",
      "89 ==>  4096\n",
      "95 ==>  10926\n",
      "103 ==>  3968\n",
      "109 ==>  10865\n",
      "117 ==>  4096\n",
      "123 ==>  10718\n",
      "131 ==>  4096\n",
      "137 ==>  10632\n",
      "145 ==>  2048\n",
      "151 ==>  5504\n",
      "159 ==>  2048\n",
      "165 ==>  5504\n",
      "173 ==>  2048\n",
      "179 ==>  5504\n",
      "187 ==>  2048\n",
      "193 ==>  5504\n",
      "201 ==>  2048\n",
      "207 ==>  5504\n",
      "215 ==>  2048\n",
      "221 ==>  5504\n",
      "229 ==>  2048\n",
      "235 ==>  5504\n",
      "243 ==>  2048\n",
      "249 ==>  5504\n",
      "257 ==>  2048\n",
      "263 ==>  5504\n",
      "271 ==>  2048\n",
      "277 ==>  5504\n",
      "285 ==>  2048\n",
      "291 ==>  5504\n",
      "299 ==>  2048\n",
      "305 ==>  5504\n",
      "313 ==>  2048\n",
      "319 ==>  5504\n",
      "327 ==>  2048\n",
      "333 ==>  5504\n",
      "341 ==>  2048\n",
      "347 ==>  5504\n",
      "355 ==>  2048\n",
      "361 ==>  5504\n",
      "369 ==>  2048\n",
      "375 ==>  5504\n",
      "383 ==>  2048\n",
      "389 ==>  5504\n",
      "397 ==>  2048\n",
      "403 ==>  5504\n",
      "411 ==>  2048\n",
      "417 ==>  5504\n",
      "425 ==>  2048\n",
      "431 ==>  5504\n",
      "***************   Pruning Model   ***************\n",
      "Pruning model\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Model size after pruning:  13.476839424\n",
      "Saving model after pruning to checkpoint dir\n",
      "Model saved\n",
      "***************   Model Pruned Successfully   ***************\n",
      "Model Size after Pruning:  13.476839424\n",
      "evaluating on wikitext2\n",
      "nsamples 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:   0%|                                                    | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WikiText Validation:   8%|███▌                                        | 2/25 [00:01<00:11,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  12%|█████▎                                      | 3/25 [00:01<00:10,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  16%|███████                                     | 4/25 [00:01<00:09,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  20%|████████▊                                   | 5/25 [00:02<00:08,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  24%|██████████▌                                 | 6/25 [00:02<00:08,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  28%|████████████▎                               | 7/25 [00:03<00:07,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  32%|██████████████                              | 8/25 [00:03<00:07,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  36%|███████████████▊                            | 9/25 [00:04<00:06,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  40%|█████████████████▏                         | 10/25 [00:04<00:06,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  44%|██████████████████▉                        | 11/25 [00:04<00:05,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  48%|████████████████████▋                      | 12/25 [00:05<00:05,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  52%|██████████████████████▎                    | 13/25 [00:05<00:04,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  56%|████████████████████████                   | 14/25 [00:06<00:04,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  60%|█████████████████████████▊                 | 15/25 [00:06<00:04,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  64%|███████████████████████████▌               | 16/25 [00:06<00:03,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  68%|█████████████████████████████▏             | 17/25 [00:07<00:03,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  72%|██████████████████████████████▉            | 18/25 [00:07<00:02,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  76%|████████████████████████████████▋          | 19/25 [00:08<00:02,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  80%|██████████████████████████████████▍        | 20/25 [00:08<00:02,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  84%|████████████████████████████████████       | 21/25 [00:08<00:01,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  88%|█████████████████████████████████████▊     | 22/25 [00:09<00:01,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  92%|███████████████████████████████████████▌   | 23/25 [00:09<00:00,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  96%|█████████████████████████████████████████▎ | 24/25 [00:10<00:00,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WikiText Validation: 100%|███████████████████████████████████████████| 25/25 [00:10<00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPL:  17.797422409057617\n",
      "Perplexity on wikitext2:  17.797422409057617\n",
      "Loading checkpoint from /data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/\n",
      "Model passed to evaluation:  LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11:07:59:04,742 WARNING  [task.py:763] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-06-11:07:59:04,744 WARNING  [task.py:775] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2024-06-11:07:59:41,779 WARNING  [task.py:763] [Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-06-11:07:59:41,781 WARNING  [task.py:775] [Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for winogrande contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/winogrande\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2024-06-11:08:03:33,931 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-06-11:08:03:33,933 INFO     [evaluator.py:177] Initializing huggingface model, with arguments: {'pretrained': '/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/'}\n",
      "2024-06-11:08:03:33,945 WARNING  [logging.py:61] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "2024-06-11:08:03:33,946 INFO     [huggingface.py:163] Using device 'cuda'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7197c7b2a244b4892e2253eefb2737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11:08:05:43,425 WARNING  [task.py:763] [Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-06-11:08:05:43,427 WARNING  [task.py:775] [Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-06-11:08:06:18,213 WARNING  [task.py:763] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-06-11:08:06:18,214 WARNING  [task.py:775] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-06-11:08:08:08,024 WARNING  [evaluator.py:239] Overwriting default num_fewshot of openbookqa from None to 0\n",
      "2024-06-11:08:08:08,026 WARNING  [evaluator.py:239] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2024-06-11:08:08:08,027 WARNING  [evaluator.py:239] Overwriting default num_fewshot of boolq from None to 0\n",
      "2024-06-11:08:08:08,027 WARNING  [evaluator.py:239] Overwriting default num_fewshot of rte from None to 0\n",
      "2024-06-11:08:08:08,028 WARNING  [evaluator.py:239] Overwriting default num_fewshot of winogrande from None to 0\n",
      "2024-06-11:08:08:08,028 WARNING  [evaluator.py:239] Overwriting default num_fewshot of arc_easy from None to 0\n",
      "2024-06-11:08:08:08,029 WARNING  [evaluator.py:239] Overwriting default num_fewshot of arc_challenge from None to 0\n",
      "2024-06-11:08:08:08,034 INFO     [task.py:395] Building contexts for openbookqa on rank 0...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 130.98it/s]\n",
      "2024-06-11:08:08:08,814 INFO     [task.py:395] Building contexts for hellaswag on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1876.92it/s]\n",
      "2024-06-11:08:08:08,902 INFO     [task.py:395] Building contexts for boolq on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1591.02it/s]\n",
      "2024-06-11:08:08:08,974 INFO     [task.py:395] Building contexts for rte on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1547.05it/s]\n",
      "2024-06-11:08:08:09,047 INFO     [task.py:395] Building contexts for winogrande on rank 0...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 70315.24it/s]\n",
      "2024-06-11:08:08:09,056 INFO     [task.py:395] Building contexts for arc_easy on rank 0...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 988.01it/s]\n",
      "2024-06-11:08:08:09,169 INFO     [task.py:395] Building contexts for arc_challenge on rank 0...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 961.90it/s]\n",
      "2024-06-11:08:08:09,283 INFO     [evaluator.py:379] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|█████████████████████████████████████████████████████████| 2199/2199 [01:39<00:00, 22.04it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "fatal: not a git repository (or any parent up to mount point /)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "|     Alias     | Acc, None |   Acc StdErr, None   | Acc Norm, None | Acc Norm StdErr, None |\n",
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "|   openbookqa  |    0.21   | 0.04093601807403325  |      0.36      |  0.04824181513244218  |\n",
      "|   hellaswag   |    0.42   | 0.049604496374885836 |      0.58      |  0.049604496374885836 |\n",
      "|     boolq     |    0.62   | 0.048783173121456316 |      None      |          None         |\n",
      "|      rte      |    0.64   | 0.04824181513244218  |      None      |          None         |\n",
      "|   winogrande  |    0.66   | 0.04760952285695237  |      None      |          None         |\n",
      "|    arc_easy   |    0.49   | 0.05024183937956913  |      0.52      |  0.050211673156867795 |\n",
      "| arc_challenge |    0.28   | 0.04512608598542128  |      0.27      |   0.0446196043338474  |\n",
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Gardening provides a sense of accomplishment and tranquility, as you nurture plants and watch them \u001b[0m\u001b[91m grow.\n",
      "The benefits of gardening include:\n",
      "Improved health and wellness.\n",
      "The benefits of a well-designed and well-t\n",
      "The benefits of a well-designed and well-t\n",
      "The benefits of a well-designed and well-\n",
      "There are many benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a well-\n",
      "The benefits of a\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Gardening provides a sense of accomplishment and tranquility, as you nurture plants and watch them \u001b[0m\u001b[91mgrow. The benefits of gardening include:\n",
      "Improved health and wellness.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Family traditions are passed down from generation to generation, creating a sense of continuity and belonging. Whether it's holiday celebrations, special recipes, or annual gatherings, these traditions foster \u001b[0m\u001b[91m a feeling of comfort and joy.\n",
      "These traditions are a great way to bring the family together and to help them learn how to work as a team.\n",
      "These traditions are a great way to help your family learn how to work together and to help you learn how to be a good role model.\n",
      "These traditions are a great way to help your family learn how to be a good role model for their children.\n",
      "These traditions are a great way to help your family learn how to be a good role model for their children.\n",
      "These traditions are a great way to help your family learn how to be a good role model for their children. They are also a great way to help your family learn how to be a good role model for their children.\n",
      "These traditions are a great way to help your family learn how to be a good role model for their children. They are also a great way to help your family learn how to be a good role model for their children. They are also a great way to help your family learn how to be a good role model for their children.\n",
      "These traditions are a great way to help your family learn how to be a good role model for their children. They are also a great way to help you be a good role model for their children.\n",
      "These traditions are a great way to help your family learn how to be a good role model for their children. They are also a great way to help you be a good role model for their children. They are also a great way to help you be a good role model for their children.\n",
      "These traditions are a great way to help your family learn how to be a good role model for their children. They are also a great way to help you be a good role model for their children. They are also a great way to help you be a good role model for their children. They are also a great way to help you be a good role model for their children.\n",
      "These traditions are a great way to help your family learn how to be a good role model for their children. They are also a great way to help you be a good role model for their children. They are also a great way to help you be a good role model for their children. They are also a great way to help you be a good role model for their children. They are also a great way to help you be a good role model for their children.\n",
      "Th\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Family traditions are passed down from generation to generation, creating a sense of continuity and belonging. Whether it's holiday celebrations, special recipes, or annual gatherings, these traditions foster \u001b[0m\u001b[91ma feeling of comfort and joy. These traditions are a great way to bring the family together and to help them learn how to work as a team. These traditions are a great way to help your family learn how to work together and to help you learn how to be a good role model. These traditions are a great way to help your family learn how to be a good role model for their children. They are also a great way to help your family learn how to be a good role model for their children. They are also a great way to help you be a good role model for their children.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future \u001b[0m\u001b[91m, we can expect to see more innovative and elegant designs, as well as more sustainable and digital shows. We can also expect to see more diverse and inclusive designs, as well as more innovative ways to show our individualities.\n",
      "What is the future of the fashion industry?\n",
      "What is the future of the fashion industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is the future of the industry? What is\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future \u001b[0m\u001b[91m, we can expect to see more innovative and elegant designs, as well as more sustainable and digital shows. We can also expect to see more diverse and inclusive designs, as well as more innovative ways to show our individualities.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Artificial intelligence is transforming the healthcare industry by enabling \u001b[0m\u001b[91m it to be more efficient and effective.\n",
      "The healthcare industry is a very large and diverse one. It includes a wide range of medical professionals, medical institutions, and medical technologies.\n",
      "The healthcare industry is growing rapidly.\n",
      "The healthcare industry is changing rapidly.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is changing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is changing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health.\n",
      "The healthcare industry is growing rapidly. The health\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Artificial intelligence is transforming the healthcare industry by enabling \u001b[0m\u001b[91mit to be more efficient and effective. The healthcare industry is a very large and diverse one. It includes a wide range of medical professionals, medical institutions, and medical technologies. The healthcare industry is growing rapidly. The healthcare industry is changing rapidly.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Machine learning algorithms are increasingly being used to predict stock market trends. By analyzing historical data and identifying patterns, these models can \u001b[0m\u001b[91m accur Bedeutungen für die Words bedeuting.\n",
      "The word \"me\" refers to the subject of a sentence. The word \"me\" is a pronoun.\n",
      "The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence.\n",
      "The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence. The word \"me\" is a pronoun referring to the subject of a sentence.\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Machine learning algorithms are increasingly being used to predict stock market trends. By analyzing historical data and identifying patterns, these models can \u001b[0m\u001b[91maccur Bedeutungen für die Words bedeuting. The word \"me\" refers to the subject of a sentence. The word \"me\" is a pronoun. The word \"me\" is a pronoun referring to the subject of a sentence.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The integration of natural language processing with machine learning has opened up new possibilities in human-computer interaction. For instance, chatbots powered by sophisticated NLP algorithms can now understand and respond to user queries with remarkable accuracy. As these technologies continue to evolve, we can expect that \u001b[0m\u001b[91m they will become even more useful and helpful to users.\n",
      "The future of human-computer interaction is always changing. The best way to keep up with the latest technology is to stay informed and engaged.\n",
      "The future of human-computer interaction is always changing.\n",
      "The future of human-computer interaction is always changing. The best way to keep up with the latest technology is to stay informed and engaged.\n",
      "The future of human-computer interaction is always changing. The best way to keep up with the latest technology is to stay informed and engaged. The future of human-computer interaction is always changing. The best way to keep up with the latest technology is to stay informed and engaged. The future of human-computer interaction is always changing. The best way to keep up with the latest technology is to stay informed and engaged. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human-computer interaction is always changing. The future of human\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The integration of natural language processing with machine learning has opened up new possibilities in human-computer interaction. For instance, chatbots powered by sophisticated NLP algorithms can now understand and respond to user queries with remarkable accuracy. As these technologies continue to evolve, we can expect that \u001b[0m\u001b[91mthey will become even more useful and helpful to users. The future of human-computer interaction is always changing. The best way to keep up with the latest technology is to stay informed and engaged.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Self-driving cars rely heavily on sensor data and advanced algorithms to navigate \u001b[0m\u001b[91m safely.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is to avoid the risk of a collision.\n",
      "Their main goal is\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Self-driving cars rely heavily on sensor data and advanced algorithms to navigate \u001b[0m\u001b[91msafely. Their main goal is to avoid the risk of a collision.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m One of the biggest challenges in developing AI systems is ensuring they are ethical and unbiased. Researchers are working on creating frameworks that can \u001b[0m\u001b[91m be used to develop AI systems that are free from such problems.\n",
      "The future of AI is hard to predict, but it is clear that it has the power to change the world for better and worse. It will be a long time before we can fully understand the consequences of AI, but it is important that we are prepared to the best of our ability.\n",
      "The future of AI is hard to predict, but it is clear that it has the power to change the world for better and worse. It will take time for us to fully understand the consequences of AI, but we must be prepared to the best of our ability.\n",
      "The future of AI is hard to predict, but it is clear that it has the power to change the world for better and worse. It will take time for us to fully understand the consequences of AI, but we must be prepared to the best of our ability. The future of AI is hard to predict, but it is clear that it will have a significant impact on the way we live our lives.\n",
      "The future of AI is hard to predict, but it is clear that it will have a significant impact on the way we live our lives.\n",
      "The future of AI is hard to predict, but it is clear that it will have a significant impact on the way we live our lives. It will also have a significant impact on the way we think about it.\n",
      "The future of AI is hard to predict, but it is clear that it will have a significant impact on the way we live our lives. It will also have a significant impact on the way we think about it.\n",
      "The future of AI is hard to predict, but it is clear that it will have a significant impact on the way we live our lives. It will also have a significant impact on the way we think about it.\n",
      "The future of AI is hard to predict, but it is clear that it will have a significant impact on the way we live our lives. It will also have a significant impact on the way we think about it.\n",
      "The future of AI is hard to predict, but it is clear that it will have a significant impact on the way we live our lives. It will also have a significant impact on the way we think about it.\n",
      "The future of AI is hard to predict, but it is clear that it will have a significant impact on the way we live our lives. It will also have a significant impact on the way we\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m One of the biggest challenges in developing AI systems is ensuring they are ethical and unbiased. Researchers are working on creating frameworks that can \u001b[0m\u001b[91mbe used to develop AI systems that are free from such problems. The future of AI is hard to predict, but it is clear that it has the power to change the world for better and worse. It will be a long time before we can fully understand the consequences of AI, but it is important that we are prepared to the best of our ability. It will take time for us to fully understand the consequences of AI, but we must be prepared to the best of our ability. The future of AI is hard to predict, but it is clear that it will have a significant impact on the way we live our lives. It will also have a significant impact on the way we think about it.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m In the field of computer vision, convolutional neural networks have revolutionized the way machines perceive visual information. By mimicking the human visual system, these networks can classify images, detect objects, and even perform image segmentation. This has significant applications in areas such as medical imaging, where AI can assist doctors in diagnosing conditions from X-rays and MRIs. As the technology advances, we may soon see AI systems that \u001b[0m\u001b[91m can even out-perform human doctors.\n",
      "The next one is a very interesting one.\n",
      "The human brain is composed of a number of neurons that are connected to each other and to the brain. This means that the human body is composed of a number of neurons that are connected to each other and to the human body.\n",
      "The fourth one is a very interesting one.\n",
      "The fifth one is a very interesting one.\n",
      "The sixth one is a very interesting one.\n",
      "The seventh one is a very interesting one.\n",
      "The eighth one is a very interesting one.\n",
      "The ninth one is a very interesting one.\n",
      "The tenth one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The twelfth one is a very interesting one.\n",
      "The next one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The twelfth one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The twelfth one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\n",
      "The eleventh one is a very interesting one.\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m In the field of computer vision, convolutional neural networks have revolutionized the way machines perceive visual information. By mimicking the human visual system, these networks can classify images, detect objects, and even perform image segmentation. This has significant applications in areas such as medical imaging, where AI can assist doctors in diagnosing conditions from X-rays and MRIs. As the technology advances, we may soon see AI systems that \u001b[0m\u001b[91mcan even out-perform human doctors. The next one is a very interesting one. The human brain is composed of a number of neurons that are connected to each other and to the brain. This means that the human body is composed of a number of neurons that are connected to each other and to the human body. The fourth one is a very interesting one. The fifth one is a very interesting one. The sixth one is a very interesting one. The seventh one is a very interesting one. The eighth one is a very interesting one. The ninth one is a very interesting one. The tenth one is a very interesting one. The eleventh one is a very interesting one. The twelfth one is a very interesting one.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Reinforcement learning algorithms learn optimal behaviors through \u001b[0m\u001b[91m the process of selecting the best possible action in a given situation.\n",
      "Their main goal is to provide a mechanism for learning the best possible actions to take in a given situation.\n",
      "Their main goal is to provide a method for selecting the best possible actions to take in a.\n",
      "Their main goal is to provide a.\n",
      "Their main goal is to provide a. The.\n",
      "Their main goal is to provide a. The.\n",
      "Their main goal is to provide a. The. The.\n",
      "Their main goal is to provide a. The. The. The.\n",
      "Their main goal is to provide a. The. The. The. The.\n",
      "Their main goal is to provide a. The. The. The. The. The.\n",
      "Their main goal is to provide a. The. The. The. The. The. The.\n",
      "Their main goal is to provide a. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Reinforcement learning algorithms learn optimal behaviors through \u001b[0m\u001b[91mthe process of selecting the best possible action in a given situation. Their main goal is to provide a mechanism for learning the best possible actions to take in a given situation. Their main goal is to provide a method for selecting the best possible actions to take in a. Their main goal is to provide a.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could \u001b[0m\u001b[91m potentially crack any code that has been designed to resist them.\n",
      "This presents a significant concern for those who have been working so hard to keep their codes safe from discovery.\n",
      "How does quantum computing affect the future of cryptography?\n",
      "How can quantum computing affect the future of cryptography?\n",
      "How does quantum computing improve the future of cryptography?\n",
      "How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography?\n",
      "How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography? How does quantum computing improve the future of cryptography?\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could \u001b[0m\u001b[91mpotentially crack any code that has been designed to resist them. This presents a significant concern for those who have been working so hard to keep their codes safe from discovery.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that \u001b[0m\u001b[91m can help us solve some of the most difficult problems humanity has ever faced.\n",
      "Previous PostPrevious 100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that \u001b[0m\u001b[91mcan help us solve some of the most difficult problems humanity has ever faced.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Transfer learning allows models trained on large datasets to be fine-tuned for specific tasks by \u001b[0m\u001b[91m using the same model.\n",
      "\n",
      "\\begin{figure}\n",
      "\\centering\n",
      "\\includegraphics[width=\\linewidth]{fig_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Transfer learning allows models trained on large datasets to be fine-tuned for specific tasks by \u001b[0m\u001b[91musing the same model.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Explainable AI (XAI) is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to \u001b[0m\u001b[91m help human and machine interactions.\n",
      "The next topic is a very important one. It is a very important topic for the future of AI.\n",
      "The topic of AI and its impact on the future of work is a very important one. It has the potential to change the way we do business and live our lives.\n",
      "The topic of AI and its impact on the future of work is a very important one. It has the potential to change the way we do business and live our lives.\n",
      "The topic of AI and its impact on the future of work is a very important one. It is a topic that will affect the way we do business and live our lives.\n",
      "The topic of AI and its impact on the future of work is a very important one. It is a topic that will affect the way we do business and live our lives. It is a topic that will affect the way we do business and live our lives. It is a topic that will affect the way we do business and live our lives. It is a topic that will affect the way we do business and live our lives. It is a topic that will affect the way we do lives. It is a topic that will affect the way we do business and live our lives. It is a topic that will affect the way we do business and live our lives. It is a topic that will affect the way we do business and live our lives. It is a topic that will affect the way we do business and live our lives. It is a topic that will affect the way we do business and live our lives. It is a topic that will affect the way we do business and live our lives. It is a topic that will affect the way we do business and live our lives. It is a topic that will affect the way we do business and live our lives. It is a topic that will affect the way we do business and live our lives. It is a topic that will affect the way we do business and live our lives. It is a topic that will affect the way we do business and live our lives. It is a topic that will affect the way we do business and live our lives. It is a topic that will affect the way we do business and live our lives. It is a topic that will affect the way we do business and live our lives. It is a topic that will affect the way we do business and live our lives. It is a topic that will affect the way we do business and live our lives. It\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Explainable AI (XAI) is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to \u001b[0m\u001b[91mhelp human and machine interactions. The next topic is a very important one. It is a very important topic for the future of AI. The topic of AI and its impact on the future of work is a very important one. It has the potential to change the way we do business and live our lives. It is a topic that will affect the way we do business and live our lives. It is a topic that will affect the way we do lives.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and \u001b[0m\u001b[91m the sun is about to disappear.\n",
      "The sun is a star in the universe.\n",
      "The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe. The sun is a star in the universe\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and \u001b[0m\u001b[91mthe sun is about to disappear.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of \u001b[0m\u001b[91m the world and its people.\n",
      "It can be a great way to meet new friends and make new connections.\n",
      "It can be a great way to learn more about the world and its people.\n",
      "It can be a great way to have fun.\n",
      "It can be a great way to have a good time.\n",
      "It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a great way to have a good time. It can be a\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of \u001b[0m\u001b[91mthe world and its people. It can be a great way to meet new friends and make new connections. It can be a great way to learn more about the world and its people. It can be a great way to have fun. It can be a great way to have a good time.\u001b[0m\n",
      "\n",
      "\n",
      "Pruning model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size after pruning:  13.47264512\n",
      "Model size after pruning:  13.470384128\n",
      "Model size after pruning:  13.466189824\n",
      "Model size after pruning:  13.453041664\n",
      "Model size after pruning:  13.453041664\n",
      "Model size after pruning:  13.451026432\n",
      "Model size after pruning:  13.446832128\n",
      "Model size after pruning:  13.44331776\n",
      "Model size after pruning:  13.44331776\n",
      "Model size after pruning:  13.43619072\n",
      "Model size after pruning:  13.43619072\n",
      "Model size after pruning:  13.426950144\n",
      "Model size after pruning:  13.35984128\n",
      "Model size after pruning:  13.224574976\n",
      "Model size after pruning:  13.157466112\n",
      "Model size after pruning:  13.022199808\n",
      "Model size after pruning:  12.955090944\n",
      "Model size after pruning:  12.81982464\n",
      "Model size after pruning:  12.752715776\n",
      "Model size after pruning:  12.617449472\n",
      "Model size after pruning:  12.550340608\n",
      "Model size after pruning:  12.415074304\n",
      "Model size after pruning:  12.34796544\n",
      "Model size after pruning:  12.212699136\n",
      "Model size after pruning:  12.145590272\n",
      "Model size after pruning:  12.010323968\n",
      "Model size after pruning:  11.943215104\n",
      "Model size after pruning:  11.8079488\n",
      "Model size after pruning:  11.740839936\n",
      "Model size after pruning:  11.605573632\n",
      "Model size after pruning:  11.538464768\n",
      "Model size after pruning:  11.403198464\n",
      "Model size after pruning:  11.3360896\n",
      "Model size after pruning:  11.200823296\n",
      "Model size after pruning:  11.133714432\n",
      "Model size after pruning:  10.998448128\n",
      "Model size after pruning:  10.931339264\n",
      "Model size after pruning:  10.79607296\n",
      "Model size after pruning:  10.728964096\n",
      "Model size after pruning:  10.593697792\n",
      "Model size after pruning:  10.526588928\n",
      "Model size after pruning:  10.391322624\n",
      "Model size after pruning:  10.32421376\n",
      "Model size after pruning:  10.188947456\n",
      "Model size after pruning:  10.121838592\n",
      "Model size after pruning:  9.986572288\n",
      "Model size after pruning:  9.919463424\n",
      "Model size after pruning:  9.78419712\n",
      "Model size after pruning:  9.717088256\n",
      "Model size after pruning:  9.581821952\n",
      "Model size after pruning:  9.514713088\n",
      "Model size after pruning:  9.379446784\n",
      "Model size after pruning:  9.31233792\n",
      "Model size after pruning:  9.177071616\n",
      "Saving model after pruning to checkpoint dir\n",
      "Model saved\n",
      "Real Pruned Model\n",
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (4): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (o_proj): Linear(in_features=3968, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10916, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10916, bias=False)\n",
      "          (down_proj): Linear(in_features=10916, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (5): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (o_proj): Linear(in_features=3968, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10473, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10473, bias=False)\n",
      "          (down_proj): Linear(in_features=10473, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (6): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10926, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10926, bias=False)\n",
      "          (down_proj): Linear(in_features=10926, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (7): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (o_proj): Linear(in_features=3968, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10865, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10865, bias=False)\n",
      "          (down_proj): Linear(in_features=10865, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (8): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10718, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10718, bias=False)\n",
      "          (down_proj): Linear(in_features=10718, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (9): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10632, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10632, bias=False)\n",
      "          (down_proj): Linear(in_features=10632, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (10-30): 21 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2048, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2048, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (down_proj): Linear(in_features=5504, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (31): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n",
      "Real Pruned Model Size\n",
      "9.177071616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short Context: 20.504989174926486 tokens/sec, 516 tokens (including full prompt)\n",
      "Long Context: 49.769442485619344 tokens/sec, 1288 tokens (including full prompt)\n",
      "Average:  27.971937052617335 tokens/sec\n",
      "***************   Experiment completed successfully Successfully   ***************\n"
     ]
    }
   ],
   "source": [
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9462c6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T02:54:23.889547Z",
     "start_time": "2024-06-11T02:54:23.867697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4588531712"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db025774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d4c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f303338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e2b72b0",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf54a21c",
   "metadata": {},
   "source": [
    "## Experiment 2396 --> PreserveRatio=0.95, lbound=0.8, rbound=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a66b9ec0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T03:07:02.787246Z",
     "start_time": "2024-05-25T03:07:02.783634Z"
    }
   },
   "outputs": [],
   "source": [
    "pruning_dict = \"pruning_dict_1.0_0.8_1.0_chat_2396.json\"\n",
    "save_dir = \"/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/\"\n",
    "\n",
    "p = pruning_dict.split(\"_\")[-1].split(\".\")[-2]\n",
    "output_dir = \"/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints//\" + p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88ab3a7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T03:07:03.077956Z",
     "start_time": "2024-05-25T03:07:03.074311Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment = ExperimentRunner(pipeline, tokenizer, pruning_dict, \n",
    "                 save_dir=save_dir, output_dir=output_dir, ignored_layers=None, \n",
    "                 use_template=use_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5a75283",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T03:46:49.437250Z",
     "start_time": "2024-05-25T03:07:03.925278Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************   Running Experiment   ***************\n",
      "61 ==>  4096\n",
      "67 ==>  11007\n",
      "75 ==>  4096\n",
      "81 ==>  11007\n",
      "89 ==>  4096\n",
      "95 ==>  11005\n",
      "103 ==>  4096\n",
      "109 ==>  11007\n",
      "117 ==>  4096\n",
      "123 ==>  11008\n",
      "131 ==>  4096\n",
      "137 ==>  11008\n",
      "145 ==>  4096\n",
      "151 ==>  11004\n",
      "159 ==>  4096\n",
      "165 ==>  11006\n",
      "173 ==>  4096\n",
      "179 ==>  11002\n",
      "187 ==>  4096\n",
      "193 ==>  11007\n",
      "201 ==>  4096\n",
      "207 ==>  11008\n",
      "215 ==>  4096\n",
      "221 ==>  11006\n",
      "229 ==>  4096\n",
      "235 ==>  11008\n",
      "243 ==>  4096\n",
      "249 ==>  11008\n",
      "257 ==>  4096\n",
      "263 ==>  11004\n",
      "271 ==>  4096\n",
      "277 ==>  11007\n",
      "285 ==>  4096\n",
      "291 ==>  11006\n",
      "299 ==>  4096\n",
      "305 ==>  11006\n",
      "313 ==>  4096\n",
      "319 ==>  9577\n",
      "327 ==>  3328\n",
      "333 ==>  8806\n",
      "341 ==>  3328\n",
      "347 ==>  8806\n",
      "355 ==>  3328\n",
      "361 ==>  8806\n",
      "369 ==>  3328\n",
      "375 ==>  8806\n",
      "383 ==>  3328\n",
      "389 ==>  8806\n",
      "***************   Pruning Model   ***************\n",
      "Pruning model\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Saving model after pruning to checkpoint dir\n",
      "Model saved\n",
      "***************   Model Pruned Successfully   ***************\n",
      "Model Size after Pruning:  13.51458816\n",
      "evaluating on wikitext2\n",
      "nsamples 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:   0%|                                                                                                                                                                                                                                                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:   4%|████████████▎                                                                                                                                                                                                                                                                                                      | 1/25 [00:01<00:30,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:   8%|████████████████████████▌                                                                                                                                                                                                                                                                                          | 2/25 [00:01<00:19,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  12%|████████████████████████████████████▊                                                                                                                                                                                                                                                                              | 3/25 [00:02<00:16,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  16%|█████████████████████████████████████████████████                                                                                                                                                                                                                                                                  | 4/25 [00:02<00:13,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  20%|█████████████████████████████████████████████████████████████▍                                                                                                                                                                                                                                                     | 5/25 [00:03<00:12,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  24%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                                                                         | 6/25 [00:04<00:11,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  28%|█████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                                                                                             | 7/25 [00:04<00:11,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  32%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                                                                                | 8/25 [00:05<00:10,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  36%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                                    | 9/25 [00:05<00:09,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  40%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                                                       | 10/25 [00:06<00:09,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  44%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                           | 11/25 [00:07<00:08,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  48%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                               | 12/25 [00:07<00:07,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  52%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                                   | 13/25 [00:08<00:07,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                      | 14/25 [00:08<00:06,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                          | 15/25 [00:09<00:05,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                              | 16/25 [00:10<00:05,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                  | 17/25 [00:10<00:04,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                     | 18/25 [00:11<00:04,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                         | 19/25 [00:11<00:03,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                             | 20/25 [00:12<00:03,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                 | 21/25 [00:13<00:02,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 22/25 [00:13<00:01,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 23/25 [00:14<00:01,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 24/25 [00:14<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WikiText Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:15<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPL:  6.0593366622924805\n",
      "Perplexity on wikitext2:  6.0593366622924805\n",
      "Loading checkpoint from /data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model passed to evaluation:  LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-25:08:40:07,523 WARNING  [task.py:763] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-05-25:08:40:07,527 WARNING  [task.py:775] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2024-05-25:08:40:18,079 WARNING  [task.py:763] [Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-05-25:08:40:18,115 WARNING  [task.py:775] [Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for winogrande contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/winogrande\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2024-05-25:08:41:11,229 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-05-25:08:41:11,231 INFO     [evaluator.py:177] Initializing huggingface model, with arguments: {'pretrained': '/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/'}\n",
      "2024-05-25:08:41:11,253 WARNING  [logging.py:61] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "2024-05-25:08:41:11,256 INFO     [huggingface.py:163] Using device 'cuda'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b32f46fe995408f8285a3071835f9f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-25:08:41:46,031 WARNING  [task.py:763] [Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-05-25:08:41:46,038 WARNING  [task.py:775] [Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-05-25:08:42:30,013 WARNING  [task.py:763] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-05-25:08:42:30,027 WARNING  [task.py:775] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-05-25:08:42:36,228 WARNING  [evaluator.py:239] Overwriting default num_fewshot of boolq from None to 0\n",
      "2024-05-25:08:42:36,234 WARNING  [evaluator.py:239] Overwriting default num_fewshot of arc_challenge from None to 0\n",
      "2024-05-25:08:42:36,235 WARNING  [evaluator.py:239] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2024-05-25:08:42:36,236 WARNING  [evaluator.py:239] Overwriting default num_fewshot of openbookqa from None to 0\n",
      "2024-05-25:08:42:36,237 WARNING  [evaluator.py:239] Overwriting default num_fewshot of winogrande from None to 0\n",
      "2024-05-25:08:42:36,238 WARNING  [evaluator.py:239] Overwriting default num_fewshot of arc_easy from None to 0\n",
      "2024-05-25:08:42:36,239 WARNING  [evaluator.py:239] Overwriting default num_fewshot of rte from None to 0\n",
      "2024-05-25:08:42:36,245 INFO     [task.py:395] Building contexts for boolq on rank 0...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1505.02it/s]\n",
      "2024-05-25:08:42:36,329 INFO     [task.py:395] Building contexts for arc_challenge on rank 0...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 348.28it/s]\n",
      "2024-05-25:08:42:36,634 INFO     [task.py:395] Building contexts for hellaswag on rank 0...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1458.08it/s]\n",
      "2024-05-25:08:42:36,739 INFO     [task.py:395] Building contexts for openbookqa on rank 0...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1130.67it/s]\n",
      "2024-05-25:08:42:36,850 INFO     [task.py:395] Building contexts for winogrande on rank 0...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 52382.96it/s]\n",
      "2024-05-25:08:42:36,874 INFO     [task.py:395] Building contexts for arc_easy on rank 0...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 523.07it/s]\n",
      "2024-05-25:08:42:37,101 INFO     [task.py:395] Building contexts for rte on rank 0...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 248.14it/s]\n",
      "2024-05-25:08:42:37,541 INFO     [evaluator.py:379] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2199/2199 [03:57<00:00,  9.24it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "fatal: not a git repository (or any parent up to mount point /)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "|     Alias     | Acc, None |   Acc StdErr, None   | Acc Norm, None | Acc Norm StdErr, None |\n",
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "|     boolq     |    0.74   | 0.04408440022768078  |      None      |          None         |\n",
      "| arc_challenge |    0.42   | 0.04960449637488584  |      0.43      |  0.049756985195624284 |\n",
      "|   hellaswag   |    0.53   | 0.050161355804659205 |      0.68      |  0.04688261722621504  |\n",
      "|   openbookqa  |    0.31   | 0.04648231987117316  |      0.44      |  0.04988876515698589  |\n",
      "|   winogrande  |    0.69   | 0.04648231987117316  |      None      |          None         |\n",
      "|    arc_easy   |    0.7    | 0.046056618647183814 |      0.76      |  0.04292346959909284  |\n",
      "|      rte      |    0.72   | 0.045126085985421276 |      None      |          None         |\n",
      "+---------------+-----------+----------------------+----------------+-----------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Gardening provides a sense of accomplishment and tranquility, as you nurture plants and watch them \u001b[0m\u001b[91m grow.\n",
      "Gardening is a great way to get outside and enjoy the fresh air. It’s also a great way to get some exercise.\n",
      "Gardening is a great way to get some fresh air and exercise. It’s also a great way to relax and de-stress.\n",
      "Gardening is a great way to get some fresh air and exercise. It’s also a great way to relax and de-stress.\n",
      "Gardening is a great way to get some fresh air and exercise. It’s also a great way to relax and de-stress. Gardening is a great way to get some fresh air and exercise. It’s also a great way to relax and de-stress.\n",
      "Gardening is a great way to get some fresh air and exercise. It’s also a great way to relax and de-stress. Gardening is a great way to get some fresh air and exercise. It’s also a great way to relax and de-stress. Gardening is a great way to get some fresh air and exercise. It’s also a great way to relax and de-stress. Gardening is a great way to get some fresh air and exercise. It’s also a great way to relax and de-stress. Gardening is a great way to get some fresh air and exercise. It’s also a great way to relax and de-stress. Gardening is a great way to get some fresh air and exercise. It’s also a great way to relax and de-stress. Gardening is a great way to get some fresh air and exercise. It’s also a great way to relax and de-stress. Gardening is a great way to get some fresh air and exercise. It’s also a great way to relax and de-stress. Gardening is a great way to get some fresh air and exercise. It’s also a great way to relax and de-stress. Gardening is a great way to get some fresh air and exercise. It’s also a great way to relax and de-stress. Gardening is a great way to get some fresh air and exercise. It’s also a great way to relax and de-stress. Gardening is a great way to get some fresh air and exercise. It’s also a great way to relax and de-stress. Gardening is a great way to get some\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Gardening provides a sense of accomplishment and tranquility, as you nurture plants and watch them \u001b[0m\u001b[91mgrow. Gardening is a great way to get outside and enjoy the fresh air. It’s also a great way to get some exercise. Gardening is a great way to get some fresh air and exercise. It’s also a great way to relax and de-stress.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Family traditions are passed down from generation to generation, creating a sense of continuity and belonging. Whether it's holiday celebrations, special recipes, or annual gatherings, these traditions foster \u001b[0m\u001b[91m a sense of connection and community.\n",
      "Family traditions can also be a source of pride and identity. They can be a way to showcase a family's culture, values, and beliefs. For example, a family may have a tradition of celebrating a particular holiday in a specific way, such as a special meal or a cultural dance.\n",
      "Family traditions can also be a source of comfort and security. They can provide a sense of stability and predictability in an ever-changing world. They can also be a way to teach children about the importance of family and the value of tradition.\n",
      "Family traditions can also be a source of fun and entertainment. They can be a way to bring people together and create lasting memories. They can also be a way to celebrate special occasions and milestones.\n",
      "Family traditions can also be a source of inspiration. They can be a way to explore new ideas and experiences. They can also be a way to challenge assumptions and explore different perspectives.\n",
      "Family traditions can also be a source of strength. They can be a way to support each other through difficult times. They can also be a way to celebrate successes and achievements.\n",
      "Family traditions can also be a source of unity. They can be a way to bring people together and create a sense of belonging. They can also be a way to celebrate diversity and respect different perspectives.\n",
      "Family traditions can also be a source of wisdom. They can be a way to learn from the past and apply it to the present. They can also be a way to teach children about the importance of family and the value of tradition.\n",
      "Family traditions can also be a source of joy. They can be a way to celebrate special occasions and milestones. They can also be a way to create lasting memories and relationships.\n",
      "Family traditions can also be a source of comfort. They can be a way to provide a sense of stability and predictability in an ever-changing world. They can also be a way to showcase a family's culture, values, and beliefs.\n",
      "Family traditions can also be a source of strength. They can be a way to support each other through difficult times. They can also be a way to celebrate successes and achievements.\n",
      "Family traditions can also be a source of unity. They can be a way to bring people together and create a sense of belonging\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Family traditions are passed down from generation to generation, creating a sense of continuity and belonging. Whether it's holiday celebrations, special recipes, or annual gatherings, these traditions foster \u001b[0m\u001b[91ma sense of connection and community. Family traditions can also be a source of pride and identity. They can be a way to showcase a family's culture, values, and beliefs. For example, a family may have a tradition of celebrating a particular holiday in a specific way, such as a special meal or a cultural dance. Family traditions can also be a source of comfort and security. They can provide a sense of stability and predictability in an ever-changing world. They can also be a way to teach children about the importance of family and the value of tradition. Family traditions can also be a source of fun and entertainment. They can be a way to bring people together and create lasting memories. They can also be a way to celebrate special occasions and milestones. Family traditions can also be a source of inspiration. They can be a way to explore new ideas and experiences. They can also be a way to challenge assumptions and explore different perspectives. Family traditions can also be a source of strength. They can be a way to support each other through difficult times. They can also be a way to celebrate successes and achievements. Family traditions can also be a source of unity. They can be a way to bring people together and create a sense of belonging. They can also be a way to celebrate diversity and respect different perspectives. Family traditions can also be a source of wisdom. They can be a way to learn from the past and apply it to the present. Family traditions can also be a source of joy. They can be a way to celebrate special occasions and milestones. They can also be a way to create lasting memories and relationships. Family traditions can also be a source of comfort. They can be a way to provide a sense of stability and predictability in an ever-changing world.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future \u001b[0m\u001b[91m, fashion may even become more accessible and affordable, allowing everyone to participate in the creative process.\n",
      "The fashion industry is a complex and multifaceted industry that encompasses a wide range of activities, including design, production, marketing, and retail. The industry is driven by consumer demand for new and innovative styles, and it is constantly evolving to meet the changing needs of consumers.\n",
      "The fashion industry is a global industry, with major markets in Europe, the United States, and Asia. It is a highly competitive industry, with many companies vying for market share. The industry is also highly fragmented, with many small and independent companies operating in niche markets.\n",
      "The fashion industry is a major contributor to the global economy, with an estimated value of over $2.4 trillion in 2019. It employs millions of people around the world, from designers to models to retail workers. The industry is also a major source of revenue for many countries, with France, Italy, and the United States being some of the largest exporters of fashion products.\n",
      "The fashion industry is a complex and multifaceted industry that encompasses a wide range of activities, including design, production, marketing, and retail. The industry is driven by consumer demand for new and innovative styles, and it is constantly evolving to meet the changing needs of consumers. The industry is a major contributor to the global economy, employing millions of people around the world and generating significant revenue for many countries. As the industry continues to evolve, it is likely to remain a significant player in the global economy for many years to come.\n",
      "The fashion industry is a highly competitive and dynamic industry that is constantly evolving to meet the changing needs of consumers. With the rise of social media and the internet, the industry has become even more globalized, allowing for greater access to new styles and trends from around the world.\n",
      "The fashion industry is a major contributor to the global economy, with an estimated value of over $2.4 trillion in 2019. It employs millions of people around the world, from designers to models to retail workers. The industry is also a major source of revenue for many countries, with France, Italy, and the United States being some of the largest exporters of fashion products.\n",
      "The\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future \u001b[0m\u001b[91m, fashion may even become more accessible and affordable, allowing everyone to participate in the creative process. The fashion industry is a complex and multifaceted industry that encompasses a wide range of activities, including design, production, marketing, and retail. The industry is driven by consumer demand for new and innovative styles, and it is constantly evolving to meet the changing needs of consumers. The fashion industry is a global industry, with major markets in Europe, the United States, and Asia. It is a highly competitive industry, with many companies vying for market share. The industry is also highly fragmented, with many small and independent companies operating in niche markets. The fashion industry is a major contributor to the global economy, with an estimated value of over $2. 4 trillion in 2019. It employs millions of people around the world, from designers to models to retail workers. The industry is also a major source of revenue for many countries, with France, Italy, and the United States being some of the largest exporters of fashion products. The industry is a major contributor to the global economy, employing millions of people around the world and generating significant revenue for many countries. As the industry continues to evolve, it is likely to remain a significant player in the global economy for many years to come. The fashion industry is a highly competitive and dynamic industry that is constantly evolving to meet the changing needs of consumers. With the rise of social media and the internet, the industry has become even more globalized, allowing for greater access to new styles and trends from around the world.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Artificial intelligence is transforming the healthcare industry by enabling \u001b[0m\u001b[91m hospitals to improve patient care, reduce costs, and increase efficiency.\n",
      "One of the most significant ways that AI is being used in healthcare is through the development of medical imaging software. This software is able to analyze medical images, such as X-rays and MRIs, and identify potential abnormalities that may not be visible to the human eye. This technology is particularly useful in the early detection of cancer and other diseases, as it can help doctors to identify potential problems before they become more serious.\n",
      "Another way that AI is being used in healthcare is through the development of virtual assistants. These virtual assistants are able to answer patient’s questions, provide information about their condition, and even schedule appointments. This technology is particularly useful for patients who may not have access to a doctor or who may not be able to communicate in person.\n",
      "AI is also being used to improve the accuracy of diagnosis. By analyzing large amounts of data, AI can identify patterns and trends that may not be apparent to human doctors. This technology is particularly useful in the diagnosis of rare diseases, as it can help doctors to identify potential problems more quickly and accurately.\n",
      "Finally, AI is being used to improve the efficiency of healthcare systems. By automating routine tasks, AI can free up healthcare workers to focus on more complex tasks. This technology is particularly useful in the management of patient records, as it can help to ensure that all information is accurate and up-to-date.\n",
      "Overall, AI is having a significant impact on the healthcare industry. By enabling hospitals to improve patient care, reduce costs, and increase efficiency, AI is helping to make healthcare more accessible and affordable for everyone.\n",
      "The Impact of Artificial Intelligence on the Healthcare Industry\n",
      "The healthcare industry is undergoing a revolutionary transformation with the introduction of artificial intelligence (AI). AI is a technology that enables machines to learn, understand, and make decisions on their own. It is being used in a variety of ways to improve the quality of care and reduce costs in the healthcare industry.\n",
      "One of the most significant ways that AI is being used in healthcare is through the development of medical imaging software. This software is able to analyze medical images, such as X-rays and MRIs, and identify potential abnormalities that may not be visible to the human\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Artificial intelligence is transforming the healthcare industry by enabling \u001b[0m\u001b[91mhospitals to improve patient care, reduce costs, and increase efficiency. One of the most significant ways that AI is being used in healthcare is through the development of medical imaging software. This software is able to analyze medical images, such as X-rays and MRIs, and identify potential abnormalities that may not be visible to the human eye. This technology is particularly useful in the early detection of cancer and other diseases, as it can help doctors to identify potential problems before they become more serious. Another way that AI is being used in healthcare is through the development of virtual assistants. These virtual assistants are able to answer patient’s questions, provide information about their condition, and even schedule appointments. This technology is particularly useful for patients who may not have access to a doctor or who may not be able to communicate in person. AI is also being used to improve the accuracy of diagnosis. By analyzing large amounts of data, AI can identify patterns and trends that may not be apparent to human doctors. This technology is particularly useful in the diagnosis of rare diseases, as it can help doctors to identify potential problems more quickly and accurately. Finally, AI is being used to improve the efficiency of healthcare systems. By automating routine tasks, AI can free up healthcare workers to focus on more complex tasks. This technology is particularly useful in the management of patient records, as it can help to ensure that all information is accurate and up-to-date. Overall, AI is having a significant impact on the healthcare industry. By enabling hospitals to improve patient care, reduce costs, and increase efficiency, AI is helping to make healthcare more accessible and affordable for everyone. The Impact of Artificial Intelligence on the Healthcare Industry\n",
      "The healthcare industry is undergoing a revolutionary transformation with the introduction of artificial intelligence (AI). AI is a technology that enables machines to learn, understand, and make decisions on their own. It is being used in a variety of ways to improve the quality of care and reduce costs in the healthcare industry.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Machine learning algorithms are increasingly being used to predict stock market trends. By analyzing historical data and identifying patterns, these models can \u001b[0m\u001b[91m generate predictions about future price movements.\n",
      "One of the most popular machine learning algorithms for stock market prediction is the support vector machine (SVM). SVMs are a type of supervised learning algorithm that can be used to classify data points into different categories. In the context of stock market prediction, SVMs can be used to predict whether a stock will rise or fall in price over a certain period of time.\n",
      "Another popular machine learning algorithm for stock market prediction is the neural network. Neural networks are a type of deep learning algorithm that can be used to identify patterns in large datasets. In the context of stock market prediction, neural networks can be used to identify patterns in historical data that may indicate future price movements.\n",
      "Machine learning algorithms are also being used to generate trading signals. By analyzing historical data and identifying patterns, these models can generate signals that indicate when it is a good time to buy or sell a stock.\n",
      "In conclusion, machine learning algorithms are being increasingly used to predict stock market trends and generate trading signals. By analyzing historical data and identifying patterns, these models can generate predictions about future price movements and generate trading signals that can be used to make profitable trades.\n",
      "The use of machine learning algorithms in the stock market has been a topic of much debate in recent years. While some argue that these algorithms are a valuable tool for investors, others believe that they are a threat to the integrity of the market. In this article, we will explore the pros and cons of using machine learning algorithms in the stock market.\n",
      "One of the main advantages of using machine learning algorithms in the stock market is that they can help investors to make more informed decisions. By analyzing large amounts of data, these algorithms can identify patterns and trends that may not be apparent to human investors. This can help investors to make more accurate predictions about the future performance of a stock.\n",
      "Another advantage of using machine learning algorithms in the stock market is that they can help to reduce the risk of making bad investment decisions. By analyzing large amounts of data, these algorithms can identify patterns and trends that may not be apparent to human investors. This can help investors to avoid making bad investment decisions that could lead to significant losses.\n",
      "However, there are also some potential drawbacks to using machine learning algorithms in the stock market. One of the main concerns is that these algorithms may not be able to accurately predict the future performance\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Machine learning algorithms are increasingly being used to predict stock market trends. By analyzing historical data and identifying patterns, these models can \u001b[0m\u001b[91mgenerate predictions about future price movements. One of the most popular machine learning algorithms for stock market prediction is the support vector machine (SVM). SVMs are a type of supervised learning algorithm that can be used to classify data points into different categories. In the context of stock market prediction, SVMs can be used to predict whether a stock will rise or fall in price over a certain period of time. Another popular machine learning algorithm for stock market prediction is the neural network. Neural networks are a type of deep learning algorithm that can be used to identify patterns in large datasets. In the context of stock market prediction, neural networks can be used to identify patterns in historical data that may indicate future price movements. Machine learning algorithms are also being used to generate trading signals. By analyzing historical data and identifying patterns, these models can generate signals that indicate when it is a good time to buy or sell a stock. In conclusion, machine learning algorithms are being increasingly used to predict stock market trends and generate trading signals. By analyzing historical data and identifying patterns, these models can generate predictions about future price movements and generate trading signals that can be used to make profitable trades. The use of machine learning algorithms in the stock market has been a topic of much debate in recent years. While some argue that these algorithms are a valuable tool for investors, others believe that they are a threat to the integrity of the market. In this article, we will explore the pros and cons of using machine learning algorithms in the stock market. One of the main advantages of using machine learning algorithms in the stock market is that they can help investors to make more informed decisions. By analyzing large amounts of data, these algorithms can identify patterns and trends that may not be apparent to human investors. This can help investors to make more accurate predictions about the future performance of a stock. Another advantage of using machine learning algorithms in the stock market is that they can help to reduce the risk of making bad investment decisions. This can help investors to avoid making bad investment decisions that could lead to significant losses. However, there are also some potential drawbacks to using machine learning algorithms in the stock market.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The integration of natural language processing with machine learning has opened up new possibilities in human-computer interaction. For instance, chatbots powered by sophisticated NLP algorithms can now understand and respond to user queries with remarkable accuracy. As these technologies continue to evolve, we can expect that \u001b[0m\u001b[91m they will become even more powerful and intuitive, enabling us to interact with computers in a more natural and intuitive way.\n",
      "The future of human-computer interaction is bright, with new technologies emerging every day that are changing the way we interact with computers. From virtual reality to augmented reality, from natural language processing to machine learning, these technologies are transforming the way we work, play, and communicate. As these technologies continue to evolve, we can expect that they will become even more powerful and intuitive, enabling us to interact with computers in a more natural and intuitive way.\n",
      "Previous articleThe Future of Human-Computer Interaction: How AI and Machine Learning are Changing the Way We Work\n",
      "Next articleThe Future of Human-Computer Interaction: How Virtual Reality and Augmented Reality are Changing the Way We Experience the World\n",
      "The Future of Human-Computer Interaction: How Virtual Reality and Augmented Reality are Changing the Way We Experience the World\n",
      "The Future of Human-Computer Interaction: How AI and Machine Learning are Changing the Way We Work\n",
      "The Future of Human-Computer Interaction: How Virtual Reality and Augmented Reality are Changing the Way We Experience the World The future of human-computer interaction is bright, with new technologies emerging every day that are changing the way we interact with computers. From virtual reality to augmented reality, from natural language processing to machine learning, these technologies are transforming the way we work, play, and communicate. As these technologies continue to evolve, we can expect that they will become even more powerful and intuitive, enabling us to interact with computers in a more natural and intuitive way.\n",
      "The Future of Human-Computer Interaction: How AI and Machine Learning are Changing the Way We Work The future of human-computer interaction is bright, with new technologies emerging every day that are changing the way we interact with computers. From virtual reality to augmented reality, from natural language processing to machine learning, these technologies are transforming the way we work, play, and communicate. As these technologies continue to evolve, we can expect that they will become even more powerful and intuitive, enabling us to interact with computers in a more natural and intuitive way.\n",
      "The Future of Human-Computer Interaction: How Virtual Reality\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The integration of natural language processing with machine learning has opened up new possibilities in human-computer interaction. For instance, chatbots powered by sophisticated NLP algorithms can now understand and respond to user queries with remarkable accuracy. As these technologies continue to evolve, we can expect that \u001b[0m\u001b[91mthey will become even more powerful and intuitive, enabling us to interact with computers in a more natural and intuitive way. The future of human-computer interaction is bright, with new technologies emerging every day that are changing the way we interact with computers. From virtual reality to augmented reality, from natural language processing to machine learning, these technologies are transforming the way we work, play, and communicate. As these technologies continue to evolve, we can expect that they will become even more powerful and intuitive, enabling us to interact with computers in a more natural and intuitive way. Previous articleThe Future of Human-Computer Interaction: How AI and Machine Learning are Changing the Way We Work\n",
      "Next articleThe Future of Human-Computer Interaction: How Virtual Reality and Augmented Reality are Changing the Way We Experience the World\n",
      "The Future of Human-Computer Interaction: How Virtual Reality and Augmented Reality are Changing the Way We Experience the World\n",
      "The Future of Human-Computer Interaction: How AI and Machine Learning are Changing the Way We Work\n",
      "The Future of Human-Computer Interaction: How Virtual Reality and Augmented Reality are Changing the Way We Experience the World The future of human-computer interaction is bright, with new technologies emerging every day that are changing the way we interact with computers. The Future of Human-Computer Interaction: How AI and Machine Learning are Changing the Way We Work The future of human-computer interaction is bright, with new technologies emerging every day that are changing the way we interact with computers.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Self-driving cars rely heavily on sensor data and advanced algorithms to navigate \u001b[0m\u001b[91m safely and efficiently.\n",
      "The use of AI in self-driving cars has several advantages. First, it allows the car to make decisions quickly and accurately, based on real-time data from its sensors. This means that the car can avoid potential hazards and navigate safely in a variety of situations.\n",
      "Second, AI can be used to optimize the car’s route, taking into account factors such as traffic patterns, weather conditions, and road conditions. This can help the car to arrive at its destination more quickly and efficiently.\n",
      "Third, AI can be used to improve the car’s performance in difficult driving conditions. For example, it can be used to detect and avoid obstacles in low-light conditions, or to navigate through heavy traffic.\n",
      "Finally, AI can be used to improve the car’s safety features. For example, it can be used to detect and avoid potential hazards, such as pedestrians or other vehicles, and to respond quickly to any emergency situations.\n",
      "Overall, the use of AI in self-driving cars has the potential to revolutionize the way we travel. It can help to improve safety, efficiency, and convenience, and to reduce the environmental impact of transportation.\n",
      "The use of artificial intelligence (AI) in self-driving cars has been a topic of much debate in recent years. While some argue that AI is a necessary component of autonomous vehicles, others are concerned about the potential risks and ethical implications of such technology.\n",
      "One of the main arguments in favor of the use of AI in self-driving cars is that it can improve safety. AI-powered systems can detect and respond to potential hazards more quickly and accurately than a human driver. This could reduce the number of accidents caused by human error.\n",
      "Another argument in favor of the use of AI in self-driving cars is that it can reduce the environmental impact of transportation. AI-powered systems can optimize routes and reduce the amount of time spent in traffic, which could reduce emissions from cars.\n",
      "However, there are also concerns about the use of AI in self-driving cars. Some people are concerned that AI-powered systems could be vulnerable to hacking or malfunctioning, which could lead to accidents. Others are concerned about the potential for AI to be used for\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Self-driving cars rely heavily on sensor data and advanced algorithms to navigate \u001b[0m\u001b[91msafely and efficiently. The use of AI in self-driving cars has several advantages. First, it allows the car to make decisions quickly and accurately, based on real-time data from its sensors. This means that the car can avoid potential hazards and navigate safely in a variety of situations. Second, AI can be used to optimize the car’s route, taking into account factors such as traffic patterns, weather conditions, and road conditions. This can help the car to arrive at its destination more quickly and efficiently. Third, AI can be used to improve the car’s performance in difficult driving conditions. For example, it can be used to detect and avoid obstacles in low-light conditions, or to navigate through heavy traffic. Finally, AI can be used to improve the car’s safety features. For example, it can be used to detect and avoid potential hazards, such as pedestrians or other vehicles, and to respond quickly to any emergency situations. Overall, the use of AI in self-driving cars has the potential to revolutionize the way we travel. It can help to improve safety, efficiency, and convenience, and to reduce the environmental impact of transportation. The use of artificial intelligence (AI) in self-driving cars has been a topic of much debate in recent years. While some argue that AI is a necessary component of autonomous vehicles, others are concerned about the potential risks and ethical implications of such technology. One of the main arguments in favor of the use of AI in self-driving cars is that it can improve safety. AI-powered systems can detect and respond to potential hazards more quickly and accurately than a human driver. This could reduce the number of accidents caused by human error. Another argument in favor of the use of AI in self-driving cars is that it can reduce the environmental impact of transportation. AI-powered systems can optimize routes and reduce the amount of time spent in traffic, which could reduce emissions from cars. However, there are also concerns about the use of AI in self-driving cars. Some people are concerned that AI-powered systems could be vulnerable to hacking or malfunctioning, which could lead to accidents.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m One of the biggest challenges in developing AI systems is ensuring they are ethical and unbiased. Researchers are working on creating frameworks that can \u001b[0m\u001b[91m help ensure that AI systems are not discriminatory or biased in any way.\n",
      "One of the most important aspects of AI is its ability to learn and adapt. As more data becomes available, AI systems will be able to learn and improve over time. This will allow them to become more accurate and efficient in their tasks.\n",
      "AI is a rapidly growing field with a wide range of applications. From automating tasks to creating new products, AI is changing the way we live and work. As the technology continues to evolve, it is likely that AI will become even more powerful and widespread.\n",
      "AI is a rapidly growing field with a wide range of applications. From automating tasks to creating new products, AI is changing the way we live and work. As the technology continues to evolve, it is likely that AI will become even more powerful and widespread. With the right tools and resources, anyone can get started with AI.\n",
      "AI is a rapidly growing field with a wide range of applications. From automating tasks to creating new products, AI is changing the way we live and work. As the technology continues to evolve, it is likely that AI will become even more powerful and widespread. With the right tools and resources, anyone can get started with AI. By understanding the basics of AI, you can begin to explore the possibilities of this exciting technology.\n",
      "AI is a rapidly growing field with a wide range of applications. From automating tasks to creating new products, AI is changing the way we live and work. As the technology continues to evolve, it is likely that AI will become even more powerful and widespread. With the right tools and resources, anyone can get started with AI. By understanding the basics of AI, you can begin to explore the possibilities of this exciting technology.\n",
      "AI is a rapidly growing field with a wide range of applications. From automating tasks to creating new products, AI is changing the way we live and work. As the technology continues to evolve, it is likely that AI will become even more powerful and widespread. With the right tools and resources, anyone can get started with AI. By understanding the basics of AI, you can begin to explore the possibilities of this exciting technology. With the right tools and resources, anyone can get started with AI. By understanding the basics of A\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m One of the biggest challenges in developing AI systems is ensuring they are ethical and unbiased. Researchers are working on creating frameworks that can \u001b[0m\u001b[91mhelp ensure that AI systems are not discriminatory or biased in any way. One of the most important aspects of AI is its ability to learn and adapt. As more data becomes available, AI systems will be able to learn and improve over time. This will allow them to become more accurate and efficient in their tasks. AI is a rapidly growing field with a wide range of applications. From automating tasks to creating new products, AI is changing the way we live and work. As the technology continues to evolve, it is likely that AI will become even more powerful and widespread. With the right tools and resources, anyone can get started with AI. By understanding the basics of AI, you can begin to explore the possibilities of this exciting technology.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m In the field of computer vision, convolutional neural networks have revolutionized the way machines perceive visual information. By mimicking the human visual system, these networks can classify images, detect objects, and even perform image segmentation. This has significant applications in areas such as medical imaging, where AI can assist doctors in diagnosing conditions from X-rays and MRIs. As the technology advances, we may soon see AI systems that \u001b[0m\u001b[91m can not only recognize objects but also understand their context and relationships, allowing them to make more informed decisions.\n",
      "In the field of natural language processing, AI has made significant strides in understanding and generating human language. By analyzing large datasets of text, AI systems can identify patterns and relationships between words and phrases, allowing them to generate text that is more coherent and contextually appropriate. This has significant applications in areas such as customer service, where AI can assist in answering customer queries and providing personalized recommendations. As the technology advances, we may soon see AI systems that can not only understand human language but also generate it in a more natural and human-like manner.\n",
      "In the field of robotics, AI has enabled the development of autonomous systems that can navigate and interact with their environment without human intervention. By leveraging computer vision and other sensory inputs, these systems can identify objects, navigate obstacles, and perform a range of tasks. This has significant applications in areas such as manufacturing, where AI-enabled robots can assist in assembly lines and warehouses. As the technology advances, we may soon see AI systems that can not only navigate and interact with their environment but also learn and adapt to new situations on their own.\n",
      "In conclusion, AI has the potential to transform a wide range of industries and applications, from healthcare to transportation to entertainment. As the technology continues to evolve, we can expect to see even more sophisticated and powerful AI systems that can not only perform specific tasks but also understand and interact with their environment in a more natural and intuitive manner. While there are still challenges to be addressed, the future of AI is promising, and we can expect to see significant advancements in the years to come.\n",
      "AI is a rapidly evolving field that is transforming the way we live and work. From self-driving cars to virtual assistants, AI is being integrated into our daily lives in a variety of ways. As the technology continues to develop, we can expect to see even more sophisticated and powerful AI systems that can not only perform specific tasks but also understand and interact with their environment in a more natural and intuitive manner. While there are still challenges to be addressed, the future of AI is promising, and we can expect to see significant advancements in the years to come.\n",
      "AI is a\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m In the field of computer vision, convolutional neural networks have revolutionized the way machines perceive visual information. By mimicking the human visual system, these networks can classify images, detect objects, and even perform image segmentation. This has significant applications in areas such as medical imaging, where AI can assist doctors in diagnosing conditions from X-rays and MRIs. As the technology advances, we may soon see AI systems that \u001b[0m\u001b[91mcan not only recognize objects but also understand their context and relationships, allowing them to make more informed decisions. In the field of natural language processing, AI has made significant strides in understanding and generating human language. By analyzing large datasets of text, AI systems can identify patterns and relationships between words and phrases, allowing them to generate text that is more coherent and contextually appropriate. This has significant applications in areas such as customer service, where AI can assist in answering customer queries and providing personalized recommendations. As the technology advances, we may soon see AI systems that can not only understand human language but also generate it in a more natural and human-like manner. In the field of robotics, AI has enabled the development of autonomous systems that can navigate and interact with their environment without human intervention. By leveraging computer vision and other sensory inputs, these systems can identify objects, navigate obstacles, and perform a range of tasks. This has significant applications in areas such as manufacturing, where AI-enabled robots can assist in assembly lines and warehouses. As the technology advances, we may soon see AI systems that can not only navigate and interact with their environment but also learn and adapt to new situations on their own. In conclusion, AI has the potential to transform a wide range of industries and applications, from healthcare to transportation to entertainment. As the technology continues to evolve, we can expect to see even more sophisticated and powerful AI systems that can not only perform specific tasks but also understand and interact with their environment in a more natural and intuitive manner. While there are still challenges to be addressed, the future of AI is promising, and we can expect to see significant advancements in the years to come. AI is a rapidly evolving field that is transforming the way we live and work. From self-driving cars to virtual assistants, AI is being integrated into our daily lives in a variety of ways. As the technology continues to develop, we can expect to see even more sophisticated and powerful AI systems that can not only perform specific tasks but also understand and interact with their environment in a more natural and intuitive manner.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Reinforcement learning algorithms learn optimal behaviors through \u001b[0m\u001b[91m the process of trial and error.\n",
      "The main idea of reinforcement learning is to maximize the reward.\n",
      "The reward is a scalar value that is assigned to each state-action pair.\n",
      "The goal of the agent is to maximize the total reward.\n",
      "The agent is a software program that controls the robot.\n",
      "The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software program that controls the robot. The agent is a software\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Reinforcement learning algorithms learn optimal behaviors through \u001b[0m\u001b[91mthe process of trial and error. The main idea of reinforcement learning is to maximize the reward. The reward is a scalar value that is assigned to each state-action pair. The goal of the agent is to maximize the total reward. The agent is a software program that controls the robot.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could \u001b[0m\u001b[91m potentially break many of the existing cryptographic protocols.\n",
      "However, there are also potential benefits to quantum computing for cryptography. For example, quantum-resistant cryptographic protocols could be developed to protect against attacks by quantum computers. Additionally, quantum computing could be used to develop new types of cryptographic algorithms that are more secure than those currently in use.\n",
      "Overall, the impact of quantum computing on cryptography is still uncertain. However, it is clear that the field of cryptography is likely to undergo significant changes in the coming years as a result of the development of quantum computing.\n",
      "The impact of quantum computing on cryptography is still being studied, but it is likely to be significant. Quantum computers are capable of performing calculations much faster than classical computers, which could potentially allow them to break many of the current cryptographic algorithms. However, there are also potential benefits to quantum computing for cryptography, such as the development of quantum-resistant cryptographic protocols.\n",
      "What is the impact of quantum computing on cryptography?\n",
      "The impact of quantum computing on cryptography is still being studied, but it is likely to be significant. Quantum computers are capable of performing calculations much faster than classical computers, which could potentially allow them to break many of the current cryptographic algorithms. However, there are also potential benefits to quantum computing for cryptography, such as the development of quantum-resistant cryptographic protocols.\n",
      "What are the potential benefits of quantum computing for cryptography?\n",
      "The potential benefits of quantum computing for cryptography include the development of quantum-resistant cryptographic protocols and the ability to solve complex problems much faster than classical computers.\n",
      "What are the potential risks of quantum computing for cryptography?\n",
      "The potential risks of quantum computing for cryptography include the possibility that quantum computers could be used to break many of the current cryptographic algorithms. Additionally, there is a risk that quantum computing could be used to develop new types of cryptographic algorithms that are more vulnerable to attack.\n",
      "What is the future of cryptography in the face of quantum computing?\n",
      "The future of cryptography in the face of quantum computing is uncertain. However, it is clear that the field of cryptography is likely to undergo significant changes in the coming years as a result of the development of quantum computing.\n",
      "What are some of the challenges that cryptography will face in the face of quantum computing?\n",
      "Some of the challenges that cryptography will face in the face of quantum computing include the\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could \u001b[0m\u001b[91mpotentially break many of the existing cryptographic protocols. However, there are also potential benefits to quantum computing for cryptography. For example, quantum-resistant cryptographic protocols could be developed to protect against attacks by quantum computers. Additionally, quantum computing could be used to develop new types of cryptographic algorithms that are more secure than those currently in use. Overall, the impact of quantum computing on cryptography is still uncertain. However, it is clear that the field of cryptography is likely to undergo significant changes in the coming years as a result of the development of quantum computing. The impact of quantum computing on cryptography is still being studied, but it is likely to be significant. Quantum computers are capable of performing calculations much faster than classical computers, which could potentially allow them to break many of the current cryptographic algorithms. However, there are also potential benefits to quantum computing for cryptography, such as the development of quantum-resistant cryptographic protocols. What is the impact of quantum computing on cryptography?\n",
      "The impact of quantum computing on cryptography is still being studied, but it is likely to be significant. What are the potential benefits of quantum computing for cryptography?\n",
      "The potential benefits of quantum computing for cryptography include the development of quantum-resistant cryptographic protocols and the ability to solve complex problems much faster than classical computers. What are the potential risks of quantum computing for cryptography?\n",
      "The potential risks of quantum computing for cryptography include the possibility that quantum computers could be used to break many of the current cryptographic algorithms. Additionally, there is a risk that quantum computing could be used to develop new types of cryptographic algorithms that are more vulnerable to attack. What is the future of cryptography in the face of quantum computing?\n",
      "The future of cryptography in the face of quantum computing is uncertain.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that \u001b[0m\u001b[91m can transform industries and improve our lives.\n",
      "The future of AI is bright, with new developments and applications emerging every day. As we continue to explore the potential of this technology, we can expect to see even more impressive advancements in the years to come.\n",
      "Previous articleHow to Choose the Best AI Chatbot for Your Business\n",
      "Next articleHow to Choose the Best AI Chatbot for Your Business\n",
      "How to Choose the Best AI Chatbot for Your Business\n",
      "How to Choose the Best AI Chatbot for Your Business The future of AI is bright, with new developments and applications emerging every day. As we continue to explore the potential of this technology, we can expect to see even more impressive advancements in the years to come.\n",
      "How to Choose the Best AI Chatbot for Your Business The future of AI is bright, with new developments and applications emerging every day. As we continue to explore the potential of this technology, we can expect to see even more impressive advancements in the years to come.\n",
      "How to Choose the Best AI Chatbot for Your Business The future of AI is bright, with new developments and applications emerging every day. As we continue to explore the potential of this technology, we can expect to see even more impressive advancements in the years to come. The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that can transform industries and improve our lives.\n",
      "How to Choose the Best AI Chatbot for Your Business The future of AI is bright, with new developments and applications emerging every day. As we continue to explore the potential of this technology, we can expect to see even more impressive advancements in the years to come. The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy.\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that \u001b[0m\u001b[91mcan transform industries and improve our lives. The future of AI is bright, with new developments and applications emerging every day. As we continue to explore the potential of this technology, we can expect to see even more impressive advancements in the years to come. Previous articleHow to Choose the Best AI Chatbot for Your Business\n",
      "Next articleHow to Choose the Best AI Chatbot for Your Business\n",
      "How to Choose the Best AI Chatbot for Your Business\n",
      "How to Choose the Best AI Chatbot for Your Business The future of AI is bright, with new developments and applications emerging every day. How to Choose the Best AI Chatbot for Your Business The future of AI is bright, with new developments and applications emerging every day. The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that can transform industries and improve our lives.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Transfer learning allows models trained on large datasets to be fine-tuned for specific tasks by \u001b[0m\u001b[91m only using a small amount of data.\n",
      "\n",
      "\\begin{figure}[t]\n",
      "\\centering\n",
      "\\includegraphics[width=0.9\\linewidth]{figures/overview.pdf}\n",
      "\\caption{Overview of the proposed method. We first train a model on a large dataset and then fine-tune it on a small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-tuning is done by using the model's parameters and the small dataset. The fine-\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Transfer learning allows models trained on large datasets to be fine-tuned for specific tasks by \u001b[0m\u001b[91monly using a small amount of data. \\begin{figure}[t]\n",
      "\\centering\n",
      "\\includegraphics[width=0. 9\\linewidth]{figures/overview. pdf}\n",
      "\\caption{Overview of the proposed method. We first train a model on a large dataset and then fine-tune it on a small dataset. The fine-tuning is done by using the model's parameters and the small dataset.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Explainable AI (XAI) is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to \u001b[0m\u001b[91m increase trust and transparency in AI systems.\n",
      "One of the key challenges in XAI is the need to explain the decision-making process of a model in a way that is understandable to humans. This requires the ability to identify the key features that the model has learned to use in making its decisions, and to provide a clear explanation of how these features are used in the decision-making process.\n",
      "One approach to XAI is to use visualization techniques to provide insights into the decision-making process of a model. By visualizing the features that the model has learned to use, it is possible to gain insights into how the model is making its decisions. This can be particularly useful in cases where the model is making decisions that are difficult to understand or that are not aligned with human expectations.\n",
      "Another approach to XAI is to use interpretability techniques to provide insights into the decision-making process of a model. These techniques aim to identify the key features that the model has learned to use in making its decisions, and to provide a clear explanation of how these features are used in the decision-making process. This can be particularly useful in cases where the model is making decisions that are difficult to understand or that are not aligned with human expectations.\n",
      "In conclusion, XAI is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to increase trust and transparency in AI systems. Visualization and interpretability techniques are two key approaches to XAI that can be used to gain insights into the decision-making process of a model.\n",
      "The Role of Visualization and Interpretability in Explainable AI (XAI)\n",
      "Explainable AI (XAI) is a rapidly growing field that aims to provide a better understanding of how artificial intelligence (AI) systems make decisions. One of the key challenges in XAI is the need to explain the decision-making process of a model in a way that is understandable to humans. This requires the ability to identify the key features that the model has learned to use in making its decisions, and to provide a clear explanation of how these features are used in the decision-making process.\n",
      "One approach to XAI is to use visualization techniques to provide insights into the decision-making process of a model. By visualizing the features that the model has learned to use\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Explainable AI (XAI) is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to \u001b[0m\u001b[91mincrease trust and transparency in AI systems. One of the key challenges in XAI is the need to explain the decision-making process of a model in a way that is understandable to humans. This requires the ability to identify the key features that the model has learned to use in making its decisions, and to provide a clear explanation of how these features are used in the decision-making process. One approach to XAI is to use visualization techniques to provide insights into the decision-making process of a model. By visualizing the features that the model has learned to use, it is possible to gain insights into how the model is making its decisions. This can be particularly useful in cases where the model is making decisions that are difficult to understand or that are not aligned with human expectations. Another approach to XAI is to use interpretability techniques to provide insights into the decision-making process of a model. These techniques aim to identify the key features that the model has learned to use in making its decisions, and to provide a clear explanation of how these features are used in the decision-making process. In conclusion, XAI is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to increase trust and transparency in AI systems. Visualization and interpretability techniques are two key approaches to XAI that can be used to gain insights into the decision-making process of a model. The Role of Visualization and Interpretability in Explainable AI (XAI)\n",
      "Explainable AI (XAI) is a rapidly growing field that aims to provide a better understanding of how artificial intelligence (AI) systems make decisions.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and \u001b[0m\u001b[91m the sun sinks into the horizon. The sound of the waves crashing against the shore is a soothing and calming sound, and the smell of the salty air is invigorating.\n",
      "The beach is a great place to relax and unwind, with plenty of space to stretch out and take in the beauty of the surroundings. There are also plenty of activities to enjoy, such as swimming, sunbathing, and building sandcastles.\n",
      "The beach is a great place to spend a day with friends and family, or to simply enjoy some alone time. It is a great way to escape the hustle and bustle of everyday life, and to reconnect with nature.\n",
      "The beach is a great place to relax and unwind, and to take in the beauty of the natural world. It is a great way to escape the hustle and bustle of everyday life, and to reconnect with nature.\n",
      "1 What is the best beach in the world?\n",
      "2 What is the most beautiful beach in the world?\n",
      "3 What is the most beautiful beach in the world 2022?\n",
      "4 What is the most beautiful beach in the world 2021?\n",
      "5 What is the most beautiful beach in the world 2020?\n",
      "6 What is the most beautiful beach in the world 2019?\n",
      "7 What is the most beautiful beach in the world 2018?\n",
      "What is the best beach in the world?\n",
      "There are so many beautiful beaches in the world, it’s hard to choose just one as the best. But if you’re looking for a beach that’s perfect for relaxing, swimming, and sunbathing, then you can’t go wrong with any of the following:\n",
      "1. Pink Sands Beach, Harbour Island, Bahamas\n",
      "This beach is famous for its pink sand, which is said to be the result of the coral reefs that surround the island. The water is also incredibly clear, making it a great place to go for a swim.\n",
      "2. Whitehaven Beach, Whitsunday Islands, Australia\n",
      "This beach is located on the island of Hamilton in the Whitsunday Islands, and it’s one of the most popular tourist destinations in Australia. The white sand is said to be some of the purest in the world\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and \u001b[0m\u001b[91mthe sun sinks into the horizon. The sound of the waves crashing against the shore is a soothing and calming sound, and the smell of the salty air is invigorating. The beach is a great place to relax and unwind, with plenty of space to stretch out and take in the beauty of the surroundings. There are also plenty of activities to enjoy, such as swimming, sunbathing, and building sandcastles. The beach is a great place to spend a day with friends and family, or to simply enjoy some alone time. It is a great way to escape the hustle and bustle of everyday life, and to reconnect with nature. The beach is a great place to relax and unwind, and to take in the beauty of the natural world. 1 What is the best beach in the world?\n",
      "2 What is the most beautiful beach in the world?\n",
      "3 What is the most beautiful beach in the world 2022?\n",
      "4 What is the most beautiful beach in the world 2021?\n",
      "5 What is the most beautiful beach in the world 2020?\n",
      "6 What is the most beautiful beach in the world 2019?\n",
      "7 What is the most beautiful beach in the world 2018?\n",
      "What is the best beach in the world?\n",
      "There are so many beautiful beaches in the world, it’s hard to choose just one as the best. But if you’re looking for a beach that’s perfect for relaxing, swimming, and sunbathing, then you can’t go wrong with any of the following:\n",
      "1. Pink Sands Beach, Harbour Island, Bahamas\n",
      "This beach is famous for its pink sand, which is said to be the result of the coral reefs that surround the island. The water is also incredibly clear, making it a great place to go for a swim. 2. Whitehaven Beach, Whitsunday Islands, Australia\n",
      "This beach is located on the island of Hamilton in the Whitsunday Islands, and it’s one of the most popular tourist destinations in Australia.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of \u001b[0m\u001b[91m the world.\n",
      "Traveling can also help you develop new skills and knowledge. By learning about different cultures, you can gain a better understanding of the world and how it works. This can help you become more successful in your career and life.\n",
      "Traveling can also help you develop a better understanding of yourself. By exploring new places, you can gain insight into your own values and beliefs. This can help you become more confident and self-aware.\n",
      "Traveling can also help you develop a better understanding of the environment. By visiting different places, you can gain insight into how different cultures and societies interact with the environment. This can help you become more environmentally conscious and responsible.\n",
      "Traveling can also help you develop a better understanding of history. By visiting different places, you can gain insight into how different cultures and societies have evolved over time. This can help you become more informed and knowledgeable about the world.\n",
      "Traveling can also help you develop a better understanding of the world. By visiting different places, you can gain insight into how different cultures and societies interact with each other. This can help you become more understanding and empathetic.\n",
      "Traveling can also help you develop a better understanding of yourself. By exploring new places, you can gain insight into your own values and beliefs. This can help you become more confident and self-aware.\n",
      "Traveling can also help you develop a better understanding of the environment. By visiting different places, you can gain insight into how different cultures and societies interact with the environment. This can help you become more environmentally conscious and responsible.\n",
      "Traveling can also help you develop a better understanding of history. By visiting different places, you can gain insight into how different cultures and societies have evolved over time. This can help you become more informed and knowledgeable about the world.\n",
      "Traveling can also help you develop a better understanding of the world. By visiting different places, you can gain insight into how different cultures and societies interact with each other. This can help you become more understanding and empathetic.\n",
      "Traveling can also help you develop a better understanding of yourself. By exploring new places, you can gain insight into your own values and beliefs. This can help you become more confident and self-aware.\n",
      "Traveling can also help you develop a better understanding of the environment.\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of \u001b[0m\u001b[91mthe world. Traveling can also help you develop new skills and knowledge. By learning about different cultures, you can gain a better understanding of the world and how it works. This can help you become more successful in your career and life. Traveling can also help you develop a better understanding of yourself. By exploring new places, you can gain insight into your own values and beliefs. This can help you become more confident and self-aware. Traveling can also help you develop a better understanding of the environment. By visiting different places, you can gain insight into how different cultures and societies interact with the environment. This can help you become more environmentally conscious and responsible. Traveling can also help you develop a better understanding of history. By visiting different places, you can gain insight into how different cultures and societies have evolved over time. This can help you become more informed and knowledgeable about the world. Traveling can also help you develop a better understanding of the world. By visiting different places, you can gain insight into how different cultures and societies interact with each other. This can help you become more understanding and empathetic.\u001b[0m\n",
      "\n",
      "\n",
      "Pruning model\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.514563584\n",
      "Model size after pruning:  13.514563584\n",
      "Model size after pruning:  13.514539008\n",
      "Model size after pruning:  13.514539008\n",
      "Model size after pruning:  13.51446528\n",
      "Model size after pruning:  13.51446528\n",
      "Model size after pruning:  13.514440704\n",
      "Model size after pruning:  13.514440704\n",
      "Model size after pruning:  13.514440704\n",
      "Model size after pruning:  13.514440704\n",
      "Model size after pruning:  13.514440704\n",
      "Model size after pruning:  13.514440704\n",
      "Model size after pruning:  13.5143424\n",
      "Model size after pruning:  13.5143424\n",
      "Model size after pruning:  13.514293248\n",
      "Model size after pruning:  13.514293248\n",
      "Model size after pruning:  13.514145792\n",
      "Model size after pruning:  13.514145792\n",
      "Model size after pruning:  13.514121216\n",
      "Model size after pruning:  13.514121216\n",
      "Model size after pruning:  13.514121216\n",
      "Model size after pruning:  13.514121216\n",
      "Model size after pruning:  13.514072064\n",
      "Model size after pruning:  13.514072064\n",
      "Model size after pruning:  13.514072064\n",
      "Model size after pruning:  13.514072064\n",
      "Model size after pruning:  13.514072064\n",
      "Model size after pruning:  13.514072064\n",
      "Model size after pruning:  13.51397376\n",
      "Model size after pruning:  13.51397376\n",
      "Model size after pruning:  13.513949184\n",
      "Model size after pruning:  13.513949184\n",
      "Model size after pruning:  13.513900032\n",
      "Model size after pruning:  13.513900032\n",
      "Model size after pruning:  13.51385088\n",
      "Model size after pruning:  13.51385088\n",
      "Model size after pruning:  13.478682624\n",
      "Model size after pruning:  13.4535168\n",
      "Model size after pruning:  13.399400448\n",
      "Model size after pruning:  13.374234624\n",
      "Model size after pruning:  13.320118272\n",
      "Model size after pruning:  13.294952448\n",
      "Model size after pruning:  13.240836096\n",
      "Model size after pruning:  13.215670272\n",
      "Model size after pruning:  13.16155392\n",
      "Model size after pruning:  13.136388096\n",
      "Model size after pruning:  13.082271744\n",
      "Saving model after pruning to checkpoint dir\n",
      "Model saved\n",
      "Real Pruned Model\n",
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (4-5): 2 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11007, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11007, bias=False)\n",
      "          (down_proj): Linear(in_features=11007, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (6): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11005, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11005, bias=False)\n",
      "          (down_proj): Linear(in_features=11005, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (7): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11007, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11007, bias=False)\n",
      "          (down_proj): Linear(in_features=11007, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (8-9): 2 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (10): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11004, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11004, bias=False)\n",
      "          (down_proj): Linear(in_features=11004, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (11): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11006, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11006, bias=False)\n",
      "          (down_proj): Linear(in_features=11006, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (12): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11002, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11002, bias=False)\n",
      "          (down_proj): Linear(in_features=11002, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (13): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11007, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11007, bias=False)\n",
      "          (down_proj): Linear(in_features=11007, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (14): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (15): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11006, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11006, bias=False)\n",
      "          (down_proj): Linear(in_features=11006, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (16-17): 2 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (18): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11004, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11004, bias=False)\n",
      "          (down_proj): Linear(in_features=11004, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (19): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11007, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11007, bias=False)\n",
      "          (down_proj): Linear(in_features=11007, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (20-21): 2 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11006, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11006, bias=False)\n",
      "          (down_proj): Linear(in_features=11006, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (22): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=9577, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=9577, bias=False)\n",
      "          (down_proj): Linear(in_features=9577, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (23-27): 5 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (o_proj): Linear(in_features=3328, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (down_proj): Linear(in_features=8806, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (28-31): 4 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n",
      "Real Pruned Model Size\n",
      "13.082271744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short Context: 10.384607383393115 tokens/sec, 516 tokens (including full prompt)\n",
      "Long Context: 25.555844198775713 tokens/sec, 1288 tokens (including full prompt)\n",
      "Average:  14.923618028389734 tokens/sec\n",
      "***************   Experiment completed successfully Successfully   ***************\n"
     ]
    }
   ],
   "source": [
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "821da10a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T03:47:12.309966Z",
     "start_time": "2024-05-25T03:47:12.298800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6522257408"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05ba63a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T03:48:09.444031Z",
     "start_time": "2024-05-25T03:48:09.125774Z"
    }
   },
   "outputs": [],
   "source": [
    "del experiment.model\n",
    "del experiment.tokenizer \n",
    "del experiment.pipeline\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "del tokenizer\n",
    "del model\n",
    "del pipeline\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7cf97e",
   "metadata": {},
   "source": [
    "## Experiment 2504 --> PreserveRatio=0.9, lbound=0.8, rbound=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8337b81b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T03:49:57.296752Z",
     "start_time": "2024-05-25T03:49:57.293639Z"
    }
   },
   "outputs": [],
   "source": [
    "pruning_dict = \"pruning_dict_1.0_0.8_1.0_chat_2504.json\"\n",
    "save_dir = \"/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/\"\n",
    "\n",
    "p = pruning_dict.split(\"_\")[-1].split(\".\")[-2]\n",
    "output_dir = \"/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints//\" + p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc006d5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T03:49:57.890115Z",
     "start_time": "2024-05-25T03:49:57.882076Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment = ExperimentRunner(pipeline, tokenizer, pruning_dict, \n",
    "                 save_dir=save_dir, output_dir=output_dir, ignored_layers=None, \n",
    "                 use_template=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dd570a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:16:08.388332Z",
     "start_time": "2024-05-25T03:49:58.329305Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************   Running Experiment   ***************\n",
      "61 ==>  3968\n",
      "67 ==>  9876\n",
      "75 ==>  3712\n",
      "81 ==>  8908\n",
      "89 ==>  4096\n",
      "95 ==>  10464\n",
      "103 ==>  3328\n",
      "109 ==>  9240\n",
      "117 ==>  3968\n",
      "123 ==>  10427\n",
      "131 ==>  3968\n",
      "137 ==>  10163\n",
      "145 ==>  3968\n",
      "151 ==>  10317\n",
      "159 ==>  3712\n",
      "165 ==>  10697\n",
      "173 ==>  3712\n",
      "179 ==>  10797\n",
      "187 ==>  3968\n",
      "193 ==>  10806\n",
      "201 ==>  3840\n",
      "207 ==>  10805\n",
      "215 ==>  3584\n",
      "221 ==>  9539\n",
      "229 ==>  4096\n",
      "235 ==>  10074\n",
      "243 ==>  3328\n",
      "249 ==>  10955\n",
      "257 ==>  3328\n",
      "263 ==>  10135\n",
      "271 ==>  4096\n",
      "277 ==>  9850\n",
      "285 ==>  3968\n",
      "291 ==>  10163\n",
      "299 ==>  3840\n",
      "305 ==>  10411\n",
      "313 ==>  4096\n",
      "319 ==>  10869\n",
      "327 ==>  3328\n",
      "333 ==>  9100\n",
      "341 ==>  3328\n",
      "347 ==>  8806\n",
      "355 ==>  3328\n",
      "361 ==>  8806\n",
      "369 ==>  3328\n",
      "375 ==>  8806\n",
      "383 ==>  3328\n",
      "389 ==>  8806\n",
      "***************   Pruning Model   ***************\n",
      "Pruning model\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Saving model after pruning to checkpoint dir\n",
      "Model saved\n",
      "***************   Model Pruned Successfully   ***************\n",
      "Model Size after Pruning:  13.51458816\n",
      "evaluating on wikitext2\n",
      "nsamples 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:   0%|                                                                                                                                                                                                                                                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:   4%|████████████▎                                                                                                                                                                                                                                                                                                      | 1/25 [00:01<00:25,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:   8%|████████████████████████▌                                                                                                                                                                                                                                                                                          | 2/25 [00:01<00:18,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  12%|████████████████████████████████████▊                                                                                                                                                                                                                                                                              | 3/25 [00:02<00:15,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  16%|█████████████████████████████████████████████████                                                                                                                                                                                                                                                                  | 4/25 [00:02<00:14,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  20%|█████████████████████████████████████████████████████████████▍                                                                                                                                                                                                                                                     | 5/25 [00:03<00:12,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  24%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                                                                         | 6/25 [00:04<00:12,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  28%|█████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                                                                                             | 7/25 [00:04<00:10,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  32%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                                                                                | 8/25 [00:05<00:10,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  36%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                                    | 9/25 [00:05<00:09,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  40%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                                                       | 10/25 [00:06<00:09,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  44%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                           | 11/25 [00:07<00:08,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  48%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                               | 12/25 [00:07<00:07,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  52%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                                   | 13/25 [00:08<00:07,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                      | 14/25 [00:08<00:06,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                          | 15/25 [00:09<00:05,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                              | 16/25 [00:10<00:05,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                  | 17/25 [00:10<00:04,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                     | 18/25 [00:11<00:04,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                         | 19/25 [00:11<00:03,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                             | 20/25 [00:12<00:02,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                 | 21/25 [00:12<00:02,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 22/25 [00:13<00:01,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 23/25 [00:14<00:01,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 24/25 [00:14<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WikiText Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:15<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPL:  14.532150268554688\n",
      "Perplexity on wikitext2:  14.532150268554688\n",
      "Loading checkpoint from /data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model passed to evaluation:  LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-25:09:22:16,193 WARNING  [task.py:763] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-05-25:09:22:16,196 WARNING  [task.py:775] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2024-05-25:09:22:22,932 WARNING  [task.py:763] [Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-05-25:09:22:22,944 WARNING  [task.py:775] [Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for winogrande contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/winogrande\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2024-05-25:09:23:19,097 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-05-25:09:23:19,098 INFO     [evaluator.py:177] Initializing huggingface model, with arguments: {'pretrained': '/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/'}\n",
      "2024-05-25:09:23:19,110 WARNING  [logging.py:61] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "2024-05-25:09:23:19,111 INFO     [huggingface.py:163] Using device 'cuda'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3414d113859b49039b2294fd085c9e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-25:09:24:17,487 WARNING  [task.py:763] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-05-25:09:24:17,496 WARNING  [task.py:775] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-05-25:09:24:28,908 WARNING  [task.py:763] [Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-05-25:09:24:28,910 WARNING  [task.py:775] [Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-05-25:09:24:34,589 WARNING  [evaluator.py:239] Overwriting default num_fewshot of rte from None to 0\n",
      "2024-05-25:09:24:34,599 WARNING  [evaluator.py:239] Overwriting default num_fewshot of openbookqa from None to 0\n",
      "2024-05-25:09:24:34,600 WARNING  [evaluator.py:239] Overwriting default num_fewshot of boolq from None to 0\n",
      "2024-05-25:09:24:34,601 WARNING  [evaluator.py:239] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2024-05-25:09:24:34,602 WARNING  [evaluator.py:239] Overwriting default num_fewshot of arc_easy from None to 0\n",
      "2024-05-25:09:24:34,603 WARNING  [evaluator.py:239] Overwriting default num_fewshot of arc_challenge from None to 0\n",
      "2024-05-25:09:24:34,604 WARNING  [evaluator.py:239] Overwriting default num_fewshot of winogrande from None to 0\n",
      "2024-05-25:09:24:34,607 INFO     [task.py:395] Building contexts for rte on rank 0...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1501.88it/s]\n",
      "2024-05-25:09:24:34,697 INFO     [task.py:395] Building contexts for openbookqa on rank 0...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 796.38it/s]\n",
      "2024-05-25:09:24:34,883 INFO     [task.py:395] Building contexts for boolq on rank 0...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 590.06it/s]\n",
      "2024-05-25:09:24:35,079 INFO     [task.py:395] Building contexts for hellaswag on rank 0...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1065.17it/s]\n",
      "2024-05-25:09:24:35,232 INFO     [task.py:395] Building contexts for arc_easy on rank 0...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 402.01it/s]\n",
      "2024-05-25:09:24:35,507 INFO     [task.py:395] Building contexts for arc_challenge on rank 0...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 384.90it/s]\n",
      "2024-05-25:09:24:35,792 INFO     [task.py:395] Building contexts for winogrande on rank 0...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 6469.00it/s]\n",
      "2024-05-25:09:24:35,815 INFO     [evaluator.py:379] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2199/2199 [03:06<00:00, 11.78it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "fatal: not a git repository (or any parent up to mount point /)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "|     Alias     | Acc, None |   Acc StdErr, None   | Acc Norm, None | Acc Norm StdErr, None |\n",
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "|      rte      |    0.58   | 0.04960449637488584  |      None      |          None         |\n",
      "|   openbookqa  |    0.22   | 0.04163331998932268  |      0.37      |  0.04852365870939098  |\n",
      "|     boolq     |    0.69   | 0.04648231987117316  |      None      |          None         |\n",
      "|   hellaswag   |    0.48   | 0.050211673156867795 |      0.64      |  0.04824181513244218  |\n",
      "|    arc_easy   |    0.59   | 0.04943110704237102  |      0.67      |  0.04725815626252607  |\n",
      "| arc_challenge |    0.42   | 0.049604496374885836 |      0.42      |  0.04960449637488584  |\n",
      "|   winogrande  |    0.6    | 0.049236596391733084 |      None      |          None         |\n",
      "+---------------+-----------+----------------------+----------------+-----------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Gardening provides a sense of accomplishment and tranquility, as you nurture plants and watch them \u001b[0m\u001b[91m grow.\n",
      "Gardening is a great way to get some fresh air and exercise.\n",
      "Gardening is a great way to get some fresh air and exercise. It’s also a great way to reduce stress and anxiety.\n",
      "Gardening is a great way to reduce stress and anxiety. It’s also a great way to improve your mental health.\n",
      "Gardening is a great way to reduce stress and anxiety. It’s also a great way to improve your mental health. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great way to reduce stress and anxiety. It’s a great\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Gardening provides a sense of accomplishment and tranquility, as you nurture plants and watch them \u001b[0m\u001b[91mgrow. Gardening is a great way to get some fresh air and exercise. It’s also a great way to reduce stress and anxiety. Gardening is a great way to reduce stress and anxiety. It’s also a great way to improve your mental health. It’s a great way to reduce stress and anxiety.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Family traditions are passed down from generation to generation, creating a sense of continuity and belonging. Whether it's holiday celebrations, special recipes, or annual gatherings, these traditions foster \u001b[0m\u001b[91m a sense of connection and connection.\n",
      "Family traditions are a great way to bring the family together and create a sense of connection and connection. Whether it's a holiday celebration, a special recipe, or an annual gathering, these traditions foster a sense of connection and connection.\n",
      "Family traditions are a great way to bring the family together and create a sense of connection and connection. Whether it's a holiday celebration, a special recipe, or an annual gathering, these traditions foster a sense of connection and connection.\n",
      "Family traditions are a great way to bring the family together and create a sense of connection and connection. Whether it's a holiday celebration, a special recipe, or an annual gathering, these traditions foster a sense of connection and connection.\n",
      "Family traditions are a great way to bring the family together and create a sense of connection and connection. Whether it's a holiday celebration, a special recipe, or an annual gathering, these traditions foster a sense of connection and connection.\n",
      "Family traditions are a great way to bring the family together and create a sense of connection and connection. Whether it's a holiday celebration, a special recipe, or an annual gathering, these traditions foster a sense of connection and connection.\n",
      "Family traditions are a great way to bring the family together and create a sense of connection and connection. Whether it's a holiday celebration, a special recipe, or an annual gathering, these traditions foster a sense of connection and connection.\n",
      "Family traditions are a great way to bring the family together and create a sense of connection and connection. Whether it's a holiday celebration, a special recipe, or an annual gathering, these traditions foster a sense of connection and connection.\n",
      "Family traditions are a great way to bring the family together and create a sense of connection and connection. Whether it's a holiday celebration, a special recipe, or an annual gathering, these traditions foster a sense of connection and connection.\n",
      "Family traditions are a great way to bring the family together and create a sense of connection and connection. Whether it's a holiday celebration, a special recipe, or an annual gathering, these traditions foster a sense of connection and connection.\n",
      "Family traditions are a great way to bring\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Family traditions are passed down from generation to generation, creating a sense of continuity and belonging. Whether it's holiday celebrations, special recipes, or annual gatherings, these traditions foster \u001b[0m\u001b[91ma sense of connection and connection. Family traditions are a great way to bring the family together and create a sense of connection and connection. Whether it's a holiday celebration, a special recipe, or an annual gathering, these traditions foster a sense of connection and connection.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future \u001b[0m\u001b[91m, fashion will continue to evolve and evolve, with new technologies and innovative ideas.\n",
      "The future of fashion is likely to be more sustainable, with an increased focus on reducing waste and reducing the environmental impact of the industry. This could include the use of more sustainable materials, such as organ organic cotton, and the use of more sustainable production processes, such as the use of less chemicals. The future of fashion could also be more inclusive, with an increased focus on inclusivity and diversity. This could include the use of more inclusive models, the use of more diverse designs, and the use of more diverse designs. The future of fashion could also be more inclusive, with an increased focus on inclusivity and diversity. This could include the use of more inclusive models, the use of more diverse designs, and the use of more diverse designs. The future of fashion could also be more inclusive, with an increased focus on inclusivity and diversity. This could include the use of more inclusive models, the use of more diverse designs, and the use of more diverse designs.\n",
      "The future of fashion is likely to be more sustainable, with an increased focus on reducing waste and reducing the environmental impact of the industry. This could include the use of more sustainable materials, such as organ organic cotton, and the use of more sustainable production processes, such as the use of less chemicals. The future of fashion could also be more sustainable, with an increased focus on reducing waste and reducing the environmental impact of the industry. This could include the use of more sustainable materials, such as organ organic cotton, and the use of more sustainable production processes, such as the use of less chemicals. The future of fashion could also be more sustainable, with an increased focus on reducing waste and reducing the environmental impact of the industry. This could include the use of more sustainable materials, such as organ organic cotton, and the use of more sustainable production processes, such as the use of less chemicals.\n",
      "The future of fashion is likely to be more sustainable, with an increased focus on reducing waste and reducing the environmental impact of the industry. This could include the use of more sustainable materials, such as organ organic cotton, and the use of more sustainable production processes, such as the use of less chemicals. The future\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future \u001b[0m\u001b[91m, fashion will continue to evolve and evolve, with new technologies and innovative ideas. The future of fashion is likely to be more sustainable, with an increased focus on reducing waste and reducing the environmental impact of the industry. This could include the use of more sustainable materials, such as organ organic cotton, and the use of more sustainable production processes, such as the use of less chemicals. The future of fashion could also be more inclusive, with an increased focus on inclusivity and diversity. This could include the use of more inclusive models, the use of more diverse designs, and the use of more diverse designs. The future of fashion could also be more sustainable, with an increased focus on reducing waste and reducing the environmental impact of the industry.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Artificial intelligence is transforming the healthcare industry by enabling \u001b[0m\u001b[91m hospitals to provide more efficient and effective care.\n",
      "The healthcare industry is one of the largest and most important industries in the world. It is a $1 trillion dollar industry that employs over 1. 1 million people. The healthcare industry is also one of the most important industries in the world because it provides health care to people.\n",
      "The healthcare industry is a $1 trillion dollar industry that employs over 1. 1 million people. The healthcare industry is also one of the most important industries in the world because it provides health care to people. The healthcare industry is a $1 trillion dollar industry that employs over 1. 1 million people. The healthcare industry is also one of the most important industries in the world because it provides health care to people. The healthcare industry is a $1 trillion dollar industry that employs over 1. 1 million people. The healthcare industry is also one of the most important industries in the world because it provides health care to people. The healthcare industry is a $1 trillion dollar industry that employs over 1. 1 million people. The healthcare industry is a $1 trillion dollar industry that employs over 1. 1 million people. The healthcare industry is a $1 trillion dollar industry that employs over 1. 1 million people. The healthcare industry is a $1 trillion dollar industry that employs over 1. 1 million people. The healthcare industry is a $1 trillion dollar industry that employs over 1. 1 million people. The healthcare industry is a $1 trillion dollar industry that employs over 1. 1 million people. The healthcare industry is a $1 trillion dollar industry that employs over 1. 1 million people. The healthcare industry is a $1 trillion dollar industry that employs over 1. 1 million people. The healthcare industry is a $1 trillion dollar industry that employs over 1. 1 million people. The healthcare industry is a $1 trillion dollar industry that employs over 1. 1 million people. The healthcare industry is a $1 trill\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Artificial intelligence is transforming the healthcare industry by enabling \u001b[0m\u001b[91mhospitals to provide more efficient and effective care. The healthcare industry is one of the largest and most important industries in the world. It is a $1 trillion dollar industry that employs over 1. 1 million people. The healthcare industry is also one of the most important industries in the world because it provides health care to people. The healthcare industry is a $1 trillion dollar industry that employs over 1.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Machine learning algorithms are increasingly being used to predict stock market trends. By analyzing historical data and identifying patterns, these models can \u001b[0m\u001b[91m help to predict when a stock is likely to rise or fall in price.\n",
      "One of the most popular methods is the use of technical indicators. These are statistical indic indicators that are used to identify potential tr trends in a stock’s price. For example, the Relate Stochastic Osc is a popular indicator that is used to identify when a stock is likely to rise or fall in price.\n",
      "Another popular method is the use of technical indicators. These are statistical indicators that are used to identify when a stock is likely to rise or fall in price. For example, the Relative Strength Index (RSI) is a popular indicator that is used to identify when a stock is likely to rise or fall in price.\n",
      "The most important thing to remember when using these indicators is that they are not a guarantee. They are simply a tool that can be used to help identify when a stock is likely to rise or fall in price.\n",
      "The best way to use these indicators is to compare them to other indicators. This will help you to identify when a stock is likely to rise or fall in price. For example, if a stock is rising in price, you can compare it to other stocks that are rising in price.\n",
      "If a stock is falling in price, you can compare it to other stocks that are falling in price.\n",
      "What is the best indicator for a stock?\n",
      "There is no one answer to this question as the best indicator for a stock will vary depending on the invest investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’s investor’\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Machine learning algorithms are increasingly being used to predict stock market trends. By analyzing historical data and identifying patterns, these models can \u001b[0m\u001b[91mhelp to predict when a stock is likely to rise or fall in price. One of the most popular methods is the use of technical indicators. These are statistical indic indicators that are used to identify potential tr trends in a stock’s price. For example, the Relate Stochastic Osc is a popular indicator that is used to identify when a stock is likely to rise or fall in price. Another popular method is the use of technical indicators. These are statistical indicators that are used to identify when a stock is likely to rise or fall in price. For example, the Relative Strength Index (RSI) is a popular indicator that is used to identify when a stock is likely to rise or fall in price. The most important thing to remember when using these indicators is that they are not a guarantee. They are simply a tool that can be used to help identify when a stock is likely to rise or fall in price. The best way to use these indicators is to compare them to other indicators. This will help you to identify when a stock is likely to rise or fall in price. For example, if a stock is rising in price, you can compare it to other stocks that are rising in price. If a stock is falling in price, you can compare it to other stocks that are falling in price.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The integration of natural language processing with machine learning has opened up new possibilities in human-computer interaction. For instance, chatbots powered by sophisticated NLP algorithms can now understand and respond to user queries with remarkable accuracy. As these technologies continue to evolve, we can expect that \u001b[0m\u001b[91m they will become even more powerful and useful tools for us in the future.\n",
      "The future of natural language processing is looking more and more promising. With the adv of technology, we can expect that NLP will become even more accurate and efficient. This will lead to a better understanding of human language and a better understanding of the world.\n",
      "The future of natural language processing is looking more and more promising. With the adv of technology, we can expect that NLP will become even more accurate and efficient. This will lead to a better understanding of human language and a better understanding of the world.\n",
      "The future of natural language processing is looking more and more prom. With the adv of technology, we can expect that NLP will become even more accurate and efficient. This will lead to a better understanding of human language and a better understanding of the world.\n",
      "The future of natural language processing is looking more and more promising. With the adv of technology, we can expect that NLP will become even more accurate and efficient. This will lead to a better understanding of human language and a better understanding of the world.\n",
      "The future of natural language processing is looking more and more promising. With the adv of technology, we can expect that NLP will become even more accurate and efficient. This will lead to a better understanding of human language and a better understanding of the world.\n",
      "The future of natural language processing is looking more and more promising. With the adv of technology, we can expect that NLP will become even more accurate and efficient. This will lead to a better understanding of human language and a better understanding of the world.\n",
      "The future of natural language processing is looking more and more promising. With the adv of technology, we can expect that NLP will become even more accurate and efficient. This will lead to a better understanding of human language and a better understanding of the world.\n",
      "The future of natural language processing is looking more and more promising. With the adv of technology, we can expect that NLP will become even more accurate and efficient. This will lead to a better understanding of human language and a better understanding of the world.\n",
      "The future of natural language processing is looking more and more promising. With the adv of technology, we can expect that NLP will become even more accurate and efficient. This will lead to a better understanding of human language and a better understanding of the world.\n",
      "The future of natural language processing is looking more and more promising. With the adv of technology,\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The integration of natural language processing with machine learning has opened up new possibilities in human-computer interaction. For instance, chatbots powered by sophisticated NLP algorithms can now understand and respond to user queries with remarkable accuracy. As these technologies continue to evolve, we can expect that \u001b[0m\u001b[91mthey will become even more powerful and useful tools for us in the future. The future of natural language processing is looking more and more promising. With the adv of technology, we can expect that NLP will become even more accurate and efficient. This will lead to a better understanding of human language and a better understanding of the world. The future of natural language processing is looking more and more prom.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Self-driving cars rely heavily on sensor data and advanced algorithms to navigate \u001b[0m\u001b[91m safely and efficiently. The data is collected by a variety of sensors, including cameras, rad...\n",
      "What is a 3 L\n",
      "A 3-liter is a type of engine that is used in a variety of vehicles, including cars, motor motorcycles, and even some aircraft. The 3-liter is a type of engine that is used in a variety of vehicles, including cars, motorcycles, and even some aircraft. The 3-liter is a type of engine that is used in a variety of vehicles, including cars, motorcycles, and even some aircraft. The 3-liter is a type of engine that is used in a variety of vehicles, including cars, motorcycles, and even some aircraft. The 3-liter is a type of engine that is used in a variety of vehicles, including cars, motorcycles, and even some aircraft. The 3-liter is a type of engine that is used in a variety of vehicles, including cars, motorcycles, and even some aircraft. The 3-liter is a type of engine that is used in a variety of vehicles, including cars, motorcycles, and even some aircraft. The 3-liter is a type of engine that is used in a variety of vehicles, including cars, motorcycles, and even some aircraft. The 3-liter is a type of engine that is used in a variety of vehicles, including cars, motorcycles, and even some aircraft. The 3-liter is a type of engine that is used in a variety of vehicles, including cars, motorcycles, and even some aircraft. The 3-liter is a type of engine that is used in a variety of vehicles, including cars, motorcycles, and even some aircraft. The 3-liter is a type of engine that is used in a variety of vehicles, including cars, motorcycles, and even some aircraft. The 3-liter is a type of engine that is used in a variety of vehicles, including cars, motorcycles, and even some aircraft. The 3-liter is a type of engine that is used in a variety of vehicles, including cars, motorcycles, and even some aircraft. The 3-liter is a type of engine that is used in a variety of vehicles, including cars, motorcycles, and even some aircraft. The 3-liter is a type of engine that is used in a variety of\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Self-driving cars rely heavily on sensor data and advanced algorithms to navigate \u001b[0m\u001b[91msafely and efficiently. The data is collected by a variety of sensors, including cameras, rad. What is a 3 L\n",
      "A 3-liter is a type of engine that is used in a variety of vehicles, including cars, motor motorcycles, and even some aircraft. The 3-liter is a type of engine that is used in a variety of vehicles, including cars, motorcycles, and even some aircraft.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m One of the biggest challenges in developing AI systems is ensuring they are ethical and unbiased. Researchers are working on creating frameworks that can \u001b[0m\u001b[91m help ensure this, but it is still a work in progress.\n",
      "Another challenge is the lack of diversity in the field of AI. Women are under, and underrepresented in the field of AI, which can lead to a lack of diversity in the types of problems that are being solved and the solutions that are being developed. This can lead to a lack of innovation and innovation.\n",
      "The future of AI is uncertain, but it is likely that it will continue to be a powerful tool for innovation and innovation.\n",
      "The future of AI is uncertain, but it is likely that it will continue to be a powerful tool for innovation and innovation.\n",
      "The future of AI is uncertain, but it is likely that it will continue to be a powerful tool for innovation and innovation.\n",
      "The future of AI is uncertain, but it is likely that it will continue to be a powerful tool for innovation and innovation.\n",
      "The future of AI is uncertain, but it is likely that it will continue to be a powerful tool for innovation and innovation.\n",
      "The future of AI is uncertain, but it is likely that it will continue to be a powerful tool for innovation and innovation.\n",
      "The future of AI is uncertain, but it is likely that it will continue to be a powerful tool for innovation and innovation.\n",
      "The future of AI is uncertain, but it is likely that it will continue to be a powerful tool for innovation and innovation.\n",
      "The future of AI is uncertain, but it is likely that it will continue to be a powerful tool for innovation and innovation.\n",
      "The future of AI is uncertain, but it is likely that it will continue to be a powerful tool for innovation and innovation.\n",
      "The future of AI is uncertain, but it is likely that it will continue to be a powerful tool for innovation and innovation.\n",
      "The future of AI is uncertain, but it is likely that it will continue to be a powerful tool for innovation and innovation.\n",
      "The future of AI is uncertain, but it is likely that it will continue to be a powerful tool for innovation and innovation.\n",
      "The future of AI is uncertain, but it is likely that it will continue to be a powerful tool for innovation and innovation.\n",
      "The future of AI is uncertain, but it is likely that it will continue to be a powerful\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m One of the biggest challenges in developing AI systems is ensuring they are ethical and unbiased. Researchers are working on creating frameworks that can \u001b[0m\u001b[91mhelp ensure this, but it is still a work in progress. Another challenge is the lack of diversity in the field of AI. Women are under, and underrepresented in the field of AI, which can lead to a lack of diversity in the types of problems that are being solved and the solutions that are being developed. This can lead to a lack of innovation and innovation. The future of AI is uncertain, but it is likely that it will continue to be a powerful tool for innovation and innovation.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m In the field of computer vision, convolutional neural networks have revolutionized the way machines perceive visual information. By mimicking the human visual system, these networks can classify images, detect objects, and even perform image segmentation. This has significant applications in areas such as medical imaging, where AI can assist doctors in diagnosing conditions from X-rays and MRIs. As the technology advances, we may soon see AI systems that \u001b[0m\u001b[91m can not.\n",
      "In the future, we may also see AI systems that can detect and diagnose diseases from images. This would be a huge step forward in the field of medical imaging, as it would allow doctors to diagnose conditions from images without the need of a human doctor. This would be a huge step forward in the field of medical imaging, as it would allow doctors to diagnose conditions from images without the need of a human doctor.\n",
      "This would be a huge step forward in the field of medical imaging, as it would allow doctors to diagnose conditions from images without the need of a human doctor. This would be a huge step forward in the field of medical imaging, as it would allow doctors to diagnose conditions from images without the need of a human doctor.\n",
      "This would be a huge step forward in the field of medical imaging, as it would allow doctors to diagnose conditions from images without the need of a human doctor. This would be a huge step forward in the field of medical imaging, as it would allow doctors to diagnose conditions from images without the need of a human doctor.\n",
      "This would be a huge step forward in the field of medical imag, as it would allow doctors to diagnose conditions from images without the need of a human doctor. This would be a huge step forward in the field of medical imag, as it would allow doctors to diagnose conditions from images without the need of a human doctor.\n",
      "This would be a huge step forward in the field of medical imag, as it would allow doctors to diagnose conditions from images without the need of a human doctor. This would be a huge step forward in the field of medical imag, as it would allow doctors to diagnose conditions from images without the need of a human doctor.\n",
      "This would be a huge step forward in the field of medical imag, as it would allow doctors to diagnose conditions from images without the need of a human doctor. This would be a huge step forward in the field of medical imag, as it would allow doctors to diagnose conditions from images without the need of a human doctor.\n",
      "This would be a huge step forward in the field of medical imag, as it would allow doctors to diagnose conditions from images without the need of a human doctor. This would be a huge step forward in the field of medical imag, as it would allow doctors to diagnose conditions from images without the need of a human\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m In the field of computer vision, convolutional neural networks have revolutionized the way machines perceive visual information. By mimicking the human visual system, these networks can classify images, detect objects, and even perform image segmentation. This has significant applications in areas such as medical imaging, where AI can assist doctors in diagnosing conditions from X-rays and MRIs. As the technology advances, we may soon see AI systems that \u001b[0m\u001b[91mcan not. In the future, we may also see AI systems that can detect and diagnose diseases from images. This would be a huge step forward in the field of medical imaging, as it would allow doctors to diagnose conditions from images without the need of a human doctor. This would be a huge step forward in the field of medical imag, as it would allow doctors to diagnose conditions from images without the need of a human doctor.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Reinforcement learning algorithms learn optimal behaviors through \u001b[0m\u001b[91m the use of reinforcement signals.\n",
      "The most common reinforcement signal is a reward, which is a number or other scalar value that is assigned to the outcome of an action.\n",
      "For example, a reward of 1 is often given to a person who completes a task correctly.\n",
      "A reward of 0 is usually given to a person who fails a task.\n",
      "The more positive the reward, the more likely the person will be to repeat the task.\n",
      "The less positive the reward, the less likely the person will be to try the task again.\n",
      "The more negative the reward, the less likely the person will not try the task again.\n",
      "The more negative the reward, the less likely the person will not try the task again.\n",
      "The more negative the reward, the less likely the person will not try the task again. The more negative the reward, the less likely the person will not try the task again.\n",
      "The more negative the reward, the less likely the person will not try the task again. The more negative the reward, the less likely the person will not try the task again. The more negative the reward, the less likely the person will not try the task again.\n",
      "The more negative the reward, the more likely the person will not try the task again. The more negative the reward, the more likely the person will not try the task again.\n",
      "The more negative the reward, the more likely the person will not try the task again. The more negative the reward, the more likely the person will not try the task again.\n",
      "The more negative the reward, the more likely the person will not try the task again. The more negative the reward, the more likely the person will not try the task again.\n",
      "The more negative the reward, the more likely the person will not try the task again. The more negative the reward, the more likely the person will not try the task again.\n",
      "The more negative the reward, the more likely the person will not try the task again. The more negative the reward, the more likely the person will not try the task again.\n",
      "The more negative the reward, the more likely the person will not try the task again. The more negative the reward, the more likely the person will not try the task again.\n",
      "The more negative the reward, the more likely the person will not try the task again. The more negative the reward, the more likely the person will not try the task again.\n",
      "The more negative the reward,\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Reinforcement learning algorithms learn optimal behaviors through \u001b[0m\u001b[91mthe use of reinforcement signals. The most common reinforcement signal is a reward, which is a number or other scalar value that is assigned to the outcome of an action. For example, a reward of 1 is often given to a person who completes a task correctly. A reward of 0 is usually given to a person who fails a task. The more positive the reward, the more likely the person will be to repeat the task. The less positive the reward, the less likely the person will be to try the task again. The more negative the reward, the less likely the person will not try the task again. The more negative the reward, the more likely the person will not try the task again.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could \u001b[0m\u001b[91m potentially break many of the cryptographic algorithms that are currently in use.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "\n",
      "\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "\t\n",
      "\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could \u001b[0m\u001b[91m.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that \u001b[0m\u001b[91m can be used to solve some of the world’s most complex problems.\n",
      "The future of AI is looking more and more promising. With the advancements in technology, we are now able to create more powerful and efficient AI systems that can be used to solve a wide range of problems. We are also able to create more realistic simulations of the world, which can be used to test and improve our AI systems.\n",
      "The future of AI is looking more and more promising. With the advancements in technology, we are now able to create more powerful and efficient AI systems that can be used to solve a wide range of problems. We are also able to create more realistic simulations of the world, which can be used to test and improve our AI systems.\n",
      "The future of AI is looking more and more promising. With the advancements in technology, we are now able to create more powerful and efficient AI systems that can be used to solve a wide range of problems. We are also able to create more realistic simulations of the world, which can be used to test and improve our AI systems.\n",
      "The future of AI is looking more and more promising. With the advancements in technology, we are now able to create more powerful and efficient AI systems that can be used to solve a wide range of problems. We are also able to create more realistic simulations of the world, which can be used to test and improve our AI systems.\n",
      "The future of AI is looking more and more promising. With the advancements in technology, we are now able to create more powerful and efficient AI systems that can be used to solve a wide range of problems. We are also able to create more realistic simulations of the world, which can be used to test and improve our AI systems.\n",
      "The future of AI is looking more and more prom\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that \u001b[0m\u001b[91mcan be used to solve some of the world’s most complex problems. The future of AI is looking more and more promising. With the advancements in technology, we are now able to create more powerful and efficient AI systems that can be used to solve a wide range of problems. We are also able to create more realistic simulations of the world, which can be used to test and improve our AI systems.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Transfer learning allows models trained on large datasets to be fine-tuned for specific tasks by \u001b[0m\u001b[91m.\n",
      "The term “deep” is a reference to the fact that the network is composed deep, or deep, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers. The term “deep” is a\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Transfer learning allows models trained on large datasets to be fine-tuned for specific tasks by \u001b[0m\u001b[91mThe term “deep” is a reference to the fact that the network is composed deep, or deep, layers. The term “deep” is a reference to the fact that the network is composed of many, or many, layers.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Explainable AI (XAI) is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to \u001b[0m\u001b[91m help users understand and trust the decisions being made by the system.\n",
      "AI is a powerful tool that can be used to improve a wide range of industries, from healthcare to finance. However, it is important to remember that AI is not a pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan pan\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Explainable AI (XAI) is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to \u001b[0m\u001b[91mhelp users understand and trust the decisions being made by the system. AI is a powerful tool that can be used to improve a wide range of industries, from healthcare to finance.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and \u001b[0m\u001b[91m the sun slowly disapp...\n",
      "\n",
      "## Gameplay\n",
      "\n",
      "The game is a 2-to--ad-and-up-to-4-ad-and-up-to-6-ad-and-up-to-8-ad-and-up-to-10-ad-and-up-to-12-ad-and-up-to-14-ad-and-up-to-16-ad-and-up-to-18-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-20-ad-and-up-to-2\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and \u001b[0m\u001b[91mthe sun slowly disapp.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of \u001b[0m\u001b[91m the world.\n",
      "Traveling to new countries allows you to experience diverse cultures and traditions.\n",
      "Traveling to new countries allows you to experience different landscapes and environments.\n",
      "Traveling to new countries allows you to explore and discover new places.\n",
      "Traveling to new countries allows you to experience different cultures and traditions.\n",
      "Traveling to new countries allows you to experience different landscapes and environments. Traveling to new countries allows you to explore and discover new places. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and traditions. Traveling to new countries allows you to experience different cultures and trad\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of \u001b[0m\u001b[91mthe world. Traveling to new countries allows you to experience diverse cultures and traditions. Traveling to new countries allows you to experience different landscapes and environments. Traveling to new countries allows you to explore and discover new places. Traveling to new countries allows you to experience different cultures and traditions.\u001b[0m\n",
      "\n",
      "\n",
      "Pruning model\n",
      "Model size after pruning:  13.510393856\n",
      "Model size after pruning:  13.482573824\n",
      "Model size after pruning:  13.469990912\n",
      "Model size after pruning:  13.418381312\n",
      "Model size after pruning:  13.418381312\n",
      "Model size after pruning:  13.405011968\n",
      "Model size after pruning:  13.379846144\n",
      "Model size after pruning:  13.336395776\n",
      "Model size after pruning:  13.332201472\n",
      "Model size after pruning:  13.317922816\n",
      "Model size after pruning:  13.313728512\n",
      "Model size after pruning:  13.292961792\n",
      "Model size after pruning:  13.288767488\n",
      "Model size after pruning:  13.271785472\n",
      "Model size after pruning:  13.25920256\n",
      "Model size after pruning:  13.251559424\n",
      "Model size after pruning:  13.238976512\n",
      "Model size after pruning:  13.233790976\n",
      "Model size after pruning:  13.229596672\n",
      "Model size after pruning:  13.22463232\n",
      "Model size after pruning:  13.216243712\n",
      "Model size after pruning:  13.211254784\n",
      "Model size after pruning:  13.194477568\n",
      "Model size after pruning:  13.158375424\n",
      "Model size after pruning:  13.158375424\n",
      "Model size after pruning:  13.13542144\n",
      "Model size after pruning:  13.110255616\n",
      "Model size after pruning:  13.108953088\n",
      "Model size after pruning:  13.083787264\n",
      "Model size after pruning:  13.062332416\n",
      "Model size after pruning:  13.062332416\n",
      "Model size after pruning:  13.033873408\n",
      "Model size after pruning:  13.029679104\n",
      "Model size after pruning:  13.008912384\n",
      "Model size after pruning:  13.000523776\n",
      "Model size after pruning:  12.985851904\n",
      "Model size after pruning:  12.985851904\n",
      "Model size after pruning:  12.98243584\n",
      "Model size after pruning:  12.957270016\n",
      "Model size after pruning:  12.910379008\n",
      "Model size after pruning:  12.885213184\n",
      "Model size after pruning:  12.831096832\n",
      "Model size after pruning:  12.805931008\n",
      "Model size after pruning:  12.751814656\n",
      "Model size after pruning:  12.726648832\n",
      "Model size after pruning:  12.67253248\n",
      "Model size after pruning:  12.647366656\n",
      "Model size after pruning:  12.593250304\n",
      "Saving model after pruning to checkpoint dir\n",
      "Model saved\n",
      "Real Pruned Model\n",
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (4): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (o_proj): Linear(in_features=3968, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=9876, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=9876, bias=False)\n",
      "          (down_proj): Linear(in_features=9876, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (5): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3712, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3712, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3712, bias=False)\n",
      "          (o_proj): Linear(in_features=3712, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=8908, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=8908, bias=False)\n",
      "          (down_proj): Linear(in_features=8908, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (6): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10464, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10464, bias=False)\n",
      "          (down_proj): Linear(in_features=10464, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (7): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (o_proj): Linear(in_features=3328, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=9240, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=9240, bias=False)\n",
      "          (down_proj): Linear(in_features=9240, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (8): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (o_proj): Linear(in_features=3968, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10427, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10427, bias=False)\n",
      "          (down_proj): Linear(in_features=10427, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (9): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (o_proj): Linear(in_features=3968, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10163, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10163, bias=False)\n",
      "          (down_proj): Linear(in_features=10163, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (10): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (o_proj): Linear(in_features=3968, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10317, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10317, bias=False)\n",
      "          (down_proj): Linear(in_features=10317, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (11): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3712, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3712, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3712, bias=False)\n",
      "          (o_proj): Linear(in_features=3712, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10697, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10697, bias=False)\n",
      "          (down_proj): Linear(in_features=10697, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (12): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3712, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3712, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3712, bias=False)\n",
      "          (o_proj): Linear(in_features=3712, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10797, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10797, bias=False)\n",
      "          (down_proj): Linear(in_features=10797, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (13): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (o_proj): Linear(in_features=3968, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10806, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10806, bias=False)\n",
      "          (down_proj): Linear(in_features=10806, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (14): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (o_proj): Linear(in_features=3840, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10805, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10805, bias=False)\n",
      "          (down_proj): Linear(in_features=10805, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (15): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "          (o_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=9539, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=9539, bias=False)\n",
      "          (down_proj): Linear(in_features=9539, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (16): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10074, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10074, bias=False)\n",
      "          (down_proj): Linear(in_features=10074, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (17): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (o_proj): Linear(in_features=3328, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10955, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10955, bias=False)\n",
      "          (down_proj): Linear(in_features=10955, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (18): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (o_proj): Linear(in_features=3328, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10135, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10135, bias=False)\n",
      "          (down_proj): Linear(in_features=10135, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (19): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=9850, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=9850, bias=False)\n",
      "          (down_proj): Linear(in_features=9850, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (20): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (o_proj): Linear(in_features=3968, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10163, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10163, bias=False)\n",
      "          (down_proj): Linear(in_features=10163, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (21): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (o_proj): Linear(in_features=3840, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10411, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10411, bias=False)\n",
      "          (down_proj): Linear(in_features=10411, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (22): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10869, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10869, bias=False)\n",
      "          (down_proj): Linear(in_features=10869, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (23): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (o_proj): Linear(in_features=3328, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=9100, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=9100, bias=False)\n",
      "          (down_proj): Linear(in_features=9100, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (24-27): 4 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3328, bias=False)\n",
      "          (o_proj): Linear(in_features=3328, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=8806, bias=False)\n",
      "          (down_proj): Linear(in_features=8806, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (28-31): 4 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n",
      "Real Pruned Model Size\n",
      "12.593250304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short Context: 20.326270996495822 tokens/sec, 24 tokens (including full prompt)\n",
      "Long Context: 41.43768205141343 tokens/sec, 1288 tokens (including full prompt)\n",
      "Average:  20.555450386164807 tokens/sec\n",
      "***************   Experiment completed successfully Successfully   ***************\n"
     ]
    }
   ],
   "source": [
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a9cb09a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:21:20.409690Z",
     "start_time": "2024-05-25T04:21:20.402167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6277746688"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26f160e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed5ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0.95\n",
    "+---------------+-----------+----------------------+----------------+-----------------------+\n",
    "|     Alias     | Acc, None |   Acc StdErr, None   | Acc Norm, None | Acc Norm StdErr, None |\n",
    "+---------------+-----------+----------------------+----------------+-----------------------+\n",
    "|     boolq     |    0.74   | 0.04408440022768078  |      None      |          None         |\n",
    "| arc_challenge |    0.42   | 0.04960449637488584  |      0.43      |  0.049756985195624284 |\n",
    "|   hellaswag   |    0.53   | 0.050161355804659205 |      0.68      |  0.04688261722621504  |\n",
    "|   openbookqa  |    0.31   | 0.04648231987117316  |      0.44      |  0.04988876515698589  |\n",
    "|   winogrande  |    0.69   | 0.04648231987117316  |      None      |          None         |\n",
    "|    arc_easy   |    0.7    | 0.046056618647183814 |      0.76      |  0.04292346959909284  |\n",
    "|      rte      |    0.72   | 0.045126085985421276 |      None      |          None         |\n",
    "+---------------+-----------+----------------------+----------------+-----------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9642c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0.9\n",
    "+---------------+-----------+----------------------+----------------+-----------------------+\n",
    "|     Alias     | Acc, None |   Acc StdErr, None   | Acc Norm, None | Acc Norm StdErr, None |\n",
    "+---------------+-----------+----------------------+----------------+-----------------------+\n",
    "|      rte      |    0.58   | 0.04960449637488584  |      None      |          None         |\n",
    "|   openbookqa  |    0.22   | 0.04163331998932268  |      0.37      |  0.04852365870939098  |\n",
    "|     boolq     |    0.69   | 0.04648231987117316  |      None      |          None         |\n",
    "|   hellaswag   |    0.48   | 0.050211673156867795 |      0.64      |  0.04824181513244218  |\n",
    "|    arc_easy   |    0.59   | 0.04943110704237102  |      0.67      |  0.04725815626252607  |\n",
    "| arc_challenge |    0.42   | 0.049604496374885836 |      0.42      |  0.04960449637488584  |\n",
    "|   winogrande  |    0.6    | 0.049236596391733084 |      None      |          None         |\n",
    "+---------------+-----------+----------------------+----------------+-----------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd132ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0.8\n",
    "+---------------+-----------+----------------------+----------------+-----------------------+\n",
    "|     Alias     | Acc, None |   Acc StdErr, None   | Acc Norm, None | Acc Norm StdErr, None |\n",
    "+---------------+-----------+----------------------+----------------+-----------------------+\n",
    "|   openbookqa  |    0.21   | 0.040936018074033256 |      0.4       |  0.049236596391733084 |\n",
    "|      rte      |    0.63   | 0.04852365870939099  |      None      |          None         |\n",
    "| arc_challenge |    0.29   | 0.04560480215720684  |      0.36      |  0.04824181513244218  |\n",
    "|   winogrande  |    0.69   | 0.04648231987117316  |      None      |          None         |\n",
    "|     boolq     |    0.67   | 0.04725815626252609  |      None      |          None         |\n",
    "|    arc_easy   |    0.51   | 0.05024183937956912  |      0.53      |  0.05016135580465919  |\n",
    "|   hellaswag   |    0.45   | 0.049999999999999996 |      0.65      |   0.0479372485441102  |\n",
    "+---------------+-----------+----------------------+----------------+-----------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a9a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0.7\n",
    "+---------------+-----------+----------------------+----------------+-----------------------+\n",
    "|     Alias     | Acc, None |   Acc StdErr, None   | Acc Norm, None | Acc Norm StdErr, None |\n",
    "+---------------+-----------+----------------------+----------------+-----------------------+\n",
    "|      rte      |    0.64   | 0.048241815132442176 |      None      |          None         |\n",
    "| arc_challenge |    0.33   | 0.047258156262526045 |      0.32      |  0.046882617226215034 |\n",
    "|   winogrande  |    0.66   | 0.04760952285695237  |      None      |          None         |\n",
    "|    arc_easy   |    0.53   | 0.050161355804659205 |      0.54      |  0.05009082659620332  |\n",
    "|   hellaswag   |    0.39   | 0.04902071300001974  |      0.56      |  0.04988876515698589  |\n",
    "|   openbookqa  |    0.28   | 0.04512608598542128  |      0.43      |  0.04975698519562428  |\n",
    "|     boolq     |    0.71   | 0.04560480215720685  |      None      |          None         |\n",
    "+---------------+-----------+----------------------+----------------+-----------------------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819a0d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0.6\n",
    "+---------------+-----------+----------------------+----------------+-----------------------+\n",
    "|     Alias     | Acc, None |   Acc StdErr, None   | Acc Norm, None | Acc Norm StdErr, None |\n",
    "+---------------+-----------+----------------------+----------------+-----------------------+\n",
    "|    arc_easy   |    0.41   | 0.049431107042371025 |      0.36      |  0.04824181513244218  |\n",
    "|   winogrande  |    0.55   |         0.05         |      None      |          None         |\n",
    "|   hellaswag   |    0.36   | 0.04824181513244218  |      0.49      |  0.05024183937956912  |\n",
    "|     boolq     |    0.45   |         0.05         |      None      |          None         |\n",
    "|      rte      |    0.57   | 0.04975698519562428  |      None      |          None         |\n",
    "|   openbookqa  |    0.14   | 0.03487350880197769  |      0.29      |  0.045604802157206845 |\n",
    "| arc_challenge |    0.21   | 0.040936018074033256 |      0.31      |  0.04648231987117316  |\n",
    "+---------------+-----------+----------------------+----------------+-----------------------+\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38422556",
   "metadata": {},
   "source": [
    "## Experiment 2540 --> PreserveRatio=0.8, lbound=0.7, rbound=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fc553c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:22:11.556068Z",
     "start_time": "2024-05-25T04:22:11.547977Z"
    }
   },
   "outputs": [],
   "source": [
    "pruning_dict = \"pruning_dict_1.0_0.7_1.0_chat_2540.json\"\n",
    "save_dir = \"/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/\"\n",
    "\n",
    "p = pruning_dict.split(\"_\")[-1].split(\".\")[-2]\n",
    "output_dir = \"/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints//\" + p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b4dae91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:22:12.100896Z",
     "start_time": "2024-05-25T04:22:12.093412Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment = ExperimentRunner(pipeline, tokenizer, pruning_dict, \n",
    "                 save_dir=save_dir, output_dir=output_dir, ignored_layers=None, \n",
    "                 use_template=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da92c1d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:45:13.572780Z",
     "start_time": "2024-05-25T04:22:12.346679Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************   Running Experiment   ***************\n",
      "61 ==>  4096\n",
      "67 ==>  11008\n",
      "75 ==>  4096\n",
      "81 ==>  11004\n",
      "89 ==>  4096\n",
      "95 ==>  11003\n",
      "103 ==>  4096\n",
      "109 ==>  11008\n",
      "117 ==>  4096\n",
      "123 ==>  11007\n",
      "131 ==>  4096\n",
      "137 ==>  11007\n",
      "145 ==>  4096\n",
      "151 ==>  10994\n",
      "159 ==>  4096\n",
      "165 ==>  11000\n",
      "173 ==>  4096\n",
      "179 ==>  8538\n",
      "187 ==>  2816\n",
      "193 ==>  7706\n",
      "201 ==>  2816\n",
      "207 ==>  7706\n",
      "215 ==>  2816\n",
      "221 ==>  7706\n",
      "229 ==>  2816\n",
      "235 ==>  7767\n",
      "243 ==>  2816\n",
      "249 ==>  7784\n",
      "257 ==>  2816\n",
      "263 ==>  7777\n",
      "271 ==>  2816\n",
      "277 ==>  7780\n",
      "285 ==>  2816\n",
      "291 ==>  7778\n",
      "299 ==>  2816\n",
      "305 ==>  7780\n",
      "313 ==>  2816\n",
      "319 ==>  7778\n",
      "327 ==>  2816\n",
      "333 ==>  7780\n",
      "341 ==>  2816\n",
      "347 ==>  7778\n",
      "355 ==>  2816\n",
      "361 ==>  7780\n",
      "369 ==>  2816\n",
      "375 ==>  7778\n",
      "383 ==>  2816\n",
      "389 ==>  7780\n",
      "***************   Pruning Model   ***************\n",
      "Pruning model\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Saving model after pruning to checkpoint dir\n",
      "Model saved\n",
      "***************   Model Pruned Successfully   ***************\n",
      "Model Size after Pruning:  13.51458816\n",
      "evaluating on wikitext2\n",
      "nsamples 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:   0%|                                                                                                                                                                                                                                                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:   4%|████████████▎                                                                                                                                                                                                                                                                                                      | 1/25 [00:00<00:14,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:   8%|████████████████████████▌                                                                                                                                                                                                                                                                                          | 2/25 [00:01<00:13,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  12%|████████████████████████████████████▊                                                                                                                                                                                                                                                                              | 3/25 [00:01<00:12,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  16%|█████████████████████████████████████████████████                                                                                                                                                                                                                                                                  | 4/25 [00:02<00:12,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  20%|█████████████████████████████████████████████████████████████▍                                                                                                                                                                                                                                                     | 5/25 [00:02<00:11,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  24%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                                                                         | 6/25 [00:03<00:10,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  28%|█████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                                                                                             | 7/25 [00:04<00:10,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  32%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                                                                                | 8/25 [00:04<00:09,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  36%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                                    | 9/25 [00:05<00:09,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  40%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                                                       | 10/25 [00:05<00:08,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  44%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                           | 11/25 [00:06<00:08,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  48%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                               | 12/25 [00:07<00:07,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  52%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                                   | 13/25 [00:07<00:07,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                      | 14/25 [00:08<00:06,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                          | 15/25 [00:08<00:05,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                              | 16/25 [00:09<00:05,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                  | 17/25 [00:09<00:04,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                     | 18/25 [00:10<00:04,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                         | 19/25 [00:11<00:03,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                             | 20/25 [00:11<00:02,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                 | 21/25 [00:12<00:02,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 22/25 [00:12<00:01,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 23/25 [00:13<00:01,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 24/25 [00:14<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WikiText Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:14<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPL:  15.140096664428711\n",
      "Perplexity on wikitext2:  15.140096664428711\n",
      "Loading checkpoint from /data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model passed to evaluation:  LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-25:09:53:50,495 WARNING  [task.py:763] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-05-25:09:53:50,497 WARNING  [task.py:775] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2024-05-25:09:53:56,827 WARNING  [task.py:763] [Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-05-25:09:53:56,829 WARNING  [task.py:775] [Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for winogrande contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/winogrande\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2024-05-25:09:54:38,861 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-05-25:09:54:38,863 INFO     [evaluator.py:177] Initializing huggingface model, with arguments: {'pretrained': '/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/'}\n",
      "2024-05-25:09:54:38,875 WARNING  [logging.py:61] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "2024-05-25:09:54:38,876 INFO     [huggingface.py:163] Using device 'cuda'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f762c59606242bba23787b731bbdad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-25:09:55:11,884 WARNING  [task.py:763] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-05-25:09:55:11,886 WARNING  [task.py:775] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-05-25:09:55:29,970 WARNING  [task.py:763] [Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-05-25:09:55:29,972 WARNING  [task.py:775] [Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-05-25:09:55:59,231 WARNING  [evaluator.py:239] Overwriting default num_fewshot of openbookqa from None to 0\n",
      "2024-05-25:09:55:59,232 WARNING  [evaluator.py:239] Overwriting default num_fewshot of rte from None to 0\n",
      "2024-05-25:09:55:59,232 WARNING  [evaluator.py:239] Overwriting default num_fewshot of arc_challenge from None to 0\n",
      "2024-05-25:09:55:59,233 WARNING  [evaluator.py:239] Overwriting default num_fewshot of winogrande from None to 0\n",
      "2024-05-25:09:55:59,233 WARNING  [evaluator.py:239] Overwriting default num_fewshot of boolq from None to 0\n",
      "2024-05-25:09:55:59,235 WARNING  [evaluator.py:239] Overwriting default num_fewshot of arc_easy from None to 0\n",
      "2024-05-25:09:55:59,235 WARNING  [evaluator.py:239] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2024-05-25:09:55:59,239 INFO     [task.py:395] Building contexts for openbookqa on rank 0...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1665.25it/s]\n",
      "2024-05-25:09:55:59,311 INFO     [task.py:395] Building contexts for rte on rank 0...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1408.36it/s]\n",
      "2024-05-25:09:55:59,390 INFO     [task.py:395] Building contexts for arc_challenge on rank 0...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 869.50it/s]\n",
      "2024-05-25:09:55:59,517 INFO     [task.py:395] Building contexts for winogrande on rank 0...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 59807.56it/s]\n",
      "2024-05-25:09:55:59,527 INFO     [task.py:395] Building contexts for boolq on rank 0...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1407.19it/s]\n",
      "2024-05-25:09:55:59,607 INFO     [task.py:395] Building contexts for arc_easy on rank 0...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 850.86it/s]\n",
      "2024-05-25:09:55:59,739 INFO     [task.py:395] Building contexts for hellaswag on rank 0...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 2026.37it/s]\n",
      "2024-05-25:09:55:59,817 INFO     [evaluator.py:379] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2199/2199 [02:02<00:00, 17.99it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "fatal: not a git repository (or any parent up to mount point /)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "|     Alias     | Acc, None |   Acc StdErr, None   | Acc Norm, None | Acc Norm StdErr, None |\n",
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "|   openbookqa  |    0.21   | 0.040936018074033256 |      0.4       |  0.049236596391733084 |\n",
      "|      rte      |    0.63   | 0.04852365870939099  |      None      |          None         |\n",
      "| arc_challenge |    0.29   | 0.04560480215720684  |      0.36      |  0.04824181513244218  |\n",
      "|   winogrande  |    0.69   | 0.04648231987117316  |      None      |          None         |\n",
      "|     boolq     |    0.67   | 0.04725815626252609  |      None      |          None         |\n",
      "|    arc_easy   |    0.51   | 0.05024183937956912  |      0.53      |  0.05016135580465919  |\n",
      "|   hellaswag   |    0.45   | 0.049999999999999996 |      0.65      |   0.0479372485441102  |\n",
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Gardening provides a sense of accomplishment and tranquility, as you nurture plants and watch them \u001b[0m\u001b[91m grow.\n",
      "The benefits of gardening are numerous. It is a great way to relax and enjoy the outdoors. It is also a great way to get some exercise. It is also a great way to meet new people. It is also a great way to learn about the environment. It is also a great way to learn about the history of the area. It is also a great way to learn about the culture of the area. It is also a great way to learn about the food of the area. It is also a great way to learn about the wildlife of the area. It is also a great way to learn about the medicinal plants of the area. It is also a great way to learn about the history of the people of the area. It is also a great way to learn about the history of the land of the area. It is also a great way to learn about the history of the country of the area. It is also a great way to learn about the history of the world of the area. It is also a great way to learn about the history of the universe of the area. It is also a great way to learn about the history of the universe of the world of the area. It is also a great way to learn about the history of the world of the universe of the world of the area. It is also a great way to learn about the history of the world of the universe of the world of the world of the area. It is also a great way to learn about the history of the world of the universe of the world of the world of the world of the area. It is also a great way to learn about the history of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Gardening provides a sense of accomplishment and tranquility, as you nurture plants and watch them \u001b[0m\u001b[91mgrow. The benefits of gardening are numerous. It is a great way to relax and enjoy the outdoors. It is also a great way to get some exercise. It is also a great way to meet new people. It is also a great way to learn about the environment. It is also a great way to learn about the history of the area. It is also a great way to learn about the culture of the area. It is also a great way to learn about the food of the area. It is also a great way to learn about the wildlife of the area. It is also a great way to learn about the medicinal plants of the area. It is also a great way to learn about the history of the people of the area. It is also a great way to learn about the history of the land of the area. It is also a great way to learn about the history of the country of the area. It is also a great way to learn about the history of the world of the area. It is also a great way to learn about the history of the universe of the area. It is also a great way to learn about the history of the universe of the world of the area. It is also a great way to learn about the history of the world of the universe of the world of the area. It is also a great way to learn about the history of the world of the universe of the world of the world of the area. It is also a great way to learn about the history of the world of the universe of the world of the world of the world of the area.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Family traditions are passed down from generation to generation, creating a sense of continuity and belonging. Whether it's holiday celebrations, special recipes, or annual gatherings, these traditions foster \u001b[0m\u001b[91m a sense of identity and connection.\n",
      "3. Traditions are a great way to teach children about the world around them. Traditional celebrations are a great way to teach children about the world around them. They can be a great way to teach children about the world around them.\n",
      "4. Traditions are a great way to teach children about the world around them. Traditional celebrations are a great way to teach children about the world around them. They can be a great way to teach children about the world around them.\n",
      "5. Traditional celebrations are a great way to teach children about the world around them. Traditional celebrations are a great way to teach children about the world around them. They can be a great way to teach children about the world around them.\n",
      "6. Traditional celebrations are a great way to teach children about the world around them. Traditional celebrations are a great way to teach children about the world around them. They can be a great way to teach children about the world around them.\n",
      "7. Traditional celebrations are a great way to teach children about the world around them. Traditional celebrations are a great way to teach children about the world around them. They can be a great way to teach children about the world around them.\n",
      "8. Traditional celebrations are a great way to teach children about the world around them. Traditional celebrations are a great way to teach children about the world around them. They can be a great way to teach children about the world around them.\n",
      "9. Traditional celebrations are a great way to teach children about the world around them. Traditional celebrations are a great way to teach children about the world around them. They can be a great way to teach children about the world around them.\n",
      "10. Traditional celebrations are a great way to teach children about the world around them. Traditional celebrations are a great way to teach children about the world around them. They can be a great way to teach children about the world around them.\n",
      "11. Traditional celebrations are a great way to teach children about the world around them. Traditional celebrations are a great way to teach children about the world around them. They can be a great way to teach children about the world around them.\n",
      "12. Traditional celebrations are a great way to teach children about the world around them. Traditional celebrations are a great way to teach children about the world around them. They\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Family traditions are passed down from generation to generation, creating a sense of continuity and belonging. Whether it's holiday celebrations, special recipes, or annual gatherings, these traditions foster \u001b[0m\u001b[91ma sense of identity and connection. 3. Traditions are a great way to teach children about the world around them. Traditional celebrations are a great way to teach children about the world around them. They can be a great way to teach children about the world around them. 4. 5. 6. 7. 8. 9. 10. 11. 12.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future \u001b[0m\u001b[91m, fashion may be sh-y of the world of the metaverse, where fashion is a part of a virtual world.\n",
      "The fashion industry is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future \u001b[0m\u001b[91m, fashion may be sh-y of the world of the metaverse, where fashion is a part of a virtual world.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Artificial intelligence is transforming the healthcare industry by enabling \u001b[0m\u001b[91m hospitals to make more informed decisions about patient care.\n",
      "The healthcare industry is one of the largest in the world, and it is also one of the most complex. The industry is also one of the most important in the world, as it is the source of the most expensive healthcare in the world.\n",
      "The healthcare industry is also one of the most difficult to enter. The industry is also one of the most dangerous in the world, as it is the source of the most dangerous infections in the world.\n",
      "The healthcare industry is also one of the most rewarding in the world, as it is the source of the most rewarding experiences in the world.\n",
      "The healthcare industry is also one of the most frustrating in the world, as it is the source of the most frustrating experiences in the world.\n",
      "The healthcare industry is also one of the most inspiring in the world, as it is the source of the most inspiring experiences in the world.\n",
      "The healthcare industry is also one of the most depressing in the world, as it is the source of the most depressing experiences in the world.\n",
      "The healthcare industry is also one of the most exhilarating in the world, as it is the source of the most exhilarating experiences in the world.\n",
      "The healthcare industry is also one of the most frightening in the world, as it is the source of the most frightening experiences in the world.\n",
      "The healthcare industry is also one of the most inspiring in the world, as it is the source of the most inspiring experiences in the world.\n",
      "The healthcare industry is also one of the most depressing in the world, as it is the source of the most depressing experiences in the world.\n",
      "The healthcare industry is also one of the most frightening in the world, as it is the source of the most frightening experiences in the world.\n",
      "The healthcare industry is also one of the most inspiring in the world, as it is the source of the most inspiring experiences in the world.\n",
      "The healthcare industry is also one of the most frightening in the world, as it is the source of the most frightening experiences in the world.\n",
      "The healthcare industry is also one of the most inspiring in the world, as it is the source of the most inspiring experiences in the world.\n",
      "The healthcare industry is also one of\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Artificial intelligence is transforming the healthcare industry by enabling \u001b[0m\u001b[91mhospitals to make more informed decisions about patient care. The healthcare industry is one of the largest in the world, and it is also one of the most complex. The industry is also one of the most important in the world, as it is the source of the most expensive healthcare in the world. The healthcare industry is also one of the most difficult to enter. The industry is also one of the most dangerous in the world, as it is the source of the most dangerous infections in the world. The healthcare industry is also one of the most rewarding in the world, as it is the source of the most rewarding experiences in the world. The healthcare industry is also one of the most frustrating in the world, as it is the source of the most frustrating experiences in the world. The healthcare industry is also one of the most inspiring in the world, as it is the source of the most inspiring experiences in the world. The healthcare industry is also one of the most depressing in the world, as it is the source of the most depressing experiences in the world. The healthcare industry is also one of the most exhilarating in the world, as it is the source of the most exhilarating experiences in the world. The healthcare industry is also one of the most frightening in the world, as it is the source of the most frightening experiences in the world.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Machine learning algorithms are increasingly being used to predict stock market trends. By analyzing historical data and identifying patterns, these models can \u001b[0m\u001b[91m predict whether a stock will be sold at a certain price, or whether it will be bought at a certain price.\n",
      "The problem is that these algorithms are not always accurate. In fact, they are often wrong. This is because they are not always able to predict the future. They are only able to predict the past.\n",
      "This is a problem because the future is not always the same as the past. The future is a lot more complicated. It is a lot more difficult to predict the future.\n",
      "The problem is that the future is not always the same as the past. The future is a lot more complicated. It is a lot more difficult to predict the future.\n",
      "The problem is that the future is not always the same as the past. The future is a lot more complicated. It is a lot more difficult to predict the future.\n",
      "The problem is that the future is not always the same as the past. The future is a lot more complicated. It is a lot more difficult to predict the future.\n",
      "The problem is that the future is not always the same as the past. The future is a lot more complicated. It is a lot more difficult to predict the future.\n",
      "The problem is that the future is not always the same as the past. The future is a lot more complicated. It is a lot more difficult to predict the future.\n",
      "The problem is that the future is not always the same as the past. The future is a lot more complicated. It is a lot more difficult to predict the future.\n",
      "The problem is that the future is not always the same as the past. The future is a lot more complicated. It is a lot more difficult to predict the future.\n",
      "The problem is that the future is not always the same as the past. The future is a lot more complicated. It is a lot more difficult to predict the future.\n",
      "The problem is that the future is not always the same as the past. The future is a lot more complicated. It is a lot more difficult to predict the future.\n",
      "The problem is that the future is not always the same as the past. The future is a lot more complicated. It is a lot more difficult to predict the future.\n",
      "The problem is that the future is not always the same as the past. The future is a lot more complicated. It is a lot more difficult to predict the future.\n",
      "The problem is that the future is not always the same as the past. The future is a lot more complicated. It is\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Machine learning algorithms are increasingly being used to predict stock market trends. By analyzing historical data and identifying patterns, these models can \u001b[0m\u001b[91mpredict whether a stock will be sold at a certain price, or whether it will be bought at a certain price. The problem is that these algorithms are not always accurate. In fact, they are often wrong. This is because they are not always able to predict the future. They are only able to predict the past. This is a problem because the future is not always the same as the past. The future is a lot more complicated. It is a lot more difficult to predict the future. The problem is that the future is not always the same as the past.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The integration of natural language processing with machine learning has opened up new possibilities in human-computer interaction. For instance, chatbots powered by sophisticated NLP algorithms can now understand and respond to user queries with remarkable accuracy. As these technologies continue to evolve, we can expect that \u001b[0m\u001b[91m they will be used more frequently in the workplace.\n",
      "The use of AI in the workplace is not without its challenges. One of the biggest concerns is the potential for the technology to be used as a tool for discrimination. This is a legitimate concern, as we have seen it happen in the past. However, we can be confident that the technology will be used in a way that is not discriminatory.\n",
      "The future of AI in the workplace is looking to be a bright one. The technology is becoming more and more powerful, and the ability to integrate it with other technologies is only going to increase. This is a great time to be working in the workplace.\n",
      "The future of AI in the workplace is looking to be a bright one. The technology is becoming more and more powerful, and the ability to integrate it with other technologies is only going to increase. This is a great time to be working in the workplace. The future of AI in the workplace is looking to be a bright one. The technology is becoming more and more powerful, and the ability to integrate it with other technologies is only going to increase. This is a great time to be working in the workplace.\n",
      "The future of AI in the workplace is looking to be a bright one. The technology is becoming more and more powerful, and the ability to integrate it with other technologies is only going to increase. This is a great time to be working in the workplace.\n",
      "The future of AI in the workplace is looking to be a bright one. The technology is becoming more and more powerful, and the ability to integrate it with other technologies is only going to increase. This is a great time to be working in the workplace. The future of AI in the workplace is looking to be a bright one. The technology is becoming more and more powerful, and the ability to integrate it with other technologies is only going to increase. This is a great time to be working in the workplace. The future of AI in the workplace is looking to be a bright one. The technology is becoming more and more powerful, and the ability to integrate it with other technologies is only going to increase. This is a great time to be working in the workplace. The future of AI in the workplace is looking to be a bright one. The technology is becoming more and more powerful, and the ability to integrate it with other\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The integration of natural language processing with machine learning has opened up new possibilities in human-computer interaction. For instance, chatbots powered by sophisticated NLP algorithms can now understand and respond to user queries with remarkable accuracy. As these technologies continue to evolve, we can expect that \u001b[0m\u001b[91mthey will be used more frequently in the workplace. The use of AI in the workplace is not without its challenges. One of the biggest concerns is the potential for the technology to be used as a tool for discrimination. This is a legitimate concern, as we have seen it happen in the past. However, we can be confident that the technology will be used in a way that is not discriminatory. The future of AI in the workplace is looking to be a bright one. The technology is becoming more and more powerful, and the ability to integrate it with other technologies is only going to increase. This is a great time to be working in the workplace.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Self-driving cars rely heavily on sensor data and advanced algorithms to navigate \u001b[0m\u001b[91m, avoid, and drive. The technology is still in its infancy, but it is rapidly developing.\n",
      "The technology is rapidly developing.\n",
      "The technology is still in its infordate.\n",
      "The technology is in its f.\n",
      "The technology is in its f.e.\n",
      "The technology is in its f.e.t.\n",
      "The technology is in its f.e.t.a.\n",
      "The technology is in its f.e.t.a.i.\n",
      "The technology is in its f.e.t.a.i.n.\n",
      "The technology is in its f.e.t.a.i.n.a.\n",
      "The technology is in its f.e.t.a.i.n.a.n.\n",
      "The technology is in its f.e.t.a.i.n.a.n.a.\n",
      "The technology is in its f.e.t.a.i.n.a.n.a.n.\n",
      "The technology is in its f.e.t.a.i.n.a.n.a.n.a.\n",
      "The technology is in its f.e.t.a.i.n.a.n.a.n.a.n.\n",
      "The technology is in its f.e.t.a.i.n.a.n.a.n.a.n.a.\n",
      "The technology is in its f.e.t.a.i.n.a.n.a.n.a.n.a.n.\n",
      "The technology is in its f.e.t.a.i.n.a.n.a.n.a.n.a.n.a.\n",
      "The technology is in its f.e.t.a.i.n.a.n.a.n.a.n.a.n.a.n.a.\n",
      "The technology is in its f.e.t.a.i.n.a.n.a.n.a.n.a.n.a.n.a.n.a.n.a.n.a.n.a.n.a.n.a.n.a.n.a.n.a.n.a.n.a.n.a.n.a.n.a.n.a.n.a\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Self-driving cars rely heavily on sensor data and advanced algorithms to navigate \u001b[0m\u001b[91m, avoid, and drive. The technology is still in its infancy, but it is rapidly developing. The technology is rapidly developing. The technology is still in its infordate. The technology is in its f. e. t. a. i.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m One of the biggest challenges in developing AI systems is ensuring they are ethical and unbiased. Researchers are working on creating frameworks that can \u001b[0m\u001b[91m help to ensure that AI systems are not designed to perpetuate the biases of their human creators.\n",
      "The future of AI is likely to be more powerful and more intelligent than anything we have seen in the past. AI is likely to become more powerful and more intelligent as time goes on.\n",
      "The future of AI is likely to be more powerful and more intelligent than anything we have seen in the past. AI is likely to become more powerful and more intelligent as time goes on. The future of AI is likely to be more powerful and more intelligent than anything we have seen in the past.\n",
      "The future of AI is likely to be more powerful and more intelligent than anything we have seen in the past. AI is likely to become more powerful and more intelligent as time goes on. The future of AI is likely to be more powerful and more intelligent than anything we have seen in the past. The future of AI is likely to be more powerful and more intelligent than anything we have seen in the past. The future of AI is likely to be more powerful and more intelligent than anything we have seen in the past. The future of AI is likely to be more powerful and more intelligent than anything we have seen in the past. The future of AI is likely to be more powerful and more intelligent than anything we have seen in the past. The future of AI is likely to be more powerful and more intelligent than anything we have seen in the past. The future of AI is likely to be more powerful and more intelligent than anything we have seen in the past. The future of AI is likely to be more powerful and more intelligent than anything we have seen in the past. The future of AI is likely to be more powerful and more intelligent than anything we have seen in the past. The future of AI is likely to be more powerful and more intelligent than anything we have seen in the past. The future of AI is likely to be more powerful and more intelligent than anything we have seen in the past. The future of AI is likely to be more powerful and more intelligent than anything we have seen in the past. The future of AI is likely to be more powerful and more intelligent than anything we have seen in the past. The future of AI is likely to be more powerful and more intelligent than anything we have seen in the past. The future of A\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m One of the biggest challenges in developing AI systems is ensuring they are ethical and unbiased. Researchers are working on creating frameworks that can \u001b[0m\u001b[91mhelp to ensure that AI systems are not designed to perpetuate the biases of their human creators. The future of AI is likely to be more powerful and more intelligent than anything we have seen in the past. AI is likely to become more powerful and more intelligent as time goes on.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m In the field of computer vision, convolutional neural networks have revolutionized the way machines perceive visual information. By mimicking the human visual system, these networks can classify images, detect objects, and even perform image segmentation. This has significant applications in areas such as medical imaging, where AI can assist doctors in diagnosing conditions from X-rays and MRIs. As the technology advances, we may soon see AI systems that \u001b[0m\u001b[91m can detect cancer, heart disease, and other conditions.\n",
      "In the field of robotics, AI is also being used to create autonomous robots that can perform tasks such as cleaning, construction, and even military operations. These robots can be programmed to perform complex tasks, such as building a bridge, or to simply clean a room. These robots can also be used to protect soldiers in combat zones, or to help them navigate through a war zone.\n",
      "In the field of robotics, AI is also being used to create autonomous robots that can perform tasks such as cleaning, construction, and military operations. These robots can be programmed to perform complex tasks, such as building a bridge, or to simply clean a room. These robots can also be used to protect soldiers in combat zones, or to help them navigate through a war zone.\n",
      "In the field of robotics, AI is also being used to create autonomous robots that can perform tasks such as cleaning, construction, and military operations. These robots can be programmed to perform complex tasks, such as building a bridge, or to simply clean a room. These robots can also be used to protect soldiers in combat zones, or to help them navigate through a war zone. In the field of robotics, AI is also being used to create autonomous robots that can perform tasks such as cleaning, construction, and military operations. These robots can be programmed to perform complex tasks, such as building a bridge, or to simply clean a room. These robots can also be used to protect soldiers in combat zones, or to help them navigate through a war zone.\n",
      "In the field of robotics, AI is also being used to create autonomous robots that can perform tasks such as cleaning, construction, and military operations. These robots can be programmed to perform complex tasks, such as building a bridge, or to simply clean a room. These robots can also be used to protect soldiers in combat zones, or to help them navigate through a war zone. In the field of robotics, AI is also being used to create autonomous robots that can perform tasks such as cleaning, construction, and military operations. These robots can be programmed to perform complex tasks, such as building a bridge, or to simply clean a room. These robots can also be used to protect soldiers in a war zone, or to help them to navigate through\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m In the field of computer vision, convolutional neural networks have revolutionized the way machines perceive visual information. By mimicking the human visual system, these networks can classify images, detect objects, and even perform image segmentation. This has significant applications in areas such as medical imaging, where AI can assist doctors in diagnosing conditions from X-rays and MRIs. As the technology advances, we may soon see AI systems that \u001b[0m\u001b[91mcan detect cancer, heart disease, and other conditions. In the field of robotics, AI is also being used to create autonomous robots that can perform tasks such as cleaning, construction, and even military operations. These robots can be programmed to perform complex tasks, such as building a bridge, or to simply clean a room. These robots can also be used to protect soldiers in combat zones, or to help them navigate through a war zone. In the field of robotics, AI is also being used to create autonomous robots that can perform tasks such as cleaning, construction, and military operations.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Reinforcement learning algorithms learn optimal behaviors through \u001b[0m\u001b[91m the process of reinforcement.\n",
      "The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict.\n",
      "The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict. The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict. The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict. The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict. The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict. The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict. The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict. The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict. The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict. The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict. The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict. The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict. The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict. The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict. The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict. The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict. The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict. The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict. The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict. The goal of\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Reinforcement learning algorithms learn optimal behaviors through \u001b[0m\u001b[91mthe process of reinforcement. The goal of a neural network is to create a mathematical system that can be used to predict, predict, and even predict.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could \u001b[0m\u001b[91m potentially be used to break the cryptographic codes that protect the digital world from malicious attacks.\n",
      "The problem is that the technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat of a quantum cryptography-powered attack is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one. The technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one. The technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a quantum cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could \u001b[0m\u001b[91mpotentially be used to break the cryptographic codes that protect the digital world from malicious attacks. The problem is that the technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat of a quantum cryptography-powered attack is a real one. The threat of a quantum cryptography-powered attack is a real one. The technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. The threat of a cryptography-powered attack is a real one.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that \u001b[0m\u001b[91m can transform our lives in countless ways.\n",
      "The future of AI and machine learning is bright. As we’ve seen, the technology is rapidly advancing, and the potential for its applications is enormous. From self-driving cars to medical diagnosis to cybersecurity, the possibilities are endless.\n",
      "However, it’s important to keep in mind that the future of AI and machine learning will be shaped by the ethical and legal issues that arise as the technology continues to evol. These issues include the ethical questions of privacy, bias, and the role of human control.\n",
      "The ethical questions of privacy, bias, and the role of human control are all important to consider as the technology continues to evolve. These issues will be important to keep in mind as the technology continues to evolve.\n",
      "The future of AI and machine learning is bright, but it’s important to keep in mind that the technology will be shaped by the ethical and legal issues that arise as the technology continues to evolve. These issues include the ethical questions of privacy, bias, and the role of human control.\n",
      "The future of AI and machine learning is bright, but it’s important to keep in mind that the technology will be shaped by the ethical and legal issues that arise as the technology continues to evolve. These include the ethical questions of privacy, bias, and the role of human control.\n",
      "The future of AI and machine learning is bright, but it’s important to keep in mind that the technology will be shaped by the ethical and legal issues that arise as the technology continues to evolve. These include the ethical questions of privacy, bias, and the role of human control. The future of AI and machine learning is bright, but it’s important to keep in mind that the technology will be shaped by the ethical and legal issues that arise as the technology continues to evolve.\n",
      "The future of AI and machine learning is bright, but it’s important to keep in mind that the technology will be shaped by the ethical and legal issues that arise as the technology continues to evolve. These include the ethical questions of privacy, bias, and the role of human control. The future of AI and machine learning is bright, but it’s important to keep in mind that the technology will be shaped by the ethical and legal issues that arise as the\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that \u001b[0m\u001b[91mcan transform our lives in countless ways. The future of AI and machine learning is bright. As we’ve seen, the technology is rapidly advancing, and the potential for its applications is enormous. From self-driving cars to medical diagnosis to cybersecurity, the possibilities are endless. However, it’s important to keep in mind that the future of AI and machine learning will be shaped by the ethical and legal issues that arise as the technology continues to evol. These issues include the ethical questions of privacy, bias, and the role of human control. The ethical questions of privacy, bias, and the role of human control are all important to consider as the technology continues to evolve. These issues will be important to keep in mind as the technology continues to evolve. The future of AI and machine learning is bright, but it’s important to keep in mind that the technology will be shaped by the ethical and legal issues that arise as the technology continues to evolve. These include the ethical questions of privacy, bias, and the role of human control.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Transfer learning allows models trained on large datasets to be fine-tuned for specific tasks by \u001b[0m\u001b[91m adding a few thousand to a few hundred thousand times of the way data.\n",
      "\n",
      "\\begin{itemize}\n",
      "\\item \\textbf{Transfer learning} is a method of learning that allows the use of a model that has been developed to address a problem in a different domain, field, or time in a different field, time, or region of the world.\n",
      "\\end{itemize}\n",
      "\n",
      "\\begin{itemize}\n",
      "\\item \\textbf{Machine learning} is a field of study that focuses on the development of software that allows computers to learn, or learn to do, a variety of tasks.\n",
      "\\end{itemize}\n",
      "\n",
      "\\begin{itemize}\n",
      "\\item \\textbf{Artificial intelligence} is a field of study that focuses on the development of software that allows computers to learn, or learn to do, a variety of tasks.\n",
      "\\end{itemize}\n",
      "\n",
      "\\begin{itemize}\n",
      "\\item \\textbf{Computer science} is a field of study that focuses on the development of software that allows computers to learn, or learn to do, a variety of tasks.\n",
      "\\end{itemize}\n",
      "\n",
      "\\begin{itemize}\n",
      "\\item \\textbf{Data science} is a field of study that focuses on the use of data to solve problems.\n",
      "\\end{itemize}\n",
      "\n",
      "\\begin{itemize}\n",
      "\\item \\textbf{Data analysis} is a field of study that focuses on the use of data to solve problems.\n",
      "\\end{itemize}\n",
      "\n",
      "\\begin{itemize}\n",
      "\\item \\textbf{Data mining} is a field of study that focuses on the use of data to solve problems.\n",
      "\\end{itemize}\n",
      "\n",
      "\\begin{itemize}\n",
      "\\item \\textbf{Data mining} is a field of study that focuses on the use of data to solve problems.\n",
      "\\end{itemize}\n",
      "\n",
      "\\begin{itemize}\n",
      "\\item \\textbf{Data mining} is a field of study that focuses on the use of data to solve problems.\n",
      "\\end{itemize}\n",
      "\n",
      "\\begin{itemize}\n",
      "\\item \\textbf{Data mining} is a field of study that focuses on the use of data to solve problems.\n",
      "\\end{itemize}\n",
      "\n",
      "\\begin{itemize}\n",
      "\\item \\textbf{Data mining} is a field of study that focuses on the use of data to solve problems.\n",
      "\\end{\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Transfer learning allows models trained on large datasets to be fine-tuned for specific tasks by \u001b[0m\u001b[91madding a few thousand to a few hundred thousand times of the way data. \\begin{itemize}\n",
      "\\item \\textbf{Transfer learning} is a method of learning that allows the use of a model that has been developed to address a problem in a different domain, field, or time in a different field, time, or region of the world. \\end{itemize}\n",
      "\n",
      "\\begin{itemize}\n",
      "\\item \\textbf{Machine learning} is a field of study that focuses on the development of software that allows computers to learn, or learn to do, a variety of tasks. \\end{itemize}\n",
      "\n",
      "\\begin{itemize}\n",
      "\\item \\textbf{Artificial intelligence} is a field of study that focuses on the development of software that allows computers to learn, or learn to do, a variety of tasks. \\end{itemize}\n",
      "\n",
      "\\begin{itemize}\n",
      "\\item \\textbf{Computer science} is a field of study that focuses on the development of software that allows computers to learn, or learn to do, a variety of tasks. \\end{itemize}\n",
      "\n",
      "\\begin{itemize}\n",
      "\\item \\textbf{Data science} is a field of study that focuses on the use of data to solve problems. \\end{itemize}\n",
      "\n",
      "\\begin{itemize}\n",
      "\\item \\textbf{Data analysis} is a field of study that focuses on the use of data to solve problems. \\end{itemize}\n",
      "\n",
      "\\begin{itemize}\n",
      "\\item \\textbf{Data mining} is a field of study that focuses on the use of data to solve problems.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Explainable AI (XAI) is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to \u001b[0m\u001b[91m help users understand and trust the decisions of their AI-powered systems.\n",
      "In this article, we’ll explore the importance of XAI, the challenges of creating it, and the benefits of doing so.\n",
      "The Importance of XAI\n",
      "The growing use of AI in fields such as healthcare, finance, and law enforcement has led to a growing need for XAI.\n",
      "The benefits of XAI are numerous. It can help to improve the accuracy of the predictions made by the AI system, improve the efficiency of the system, and increase the likes of the system.\n",
      "The benefits of XAI are also significant. It can help to improve the accuracy of the predictions made by the AI system, improve the efficiency of the system, and increase the likes of the system.\n",
      "The challenges of creating XAI\n",
      "The challenges of creating XAI is a topic that has been discussed in the field of computer science and engineering for some time. The main problem is that the algorithms used to create XAI are not always reliable.\n",
      "The main problem is that the algorithms used to create XAI are not always reliable.\n",
      "The main problem is that the algorithms used to create XAI are not always reliable. The other problem is that the algorithms used to create XAI are not always accurate.\n",
      "The other problem is that the algorithms used to create XAI are not always accurate.\n",
      "The other problem is that the algorithms used to create XAI are not always accurate. The other problem is that the algorithms used to create XAI are not always reliable.\n",
      "The other problem is that the algorithms used to create XAI are not always reliable. The other problem is that the algorithms used to create XAI are not always accurate. The other problem is that the algorithms used to create XAI are not always reliable.\n",
      "The other problem is that the algorithms used to create XAI are not always reliable. The other problem is that the algorithms used to create XAI are not always accurate. The other problem is that the algorithms used to create XAI are not always reliable. The other problem is that the algorithms used to create XAI are not always.\n",
      "The other problem is that the algorithms used to create XAI are not always.\n",
      "The other problem is that the algorithms used to create XAI are not always. The other problem is that the algorithms used to create XAI are not always. The other problem is that the algorithms used to create XAI are not always\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Explainable AI (XAI) is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to \u001b[0m\u001b[91mhelp users understand and trust the decisions of their AI-powered systems. In this article, we’ll explore the importance of XAI, the challenges of creating it, and the benefits of doing so. The Importance of XAI\n",
      "The growing use of AI in fields such as healthcare, finance, and law enforcement has led to a growing need for XAI. The benefits of XAI are numerous. It can help to improve the accuracy of the predictions made by the AI system, improve the efficiency of the system, and increase the likes of the system. The benefits of XAI are also significant. The challenges of creating XAI\n",
      "The challenges of creating XAI is a topic that has been discussed in the field of computer science and engineering for some time. The main problem is that the algorithms used to create XAI are not always reliable. The other problem is that the algorithms used to create XAI are not always accurate. The other problem is that the algorithms used to create XAI are not always reliable.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and \u001b[0m\u001b[91m the ocean is a mix of blue and green.\n",
      "The beach is a great place to relax and enjoy the sun. The sand is soft and the water is warm. The beach is a great place to relax and enjoy the sun. The sand is soft and the water is warm.\n",
      "The beach is a great place to play. The sand is a great place to play. The water is a great place to play. The beach is a great place to play.\n",
      "The beach is a great place to eat. The sand is a great place to eat. The water is a great place to eat. The beach is a great place to eat.\n",
      "The beach is a great place to work out. The sand is a great place to work out. The water is a great place to work out. The beach is a great place to work out.\n",
      "The beach is a great place to shop. The sand is a great place to shop. The water is a great place to shop. The beach is a great place to shop.\n",
      "The beach is a great place to worship. The sand is a great place to worship. The water is a great place to worship. The beach is a great place to worship.\n",
      "The beach is a great place to worship. The sand is a great place to worship. The water is a great place to worship. The beach is a great place to worship.\n",
      "The beach is a great place to worship. The sand is a great place to worship. The water is a great place to worship. The beach is a great place to worship.\n",
      "The beach is a great place to worship. The sand is a great place to worship. The water is a great place to worship. The beach is a great place to worship.\n",
      "The beach is a great place to worship. The sand is a great place to worship. The water is a great place to worship. The beach is a great place to worship.\n",
      "The beach is a great place to worship. The sand is a great place to worship. The water is a great place to worship. The beach is a great place to worship.\n",
      "The beach is a great place to worship. The sand is a great place to worship. The water is a great place to worship. The beach is a great place to worship.\n",
      "The beach is a great place to worship. The sand is a great place to worship. The water is a great place to worship. The beach is a great place to worship.\n",
      "The beach is a great place\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and \u001b[0m\u001b[91mthe ocean is a mix of blue and green. The beach is a great place to relax and enjoy the sun. The sand is soft and the water is warm. The beach is a great place to play. The sand is a great place to play. The water is a great place to play. The beach is a great place to eat. The sand is a great place to eat. The water is a great place to eat. The beach is a great place to work out. The sand is a great place to work out. The water is a great place to work out. The beach is a great place to shop. The sand is a great place to shop. The water is a great place to shop. The beach is a great place to worship. The sand is a great place to worship. The water is a great place to worship.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of \u001b[0m\u001b[91m the world’s history and heritage.\n",
      "Traveling to other countries allows you to learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world's countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of \u001b[0m\u001b[91mthe world’s history and heritage. Traveling to other countries allows you to learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world’s countries. You can learn about the history of the world and the history of the world's countries.\u001b[0m\n",
      "\n",
      "\n",
      "Pruning model\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.514489856\n",
      "Model size after pruning:  13.514489856\n",
      "Model size after pruning:  13.514366976\n",
      "Model size after pruning:  13.514366976\n",
      "Model size after pruning:  13.514366976\n",
      "Model size after pruning:  13.514366976\n",
      "Model size after pruning:  13.5143424\n",
      "Model size after pruning:  13.5143424\n",
      "Model size after pruning:  13.514317824\n",
      "Model size after pruning:  13.514317824\n",
      "Model size after pruning:  13.51397376\n",
      "Model size after pruning:  13.51397376\n",
      "Model size after pruning:  13.513777152\n",
      "Model size after pruning:  13.513777152\n",
      "Model size after pruning:  13.453074432\n",
      "Model size after pruning:  13.411131392\n",
      "Model size after pruning:  13.32998144\n",
      "Model size after pruning:  13.2880384\n",
      "Model size after pruning:  13.206888448\n",
      "Model size after pruning:  13.164945408\n",
      "Model size after pruning:  13.083795456\n",
      "Model size after pruning:  13.041852416\n",
      "Model size after pruning:  12.9622016\n",
      "Model size after pruning:  12.92025856\n",
      "Model size after pruning:  12.841025536\n",
      "Model size after pruning:  12.799082496\n",
      "Model size after pruning:  12.71967744\n",
      "Model size after pruning:  12.6777344\n",
      "Model size after pruning:  12.598403072\n",
      "Model size after pruning:  12.556460032\n",
      "Model size after pruning:  12.477079552\n",
      "Model size after pruning:  12.435136512\n",
      "Model size after pruning:  12.355805184\n",
      "Model size after pruning:  12.313862144\n",
      "Model size after pruning:  12.234481664\n",
      "Model size after pruning:  12.192538624\n",
      "Model size after pruning:  12.113207296\n",
      "Model size after pruning:  12.071264256\n",
      "Model size after pruning:  11.991883776\n",
      "Model size after pruning:  11.949940736\n",
      "Model size after pruning:  11.870609408\n",
      "Model size after pruning:  11.828666368\n",
      "Model size after pruning:  11.749285888\n",
      "Model size after pruning:  11.707342848\n",
      "Model size after pruning:  11.62801152\n",
      "Saving model after pruning to checkpoint dir\n",
      "Model saved\n",
      "Real Pruned Model\n",
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-4): 5 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (5): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11004, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11004, bias=False)\n",
      "          (down_proj): Linear(in_features=11004, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (6): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11003, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11003, bias=False)\n",
      "          (down_proj): Linear(in_features=11003, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (7): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (8-9): 2 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11007, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11007, bias=False)\n",
      "          (down_proj): Linear(in_features=11007, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (10): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10994, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10994, bias=False)\n",
      "          (down_proj): Linear(in_features=10994, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (11): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11000, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11000, bias=False)\n",
      "          (down_proj): Linear(in_features=11000, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (12): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=8538, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=8538, bias=False)\n",
      "          (down_proj): Linear(in_features=8538, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (13-15): 3 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7706, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7706, bias=False)\n",
      "          (down_proj): Linear(in_features=7706, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (16): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7767, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7767, bias=False)\n",
      "          (down_proj): Linear(in_features=7767, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (17): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7784, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7784, bias=False)\n",
      "          (down_proj): Linear(in_features=7784, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (18): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7777, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7777, bias=False)\n",
      "          (down_proj): Linear(in_features=7777, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (19): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
      "          (down_proj): Linear(in_features=7780, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (20): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7778, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7778, bias=False)\n",
      "          (down_proj): Linear(in_features=7778, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (21): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
      "          (down_proj): Linear(in_features=7780, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (22): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7778, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7778, bias=False)\n",
      "          (down_proj): Linear(in_features=7778, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (23): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
      "          (down_proj): Linear(in_features=7780, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (24): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7778, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7778, bias=False)\n",
      "          (down_proj): Linear(in_features=7778, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (25): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
      "          (down_proj): Linear(in_features=7780, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (26): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7778, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7778, bias=False)\n",
      "          (down_proj): Linear(in_features=7778, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (27): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
      "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
      "          (down_proj): Linear(in_features=7780, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (28-31): 4 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n",
      "Real Pruned Model Size\n",
      "11.62801152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short Context: 17.223949437471063 tokens/sec, 516 tokens (including full prompt)\n",
      "Long Context: 42.66546031921937 tokens/sec, 1288 tokens (including full prompt)\n",
      "Average:  20.096777656850374 tokens/sec\n",
      "***************   Experiment completed successfully Successfully   ***************\n"
     ]
    }
   ],
   "source": [
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ee6dea2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:45:13.584053Z",
     "start_time": "2024-05-25T04:45:13.576788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5795127296"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96222c26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "680de672",
   "metadata": {},
   "source": [
    "## Experiment 2496 --> PreserveRatio=0.7, lbound=0.5, rbound=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "163d7378",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:47:26.232489Z",
     "start_time": "2024-05-25T04:47:26.228615Z"
    }
   },
   "outputs": [],
   "source": [
    "pruning_dict = \"pruning_dict_1.0_0.5_1.0_chat_2496.json\"\n",
    "save_dir = \"/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/\"\n",
    "\n",
    "p = pruning_dict.split(\"_\")[-1].split(\".\")[-2]\n",
    "output_dir = \"/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints//\" + p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f197c910",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:47:26.759264Z",
     "start_time": "2024-05-25T04:47:26.755677Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment = ExperimentRunner(pipeline, tokenizer, pruning_dict, \n",
    "                 save_dir=save_dir, output_dir=output_dir, ignored_layers=None, \n",
    "                 use_template=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79a9f657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T05:12:15.600048Z",
     "start_time": "2024-05-25T04:47:27.075592Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************   Running Experiment   ***************\n",
      "61 ==>  3968\n",
      "67 ==>  11000\n",
      "75 ==>  4096\n",
      "81 ==>  10223\n",
      "89 ==>  4096\n",
      "95 ==>  10973\n",
      "103 ==>  3840\n",
      "109 ==>  10988\n",
      "117 ==>  4096\n",
      "123 ==>  10923\n",
      "131 ==>  4096\n",
      "137 ==>  11002\n",
      "145 ==>  3840\n",
      "151 ==>  10506\n",
      "159 ==>  3968\n",
      "165 ==>  10584\n",
      "173 ==>  3968\n",
      "179 ==>  10594\n",
      "187 ==>  4096\n",
      "193 ==>  10945\n",
      "201 ==>  3840\n",
      "207 ==>  6370\n",
      "215 ==>  2048\n",
      "221 ==>  5504\n",
      "229 ==>  2048\n",
      "235 ==>  5504\n",
      "243 ==>  2048\n",
      "249 ==>  5504\n",
      "257 ==>  2048\n",
      "263 ==>  5504\n",
      "271 ==>  2048\n",
      "277 ==>  5504\n",
      "285 ==>  2048\n",
      "291 ==>  5504\n",
      "299 ==>  2048\n",
      "305 ==>  5504\n",
      "313 ==>  2048\n",
      "319 ==>  5504\n",
      "327 ==>  2048\n",
      "333 ==>  5504\n",
      "341 ==>  2048\n",
      "347 ==>  5504\n",
      "355 ==>  2048\n",
      "361 ==>  5504\n",
      "369 ==>  2048\n",
      "375 ==>  5504\n",
      "383 ==>  2048\n",
      "389 ==>  5504\n",
      "***************   Pruning Model   ***************\n",
      "Pruning model\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Saving model after pruning to checkpoint dir\n",
      "Model saved\n",
      "***************   Model Pruned Successfully   ***************\n",
      "Model Size after Pruning:  13.51458816\n",
      "evaluating on wikitext2\n",
      "nsamples 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:   0%|                                                                                                                                                                                                                                                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:   4%|████████████▎                                                                                                                                                                                                                                                                                                      | 1/25 [00:00<00:14,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:   8%|████████████████████████▌                                                                                                                                                                                                                                                                                          | 2/25 [00:01<00:13,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  12%|████████████████████████████████████▊                                                                                                                                                                                                                                                                              | 3/25 [00:01<00:13,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  16%|█████████████████████████████████████████████████                                                                                                                                                                                                                                                                  | 4/25 [00:02<00:12,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  20%|█████████████████████████████████████████████████████████████▍                                                                                                                                                                                                                                                     | 5/25 [00:02<00:11,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  24%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                                                                         | 6/25 [00:03<00:11,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  28%|█████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                                                                                             | 7/25 [00:04<00:10,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  32%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                                                                                | 8/25 [00:04<00:10,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  36%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                                    | 9/25 [00:05<00:09,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  40%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                                                       | 10/25 [00:05<00:08,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  44%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                           | 11/25 [00:06<00:08,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  48%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                               | 12/25 [00:07<00:07,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  52%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                                   | 13/25 [00:07<00:07,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                      | 14/25 [00:08<00:06,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                          | 15/25 [00:08<00:05,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                              | 16/25 [00:09<00:05,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                  | 17/25 [00:09<00:04,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                     | 18/25 [00:10<00:04,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                         | 19/25 [00:11<00:03,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                             | 20/25 [00:11<00:02,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                 | 21/25 [00:12<00:02,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 22/25 [00:12<00:01,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 23/25 [00:13<00:01,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 24/25 [00:13<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WikiText Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:14<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPL:  19.430864334106445\n",
      "Perplexity on wikitext2:  19.430864334106445\n",
      "Loading checkpoint from /data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model passed to evaluation:  LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-25:10:19:21,785 WARNING  [task.py:763] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-05-25:10:19:21,787 WARNING  [task.py:775] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2024-05-25:10:19:27,175 WARNING  [task.py:763] [Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-05-25:10:19:27,176 WARNING  [task.py:775] [Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for winogrande contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/winogrande\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2024-05-25:10:20:11,680 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-05-25:10:20:11,682 INFO     [evaluator.py:177] Initializing huggingface model, with arguments: {'pretrained': '/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/'}\n",
      "2024-05-25:10:20:11,695 WARNING  [logging.py:61] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "2024-05-25:10:20:11,696 INFO     [huggingface.py:163] Using device 'cuda'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f4a5483fb14c37a07bab1c4b3e63e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-25:10:20:27,184 WARNING  [task.py:763] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-05-25:10:20:27,187 WARNING  [task.py:775] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-05-25:10:21:08,363 WARNING  [task.py:763] [Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-05-25:10:21:08,364 WARNING  [task.py:775] [Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-05-25:10:21:14,846 WARNING  [evaluator.py:239] Overwriting default num_fewshot of rte from None to 0\n",
      "2024-05-25:10:21:14,847 WARNING  [evaluator.py:239] Overwriting default num_fewshot of arc_challenge from None to 0\n",
      "2024-05-25:10:21:14,847 WARNING  [evaluator.py:239] Overwriting default num_fewshot of winogrande from None to 0\n",
      "2024-05-25:10:21:14,848 WARNING  [evaluator.py:239] Overwriting default num_fewshot of arc_easy from None to 0\n",
      "2024-05-25:10:21:14,848 WARNING  [evaluator.py:239] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2024-05-25:10:21:14,849 WARNING  [evaluator.py:239] Overwriting default num_fewshot of openbookqa from None to 0\n",
      "2024-05-25:10:21:14,849 WARNING  [evaluator.py:239] Overwriting default num_fewshot of boolq from None to 0\n",
      "2024-05-25:10:21:14,854 INFO     [task.py:395] Building contexts for rte on rank 0...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1442.56it/s]\n",
      "2024-05-25:10:21:14,932 INFO     [task.py:395] Building contexts for arc_challenge on rank 0...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 836.87it/s]\n",
      "2024-05-25:10:21:15,064 INFO     [task.py:395] Building contexts for winogrande on rank 0...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 57088.66it/s]\n",
      "2024-05-25:10:21:15,074 INFO     [task.py:395] Building contexts for arc_easy on rank 0...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 834.70it/s]\n",
      "2024-05-25:10:21:15,207 INFO     [task.py:395] Building contexts for hellaswag on rank 0...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1873.94it/s]\n",
      "2024-05-25:10:21:15,286 INFO     [task.py:395] Building contexts for openbookqa on rank 0...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1574.34it/s]\n",
      "2024-05-25:10:21:15,362 INFO     [task.py:395] Building contexts for boolq on rank 0...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1412.39it/s]\n",
      "2024-05-25:10:21:15,442 INFO     [evaluator.py:379] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2199/2199 [02:05<00:00, 17.47it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "fatal: not a git repository (or any parent up to mount point /)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "|     Alias     | Acc, None |   Acc StdErr, None   | Acc Norm, None | Acc Norm StdErr, None |\n",
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "|      rte      |    0.64   | 0.048241815132442176 |      None      |          None         |\n",
      "| arc_challenge |    0.33   | 0.047258156262526045 |      0.32      |  0.046882617226215034 |\n",
      "|   winogrande  |    0.66   | 0.04760952285695237  |      None      |          None         |\n",
      "|    arc_easy   |    0.53   | 0.050161355804659205 |      0.54      |  0.05009082659620332  |\n",
      "|   hellaswag   |    0.39   | 0.04902071300001974  |      0.56      |  0.04988876515698589  |\n",
      "|   openbookqa  |    0.28   | 0.04512608598542128  |      0.43      |  0.04975698519562428  |\n",
      "|     boolq     |    0.71   | 0.04560480215720685  |      None      |          None         |\n",
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Gardening provides a sense of accomplishment and tranquility, as you nurture plants and watch them \u001b[0m\u001b[91m grow.\n",
      "The benefits of gardening is a term that refers to the benefits of working in a garden. This includes the benefits of working in a garden.\n",
      "The “10 Facts You Didn't Know You Didn't Know You Didn't Know\"\n",
      "The \"10 Things You Didn't Know You Didn't Know You Didn't Know\"\n",
      "The \"10 Things You Didn't Know You Didn't Know You Didn't Know\"\n",
      "The \"10 Things You Didn't Know You Didn't Know You Didn't Know\"\n",
      "The \"10 Things You Didn't Know You Didn't Know You Didn't Know\"\n",
      "The \"10 Things You Didn't Know You Didn't Know You' Didn' \"\n",
      "The \"10 Things You Don' \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You \"\n",
      "The \"10 Things You #\n",
      "The \"10 Things You #\n",
      "The \"10 Things You #\n",
      "The \"10 Things You #\n",
      "The \"10 Things You #\n",
      "The \"10 Things You #\n",
      "The \"10 Things You #\n",
      "The \"10 Things You #\n",
      "The \"10 Things You #\n",
      "The \"10 Things You #\n",
      "The \"10 Things You #\n",
      "The \"10 Things You #\n",
      "The \"10 Things You #\n",
      "The \"10 Things You #\n",
      "The \"10 Things You #\n",
      "The \"10 Things You #\n",
      "The \"10 Things You #\n",
      "The \"10 Things You #\n",
      "The \"10 Things You #\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Gardening provides a sense of accomplishment and tranquility, as you nurture plants and watch them \u001b[0m\u001b[91mgrow. The benefits of gardening is a term that refers to the benefits of working in a garden. This includes the benefits of working in a garden.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Family traditions are passed down from generation to generation, creating a sense of continuity and belonging. Whether it's holiday celebrations, special recipes, or annual gatherings, these traditions foster \u001b[0m\u001b[91m a feeling of connection and unity.\n",
      "The benefits of family traditions are numerous and varied. Some of the most common include:\n",
      "1. Strengthening relationships:\n",
      "2. Preserving culture:\n",
      "3. Strengthening bonds:\n",
      "4. Strengthening bonds: :\n",
      "5. Strengthening bonds:\n",
      "6. Strengthening bonds: :\n",
      "7. Strengthening bonds: :\n",
      "8. Strengthening strength:\n",
      "9. Strength:\n",
      "10. Strength:\n",
      "11. Strength: 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35. 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49. 50. 51. 52. 53. 54. 55. 56. 57. 58. 59. 60. 61. 62. 63. 64. 65. 66. 67. 68. 69. 70. 71. 72. 73. 74. 75. 76. 77. 78. 79. 80. 81. 82. 83. 84. 85. 86. 87. 88. 89. 90. 91. 92. 93. 94. 95. 96. 97. 98. 99. 100. 101. 102. 123. 124. 125. 126. 127. 12\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Family traditions are passed down from generation to generation, creating a sense of continuity and belonging. Whether it's holiday celebrations, special recipes, or annual gatherings, these traditions foster \u001b[0m\u001b[91ma feeling of connection and unity. The benefits of family traditions are numerous and varied. Some of the most common include:\n",
      "1. Strengthening relationships:\n",
      "2. Preserving culture:\n",
      "3. Strengthening bonds:\n",
      "4. Strengthening bonds: :\n",
      "5. Strengthening bonds:\n",
      "6. Strengthening bonds: :\n",
      "7. Strengthening bonds: :\n",
      "8. Strengthening strength:\n",
      "9. Strength:\n",
      "10. Strength:\n",
      "11. Strength: 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35. 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49. 50. 51. 52. 53. 54. 55. 56. 57. 58. 59. 60. 61. 62. 63. 64. 65. 66. 67. 68. 69. 70. 71. 72. 73. 74. 75. 76. 77. 78. 79. 80. 81. 82. 83. 84. 85. 86. 87. 88. 89. 90. 91. 92. 93. 94. 95. 96. 97. 98. 99. 100. 101. 102. 123. 124. 125. 126. 127.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future \u001b[0m\u001b[91m, fashion will be a form of self-expression that is more inclusive and diverse, allowing people to express their individuality through the clothing of their choice.\n",
      "The “fashion” is a term that describes the fashion industry. The industry is a large and diverse business that includes everything from the design of clothing to the marketing of fashionable clothing. The industry is a global industry that is worth billions of dollars in sales each year. The industry is a very competitive industry that is filled with many players for each garment, from the fashion designer to the manufacturer to the retail store.\n",
      "The “fashion” is a term that refers to fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion, fashion,\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future \u001b[0m\u001b[91m, fashion will be a form of self-expression that is more inclusive and diverse, allowing people to express their individuality through the clothing of their choice. The “fashion” is a term that describes the fashion industry. The industry is a large and diverse business that includes everything from the design of clothing to the marketing of fashionable clothing. The industry is a global industry that is worth billions of dollars in sales each year. The industry is a very competitive industry that is filled with many players for each garment, from the fashion designer to the manufacturer to the retail store.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Artificial intelligence is transforming the healthcare industry by enabling \u001b[0m\u001b[91m hospitals to identify and treat patients with a wide range of diseases and disabilities.\n",
      "The healthcare industry is being transformed by the introduction of new technology, in particular, by the introduction of new technology, in particular, by the introduction of new technology, in particular, by the introduction of new technology, in particular, by the introduction of new technology, in the area of ​\n",
      "The “what” word is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word.\n",
      "The word “what” is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. This is a common and popular\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Artificial intelligence is transforming the healthcare industry by enabling \u001b[0m\u001b[91mhospitals to identify and treat patients with a wide range of diseases and disabilities. The healthcare industry is being transformed by the introduction of new technology, in particular, by the introduction of new technology, in particular, by the introduction of new technology, in particular, by the introduction of new technology, in particular, by the introduction of new technology, in the area of ​\n",
      "The “what” word is a common and popular term that refers to the “what” word. This is a common and popular term that refers to the “what” word. The word “what” is a common and popular term that refers to the “what” word.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Machine learning algorithms are increasingly being used to predict stock market trends. By analyzing historical data and identifying patterns, these models can \u001b[0m\u001b[91m help you to identify the best time to buy and sell stocks.\n",
      "3. Investing in a wide range of assets: Investing in a wide range of assets allows you to reduce the impact of the market on your portfolio. By doing so, you can reduce the risk of losing money in the event that a particular asset is sold at a time that is not ideal.\n",
      "4. Investing in a variety of countries: Investing in a variety of countries allows you to reduce the risk of losing money in the event that a particular country’s stock market is in a bad state.\n",
      "5. Investing in a variety of companies: Investing in a variety of companies allows you to reduce the risk of losing money in the event that a single company’.\n",
      "6. Investing in a variety of commodities: Investing in a variety of commodities allows you to reduce the risk of losing money in the event that a single commodity’.\n",
      "7. Investing in a variety of bonds: Investing in a variety of bonds allows you to reduce the risk of losing money in the event that a single bond's market is in a bad state.\n",
      "8. Investing in a variety of bonds: Investing in a variety of bonds allows you to reduce the risk of losing money in the event that a single bond’.\n",
      "9. Investing in a variety of bonds: Investing in a variety of bonds allows you to reduce the risk of losing money in the event that a single bond’.\n",
      "10. Investing in a variety of bonds: Investing in a variety of biders allows you to reduce the risk of losing money in the event that a single bond’.\n",
      "11. Investing in a variety of bonds: Investing in a variety of bonders allows you to reduce the risk of losing money in the event that a single bond’.\n",
      "12. Investing in a variety of bonds: Investing in a variety of bonders allows you to reduce the risk of losing money in the event that a single bond’.\n",
      "13. Investing in a variety of bonds: Investing in a variety of bonders allows you to reduce the risk of losing money in the event that a single bond’.\n",
      "14. Investing in a variety of bonds:\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Machine learning algorithms are increasingly being used to predict stock market trends. By analyzing historical data and identifying patterns, these models can \u001b[0m\u001b[91mhelp you to identify the best time to buy and sell stocks. 3. Investing in a wide range of assets: Investing in a wide range of assets allows you to reduce the impact of the market on your portfolio. By doing so, you can reduce the risk of losing money in the event that a particular asset is sold at a time that is not ideal. 4. Investing in a variety of countries: Investing in a variety of countries allows you to reduce the risk of losing money in the event that a particular country’s stock market is in a bad state. 5. Investing in a variety of companies: Investing in a variety of companies allows you to reduce the risk of losing money in the event that a single company’. 6. Investing in a variety of commodities: Investing in a variety of commodities allows you to reduce the risk of losing money in the event that a single commodity’. 7. Investing in a variety of bonds: Investing in a variety of bonds allows you to reduce the risk of losing money in the event that a single bond's market is in a bad state. 8. Investing in a variety of bonds: Investing in a variety of bonds allows you to reduce the risk of losing money in the event that a single bond’. 9. 10. Investing in a variety of bonds: Investing in a variety of biders allows you to reduce the risk of losing money in the event that a single bond’. 11. Investing in a variety of bonds: Investing in a variety of bonders allows you to reduce the risk of losing money in the event that a single bond’. 12. 13. 14.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The integration of natural language processing with machine learning has opened up new possibilities in human-computer interaction. For instance, chatbots powered by sophisticated NLP algorithms can now understand and respond to user queries with remarkable accuracy. As these technologies continue to evolve, we can expect that \u001b[0m\u001b[91m the future of AI will be even more impressive.\n",
      "The Future of AI is Bright:\n",
      "The Future of AI is Bright: “,’ ’, ‘’, ‘’, ‘'\n",
      "The article “The Future of AI: The 10 things you’,’, ‘, ‘, ‘, ‘, '\n",
      "The article “The Future of AI: The 10 things you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The integration of natural language processing with machine learning has opened up new possibilities in human-computer interaction. For instance, chatbots powered by sophisticated NLP algorithms can now understand and respond to user queries with remarkable accuracy. As these technologies continue to evolve, we can expect that \u001b[0m\u001b[91mthe future of AI will be even more impressive.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Self-driving cars rely heavily on sensor data and advanced algorithms to navigate \u001b[0m\u001b[91m safely and efficiently.\n",
      "The technology is rapidly developing and advancing.\n",
      "The technology is still in the early stages of development.\n",
      "The technology is not fully reliable.\n",
      "The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The technology is not fully reliable. The\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Self-driving cars rely heavily on sensor data and advanced algorithms to navigate \u001b[0m\u001b[91msafely and efficiently. The technology is rapidly developing and advancing. The technology is still in the early stages of development. The technology is not fully reliable.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m One of the biggest challenges in developing AI systems is ensuring they are ethical and unbiased. Researchers are working on creating frameworks that can \u001b[0m\u001b[91m be used to evaluate the ethical implications of a system’s design.\n",
      "The future of AI is looking to be a very exciting time. The technology is rapidly developing and advancing, and the possibilities for the future are endless. The technology is being used in a wide range of applications, from healthcare to entertainment to defense. The technology is also being used in a wide range of industries, from automotive to financial to technology. The technology is also being used in a wide range of applications, from healthcare to entertainment to defense. The technology is also being used in a wide range of industries, from automotive to financial to technology. The technology is also being used in a wide range of applications, from healthcare to entertainment to defense. The technology is also being used in a wide range of industries, from automotive to financial to technology. The technology is also being used in a wide range of industries, from automotive to financial to technology. The technology is also being used in a wide range of industries, from automotive to financial to technology. The technology is also being used in a wide range of industries, from automotive to financial to technology. The technology is also being used in a wide range of industries, from automotive to financial to technology. The technology is also being used in a wide range of industries, from automotive to financial to technology. The technology is also being used in a wide range of industries, from automotive to financial to technology. The technology is also being used in a wide range of industries, from automotive to financial to technology. The technology is also being used in a wide range of industries, from automotive to financial to technology. The technology is also being used in a wide range of industries, from automotive to financial to technology. The technology is also being used in a wide range of industries, from automotive to financial to technology. The technology is also being used in a wide range of industries, from automotive to financial to technology. The technology is also being used in a wide range of industries, from automotive to financial to technology. The technology is also being used in a wide range of industries, from automotive to financial to technology. The technology is also being used in a wide range of industries, from automotive to financial to technology. The technology is also being\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m One of the biggest challenges in developing AI systems is ensuring they are ethical and unbiased. Researchers are working on creating frameworks that can \u001b[0m\u001b[91mbe used to evaluate the ethical implications of a system’s design. The future of AI is looking to be a very exciting time. The technology is rapidly developing and advancing, and the possibilities for the future are endless. The technology is being used in a wide range of applications, from healthcare to entertainment to defense. The technology is also being used in a wide range of industries, from automotive to financial to technology. The technology is also being used in a wide range of applications, from healthcare to entertainment to defense.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m In the field of computer vision, convolutional neural networks have revolutionized the way machines perceive visual information. By mimicking the human visual system, these networks can classify images, detect objects, and even perform image segmentation. This has significant applications in areas such as medical imaging, where AI can assist doctors in diagnosing conditions from X-rays and MRIs. As the technology advances, we may soon see AI systems that \u001b[0m\u001b[91m can detect and diagnose from images of any kind of medical device.\n",
      "The future of AI and the future of medicine are likely to be deeply connected and dependent on each other. As we continue to develop more advanced and more useful AI, we will surely see this technology integrated more deeply and more broadly in the medical field. It is not difficult to imagine that the future will be filled with amazing new technologies, and that many of these technologies will be able to integrate with each other.\n",
      "The future of AI and the future of medicine are both likely to be highly dependent on each other. As we continue to develop more advanced and more useful AI, we will surely see this technology integrated more deeply and more broadly in the medical field. It is not difficult to imagine that the future will be filled with amazing new technologies, and that many of these technologies will be able to integrate with each other.\n",
      "The post The Future of AI and the Future of Medicine appeared first on TrendB Read More All Part of Our Life!!!! F Read More EYE for the eye, tooth for the tooth, hand for the hand, foot for the foot, and a heart for the heart.\n",
      "The article The Future of AI and the Future of Medicine is a good example of the power of the internet. The article is a good example of the power of social media as a publishing platform.\n",
      "The article “The Future of AI” is a good example of the power of the internet. This article is a good example of the power of social media as a publishing platform.\n",
      "Previous Post The Future of AI and the Future of Medicine\n",
      "Next Post The Future of AI and the Future of Medicine\n",
      "The Future of AI and the Future of Medicine\n",
      "The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m In the field of computer vision, convolutional neural networks have revolutionized the way machines perceive visual information. By mimicking the human visual system, these networks can classify images, detect objects, and even perform image segmentation. This has significant applications in areas such as medical imaging, where AI can assist doctors in diagnosing conditions from X-rays and MRIs. As the technology advances, we may soon see AI systems that \u001b[0m\u001b[91mcan detect and diagnose from images of any kind of medical device. The future of AI and the future of medicine are likely to be deeply connected and dependent on each other. As we continue to develop more advanced and more useful AI, we will surely see this technology integrated more deeply and more broadly in the medical field. It is not difficult to imagine that the future will be filled with amazing new technologies, and that many of these technologies will be able to integrate with each other. The future of AI and the future of medicine are both likely to be highly dependent on each other. The post The Future of AI and the Future of Medicine appeared first on TrendB Read More All Part of Our Life!!!! F Read More EYE for the eye, tooth for the tooth, hand for the hand, foot for the foot, and a heart for the heart. The article The Future of AI and the Future of Medicine is a good example of the power of the internet. The article is a good example of the power of social media as a publishing platform. The article “The Future of AI” is a good example of the power of the internet. This article is a good example of the power of social media as a publishing platform.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Reinforcement learning algorithms learn optimal behaviors through \u001b[0m\u001b[91m repeated exposure to a problem.\n",
      "Their goal is to find the optimal policy that will allow the algorithm to achieve the highest level of performance.\n",
      "The goal of a neural network is to learn the optimal parameters of the algorithm.\n",
      "The goal of a neural network is to learn the parameters of the algorithm.\n",
      "The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm. The goal of a neural network is to learn the parameters of the\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Reinforcement learning algorithms learn optimal behaviors through \u001b[0m\u001b[91mrepeated exposure to a problem. Their goal is to find the optimal policy that will allow the algorithm to achieve the highest level of performance. The goal of a neural network is to learn the optimal parameters of the algorithm. The goal of a neural network is to learn the parameters of the algorithm.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could \u001b[0m\u001b[91m potentially create a threat to the security of cryptographic systems that are currently in place.\n",
      "The threat of quantum computing to cryptography is a serious issue that could have a significant impact on the security of the internet. The threat of quantum computing to cryptography is a serious issue that could have a significant impact on the security of the internet. The threat of quantum computing to cryptography is a serious issue that could have a significant impact on the security of the internet. The threat of quantum computing to cryptography is a serious issue that could have a significant impact on the security of the internet. The threat of quantum computing to cryptography is a serious issue that could have a significant impact on the security of the internet. The threat of quantum computing to cryptography is a serious issue that could have a significant impact on the security of the internet. The threat of quantum computing to cryptography is a serious issue that could have a significant impact on the security of the internet. The threat of quantum computing to cryptography is a serious issue that could have a significant impact on the security of the internet. The threat of quantum computing to cryptography is a serious issue that could have a significant impact on the security of the internet. The threat of quantum computing to cryptography is a serious issue that could have a significant impact on the security of the internet. The threat of quantum computing to cryptography is a serious issue that could have a significant impact on the security of the internet. The threat of quantum computing to cryptography is a serious issue that could have a significant impact on the security of the internet. The threat of quantum computing to cryptography is a serious issue that could have a significant impact on the security of the internet. The threat of quantum computing to cryptography is a serious issue that could have a significant impact on the security of the internet. The threat of quantum computing to cryptography is a serious issue that could have a significant impact on the security of the internet. The threat of quantum computing to cryptography is a serious issue that could have a significant impact on the security of the internet. The threat of quantum computing to cryptography is a serious issue that could have a significant impact on the security of the internet. The threat of quantum computing to cryptography is a serious issue that could have a significant impact on the security of the internet. The threat of quantum computing to cryptography is a serious issue that could have a significant impact on the security of the internet. The threat of quantum computing to cryptography is a serious issue that could have a significant impact on\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could \u001b[0m\u001b[91mpotentially create a threat to the security of cryptographic systems that are currently in place. The threat of quantum computing to cryptography is a serious issue that could have a significant impact on the security of the internet.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that \u001b[0m\u001b[91m will be able to learn from larger and multiple data sources.\n",
      "The Future of AI and Machine Learning: AI and machine learning are two of the most powerful and important technologies of our time. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the future of the world. The future of AI and machine learning will be to the\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that \u001b[0m\u001b[91mwill be able to learn from larger and multiple data sources. The Future of AI and Machine Learning: AI and machine learning are two of the most powerful and important technologies of our time. The future of AI and machine learning will be to the future of the world.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Transfer learning allows models trained on large datasets to be fine-tuned for specific tasks by \u001b[0m\u001b[91m a much smaller set of people.\n",
      "\n",
      "\n",
      "### 2. \n",
      "\n",
      "> \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".Љ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\\\\\n",
      "Љ\n",
      ".Љ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\\\\\n",
      "\t\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Transfer learning allows models trained on large datasets to be fine-tuned for specific tasks by \u001b[0m\u001b[91ma much smaller set of people. ### 2. >. Љ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\\\\\n",
      "Љ.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Explainable AI (XAI) is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to \u001b[0m\u001b[91m help users understand and control the power of AI.\n",
      "The goal of this project is to develop a framework for implementing the concept of transparency in the context of the AI field. The objective is to develop a set of tools that will enable the implementation of the concept of transparency in the context of the AI field.\n",
      "The objective of the project is to develop a set of tools that will enable the implementation of the concept of transparency in the context of the AI field.\n",
      "The objective of the project is to develop a set of tools that will enable the implementation of the concept of transparency in the context of the AI field. The objective of the project is to develop a set of tools that will enable the implementation of the concept of transparency in the context of the AI field.\n",
      "The objective of the project is to develop a set of tools that will enable the implementation of the concept of transparency in the context of the AI field. The objective of the project is to develop a set of tools that will enable the implementation of the concept of trans-\n",
      "The project is to develop a set of tools that will enable the implementation of the concept of transparency in the context of the AI field. The objective of the project is to develop a set of tools that will enable the implementation of the concept of transparency in the context of the AI field. The objective of the project is to develop a set of tools that will enable the implementation of the concept of transparency in the context of the AI field. The objective of the project is to develop a set of tools that will enable the implementation of the concept of transparency in the context of the AI field. The objective of the project is to develop a set of tools that will enable the implementation of the concept of transparency in the context of the AI field. The objective of the project is to develop a set of tools that will enable the implementation of the concept of transparency in the context of the AI field. The objective of the project is to develop a set of tools that will enable the implementation of the concept of transparency in the context of the AI field. The objective of the project is to develop a set of tools that will enable the implementation of the concept of transparency in the context of the AI field. The objective of the project is to develop a set of tools that will enable the implementation of the concept of transpar\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Explainable AI (XAI) is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to \u001b[0m\u001b[91mhelp users understand and control the power of AI. The goal of this project is to develop a framework for implementing the concept of transparency in the context of the AI field. The objective is to develop a set of tools that will enable the implementation of the concept of transparency in the context of the AI field. The objective of the project is to develop a set of tools that will enable the implementation of the concept of transparency in the context of the AI field. The objective of the project is to develop a set of tools that will enable the implementation of the concept of trans-\n",
      "The project is to develop a set of tools that will enable the implementation of the concept of transparency in the context of the AI field.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and \u001b[0m\u001b[91m the water takes on a variety of shades of blue.\n",
      "The sun is a powerful source of energy that drives the earth’s rotation. The sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky, and the sun is the largest object in the sky,\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and \u001b[0m\u001b[91mthe water takes on a variety of shades of blue. The sun is a powerful source of energy that drives the earth’s rotation.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of \u001b[0m\u001b[91m the world.\n",
      "4. Traveling to new countries allows you to learn a foreign language. Learning a new language can be a great way to improve your skills and skills.\n",
      "5. Traveling to new countries allows you to see the world from a different perspective. Traveling to new countries allows you to see the world from a different perspective.\n",
      "6. Traveling to new countries allows you to experience the world from a different perspective.\n",
      "7. Traveling to new countries allows you to experience the world from a different perspective. This is a great way to improve your skills and skills.\n",
      "8. Traveling to new countries allows you to experience the world from a different perspective. This is a great way to improve your skills and skills.\n",
      "9. Traveling to new countries allows you to experience the world from a different perspective. This is a great way to improve your skills and skills.\n",
      "10. Traveling to new countries allows you to experience the world from a different perspective.\n",
      "11. Traveling to new countries allows you to experience the world from a different perspective. This is a great way to improve your skills and skills.\n",
      "12. Traveling to new countries allows you to experience the world from a different perspective. This is a great way to improve your skills and skills.\n",
      "13. Traveling to new countries allows you to experience the world from a different perspective. This is a great way to improve your skills and skills.\n",
      "14. Traveling to new countries allows you to experience the world from a different perspective. This is a great way to improve your skills and skills.\n",
      "15. Traveling to new countries allows you to experience the world from a different perspective. This is a great way to improve your skills and skills.\n",
      "16. Traveling to new countries allows you to experience the world from a different perspective. This is a great way to improve your skills and skills.\n",
      "17. Traveling to new countries allows you to experience the world from a different perspective. This is a great way to improve your skills and skills.\n",
      "18. Traveling to new countries allows you to experience the world from a different perspective. This is a great way to improve your skills and skills.\n",
      "19. Traveling to new countries allows you to experience the world from a different perspective. This is a great way to improve your skills and skills.\n",
      "20. Tra\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of \u001b[0m\u001b[91mthe world. 4. Traveling to new countries allows you to learn a foreign language. Learning a new language can be a great way to improve your skills and skills. 5. Traveling to new countries allows you to see the world from a different perspective. 6. Traveling to new countries allows you to experience the world from a different perspective. 7. This is a great way to improve your skills and skills. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20.\u001b[0m\n",
      "\n",
      "\n",
      "Pruning model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size after pruning:  13.510393856\n",
      "Model size after pruning:  13.510197248\n",
      "Model size after pruning:  13.510197248\n",
      "Model size after pruning:  13.490905088\n",
      "Model size after pruning:  13.490905088\n",
      "Model size after pruning:  13.490044928\n",
      "Model size after pruning:  13.48165632\n",
      "Model size after pruning:  13.4811648\n",
      "Model size after pruning:  13.4811648\n",
      "Model size after pruning:  13.47907584\n",
      "Model size after pruning:  13.47907584\n",
      "Model size after pruning:  13.478928384\n",
      "Model size after pruning:  13.470539776\n",
      "Model size after pruning:  13.458202624\n",
      "Model size after pruning:  13.45400832\n",
      "Model size after pruning:  13.443588096\n",
      "Model size after pruning:  13.439393792\n",
      "Model size after pruning:  13.429219328\n",
      "Model size after pruning:  13.429219328\n",
      "Model size after pruning:  13.42767104\n",
      "Model size after pruning:  13.419282432\n",
      "Model size after pruning:  13.305298944\n",
      "Model size after pruning:  13.23819008\n",
      "Model size after pruning:  13.102923776\n",
      "Model size after pruning:  13.035814912\n",
      "Model size after pruning:  12.900548608\n",
      "Model size after pruning:  12.833439744\n",
      "Model size after pruning:  12.69817344\n",
      "Model size after pruning:  12.631064576\n",
      "Model size after pruning:  12.495798272\n",
      "Model size after pruning:  12.428689408\n",
      "Model size after pruning:  12.293423104\n",
      "Model size after pruning:  12.22631424\n",
      "Model size after pruning:  12.091047936\n",
      "Model size after pruning:  12.023939072\n",
      "Model size after pruning:  11.888672768\n",
      "Model size after pruning:  11.821563904\n",
      "Model size after pruning:  11.6862976\n",
      "Model size after pruning:  11.619188736\n",
      "Model size after pruning:  11.483922432\n",
      "Model size after pruning:  11.416813568\n",
      "Model size after pruning:  11.281547264\n",
      "Model size after pruning:  11.2144384\n",
      "Model size after pruning:  11.079172096\n",
      "Model size after pruning:  11.012063232\n",
      "Model size after pruning:  10.876796928\n",
      "Model size after pruning:  10.809688064\n",
      "Model size after pruning:  10.67442176\n",
      "Saving model after pruning to checkpoint dir\n",
      "Model saved\n",
      "Real Pruned Model\n",
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (4): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (o_proj): Linear(in_features=3968, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11000, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11000, bias=False)\n",
      "          (down_proj): Linear(in_features=11000, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (5): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10223, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10223, bias=False)\n",
      "          (down_proj): Linear(in_features=10223, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (6): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10973, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10973, bias=False)\n",
      "          (down_proj): Linear(in_features=10973, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (7): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (o_proj): Linear(in_features=3840, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10988, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10988, bias=False)\n",
      "          (down_proj): Linear(in_features=10988, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (8): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10923, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10923, bias=False)\n",
      "          (down_proj): Linear(in_features=10923, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (9): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11002, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11002, bias=False)\n",
      "          (down_proj): Linear(in_features=11002, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (10): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (o_proj): Linear(in_features=3840, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10506, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10506, bias=False)\n",
      "          (down_proj): Linear(in_features=10506, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (11): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (o_proj): Linear(in_features=3968, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10584, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10584, bias=False)\n",
      "          (down_proj): Linear(in_features=10584, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (12): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (o_proj): Linear(in_features=3968, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10594, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10594, bias=False)\n",
      "          (down_proj): Linear(in_features=10594, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (13): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=10945, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=10945, bias=False)\n",
      "          (down_proj): Linear(in_features=10945, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (14): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (o_proj): Linear(in_features=3840, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=6370, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=6370, bias=False)\n",
      "          (down_proj): Linear(in_features=6370, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (15-27): 13 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2048, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2048, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (down_proj): Linear(in_features=5504, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (28-31): 4 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n",
      "Real Pruned Model Size\n",
      "10.67442176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short Context: 16.46419464722564 tokens/sec, 516 tokens (including full prompt)\n",
      "Long Context: 40.9696348745398 tokens/sec, 1288 tokens (including full prompt)\n",
      "Average:  18.287360287072584 tokens/sec\n",
      "***************   Experiment completed successfully Successfully   ***************\n"
     ]
    }
   ],
   "source": [
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc69a771",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T05:12:15.616691Z",
     "start_time": "2024-05-25T05:12:15.605626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5318332416"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f5c85b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f825bdf",
   "metadata": {},
   "source": [
    "## Experiment 2526 --> PreserveRatio=0.6, lbound=0.5, rbound=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8088b8ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T05:15:43.669277Z",
     "start_time": "2024-05-25T05:15:43.661456Z"
    }
   },
   "outputs": [],
   "source": [
    "pruning_dict = \"pruning_dict_1.0_0.5_1.0_chat_2526.json\"\n",
    "save_dir = \"/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/\"\n",
    "\n",
    "p = pruning_dict.split(\"_\")[-1].split(\".\")[-2]\n",
    "output_dir = \"/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints//\" + p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c06bb99c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T05:15:44.143332Z",
     "start_time": "2024-05-25T05:15:44.139988Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment = ExperimentRunner(pipeline, tokenizer, pruning_dict, \n",
    "                 save_dir=save_dir, output_dir=output_dir, ignored_layers=None, \n",
    "                 use_template=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18f904f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T05:38:52.454204Z",
     "start_time": "2024-05-25T05:15:44.621554Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************   Running Experiment   ***************\n",
      "61 ==>  3584\n",
      "67 ==>  5504\n",
      "75 ==>  3584\n",
      "81 ==>  5504\n",
      "89 ==>  3072\n",
      "95 ==>  8965\n",
      "103 ==>  2944\n",
      "109 ==>  5504\n",
      "117 ==>  3968\n",
      "123 ==>  6234\n",
      "131 ==>  3840\n",
      "137 ==>  5504\n",
      "145 ==>  3200\n",
      "151 ==>  5504\n",
      "159 ==>  3968\n",
      "165 ==>  5504\n",
      "173 ==>  3840\n",
      "179 ==>  5504\n",
      "187 ==>  3200\n",
      "193 ==>  5504\n",
      "201 ==>  3584\n",
      "207 ==>  5504\n",
      "215 ==>  2432\n",
      "221 ==>  6185\n",
      "229 ==>  3968\n",
      "235 ==>  5511\n",
      "243 ==>  3968\n",
      "249 ==>  5504\n",
      "257 ==>  3840\n",
      "263 ==>  5504\n",
      "271 ==>  3712\n",
      "277 ==>  5504\n",
      "285 ==>  3456\n",
      "291 ==>  5504\n",
      "299 ==>  3072\n",
      "305 ==>  5504\n",
      "313 ==>  2048\n",
      "319 ==>  5504\n",
      "327 ==>  2048\n",
      "333 ==>  5504\n",
      "341 ==>  2048\n",
      "347 ==>  5504\n",
      "355 ==>  2048\n",
      "361 ==>  5504\n",
      "369 ==>  2048\n",
      "375 ==>  5504\n",
      "383 ==>  2048\n",
      "389 ==>  5504\n",
      "***************   Pruning Model   ***************\n",
      "Pruning model\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Saving model after pruning to checkpoint dir\n",
      "Model saved\n",
      "***************   Model Pruned Successfully   ***************\n",
      "Model Size after Pruning:  13.51458816\n",
      "evaluating on wikitext2\n",
      "nsamples 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:   0%|                                                                                                                                                                                                                                                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:   4%|████████████▎                                                                                                                                                                                                                                                                                                      | 1/25 [00:00<00:13,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:   8%|████████████████████████▌                                                                                                                                                                                                                                                                                          | 2/25 [00:01<00:12,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  12%|████████████████████████████████████▊                                                                                                                                                                                                                                                                              | 3/25 [00:01<00:13,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  16%|█████████████████████████████████████████████████                                                                                                                                                                                                                                                                  | 4/25 [00:02<00:12,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  20%|█████████████████████████████████████████████████████████████▍                                                                                                                                                                                                                                                     | 5/25 [00:02<00:11,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  24%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                                                                         | 6/25 [00:03<00:11,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  28%|█████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                                                                                             | 7/25 [00:04<00:10,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  32%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                                                                                | 8/25 [00:04<00:09,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  36%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                                    | 9/25 [00:05<00:09,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  40%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                                                       | 10/25 [00:05<00:08,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  44%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                           | 11/25 [00:06<00:07,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  48%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                               | 12/25 [00:06<00:07,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  52%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                                   | 13/25 [00:07<00:06,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                      | 14/25 [00:08<00:06,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                          | 15/25 [00:08<00:05,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                              | 16/25 [00:09<00:05,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                  | 17/25 [00:09<00:04,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                     | 18/25 [00:10<00:04,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                         | 19/25 [00:10<00:03,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                             | 20/25 [00:11<00:02,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                 | 21/25 [00:12<00:02,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 22/25 [00:12<00:01,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 23/25 [00:13<00:01,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "WikiText Validation:  96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 24/25 [00:13<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WikiText Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:14<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPL:  35.08295440673828\n",
      "Perplexity on wikitext2:  35.08295440673828\n",
      "Loading checkpoint from /data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model passed to evaluation:  LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-25:10:47:24,223 WARNING  [task.py:763] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-05-25:10:47:24,225 WARNING  [task.py:775] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2024-05-25:10:47:30,324 WARNING  [task.py:763] [Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-05-25:10:47:30,325 WARNING  [task.py:775] [Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for winogrande contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/winogrande\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "2024-05-25:10:48:13,419 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-05-25:10:48:13,421 INFO     [evaluator.py:177] Initializing huggingface model, with arguments: {'pretrained': '/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/'}\n",
      "2024-05-25:10:48:13,434 WARNING  [logging.py:61] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "2024-05-25:10:48:13,435 INFO     [huggingface.py:163] Using device 'cuda'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92fab356bea418db9a09508d227c0ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-25:10:48:35,514 WARNING  [task.py:763] [Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-05-25:10:48:35,515 WARNING  [task.py:775] [Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-05-25:10:48:40,208 WARNING  [task.py:763] [Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-05-25:10:48:40,209 WARNING  [task.py:775] [Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-05-25:10:49:13,332 WARNING  [evaluator.py:239] Overwriting default num_fewshot of arc_easy from None to 0\n",
      "2024-05-25:10:49:13,333 WARNING  [evaluator.py:239] Overwriting default num_fewshot of winogrande from None to 0\n",
      "2024-05-25:10:49:13,334 WARNING  [evaluator.py:239] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2024-05-25:10:49:13,335 WARNING  [evaluator.py:239] Overwriting default num_fewshot of boolq from None to 0\n",
      "2024-05-25:10:49:13,336 WARNING  [evaluator.py:239] Overwriting default num_fewshot of rte from None to 0\n",
      "2024-05-25:10:49:13,336 WARNING  [evaluator.py:239] Overwriting default num_fewshot of openbookqa from None to 0\n",
      "2024-05-25:10:49:13,337 WARNING  [evaluator.py:239] Overwriting default num_fewshot of arc_challenge from None to 0\n",
      "2024-05-25:10:49:13,340 INFO     [task.py:395] Building contexts for arc_easy on rank 0...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 818.91it/s]\n",
      "2024-05-25:10:49:13,474 INFO     [task.py:395] Building contexts for winogrande on rank 0...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 60981.45it/s]\n",
      "2024-05-25:10:49:13,484 INFO     [task.py:395] Building contexts for hellaswag on rank 0...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1939.54it/s]\n",
      "2024-05-25:10:49:13,562 INFO     [task.py:395] Building contexts for boolq on rank 0...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1404.52it/s]\n",
      "2024-05-25:10:49:13,642 INFO     [task.py:395] Building contexts for rte on rank 0...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1521.12it/s]\n",
      "2024-05-25:10:49:13,717 INFO     [task.py:395] Building contexts for openbookqa on rank 0...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1586.05it/s]\n",
      "2024-05-25:10:49:13,791 INFO     [task.py:395] Building contexts for arc_challenge on rank 0...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 868.55it/s]\n",
      "2024-05-25:10:49:13,919 INFO     [evaluator.py:379] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2199/2199 [02:01<00:00, 18.10it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "fatal: not a git repository (or any parent up to mount point /)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "|     Alias     | Acc, None |   Acc StdErr, None   | Acc Norm, None | Acc Norm StdErr, None |\n",
      "+---------------+-----------+----------------------+----------------+-----------------------+\n",
      "|    arc_easy   |    0.41   | 0.049431107042371025 |      0.36      |  0.04824181513244218  |\n",
      "|   winogrande  |    0.55   |         0.05         |      None      |          None         |\n",
      "|   hellaswag   |    0.36   | 0.04824181513244218  |      0.49      |  0.05024183937956912  |\n",
      "|     boolq     |    0.45   |         0.05         |      None      |          None         |\n",
      "|      rte      |    0.57   | 0.04975698519562428  |      None      |          None         |\n",
      "|   openbookqa  |    0.14   | 0.03487350880197769  |      0.29      |  0.045604802157206845 |\n",
      "| arc_challenge |    0.21   | 0.040936018074033256 |      0.31      |  0.04648231987117316  |\n",
      "+---------------+-----------+----------------------+----------------+-----------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Gardening provides a sense of accomplishment and tranquility, as you nurture plants and watch them \u001b[0m\u001b[91m grow and flourish.\n",
      "The benefits of gardening are well known and dating the girl of aids to be by to the is a common. The the girl. the is a common term for the girl of a-'the girl of a- tag- tagged- tag- tagged- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag- tag\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Gardening provides a sense of accomplishment and tranquility, as you nurture plants and watch them \u001b[0m\u001b[91mgrow and flourish. The benefits of gardening are well known and dating the girl of aids to be by to the is a common. The the girl.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Family traditions are passed down from generation to generation, creating a sense of continuity and belonging. Whether it's holiday celebrations, special recipes, or annual gatherings, these traditions foster \u001b[0m\u001b[91m the development of social skills and emotions, allowing children to to learn to be more effective and happy.\n",
      "Children are not as different from the way we think we are, and we are not more well-off in the world, in the time, in the way, in the sense, in the sense of being, in the way of being, in the way of being, in the way of being, in the way of being, in the way of being, in the way of being, in the way of being, in the way of being, in the way of being, in the way of being, in the way of being, in the way of being, in the way of being, in the way of being, in the way of being, in the way, in the way, in the way, in the way, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Family traditions are passed down from generation to generation, creating a sense of continuity and belonging. Whether it's holiday celebrations, special recipes, or annual gatherings, these traditions foster \u001b[0m\u001b[91mthe development of social skills and emotions, allowing children to to learn to be more effective and happy.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future \u001b[0m\u001b[91m, fashion will be a form of art, a form of expression, a form of fashion. In the future, fashion will be a form of expression, a form of fashion. In the future, fashion will be a form of fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a fashion. fashion will be a. fashion. fashion. fashion. fashion. fashion. fashion. fashion. fashion. fashion. fashion. fashion. fashion. fashion. fashion. fashion. fashion. fashion. fashion. fashion. fashion. fashion. fashion. fashion.. fashion. fashion..\n",
      ".\n",
      ".\n",
      "..\n",
      ".....................................................................................................................................................................................................................................................................\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future \u001b[0m\u001b[91m, fashion will be a form of art, a form of expression, a form of fashion. In the future, fashion will be a form of expression, a form of fashion. In the future, fashion will be a form of fashion. fashion will be a fashion. fashion will be a. fashion.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Artificial intelligence is transforming the healthcare industry by enabling \u001b[0m\u001b[91m doctors to make smarter dec sierp.\n",
      "3 4 5 6 50 10 101 102 11 110 1103 12 13 14 15 16 17 18 19 - 19.20 - 20 - 201 20.25 - 3.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.va.a.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.aa.ad.ad.ad.ad.ad.ad.ad.ad.ad.ad.ad.ad.ad.ad.ad.ad.ad.ad.ad.ad.ad.ad\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Artificial intelligence is transforming the healthcare industry by enabling \u001b[0m\u001b[91mdoctors to make smarter dec sierp. 3 4 5 6 50 10 101 102 11 110 1103 12 13 14 15 16 17 18 19 - 19. 20 - 20 - 201 20. 25 - 3. 4. va. a. aa.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Machine learning algorithms are increasingly being used to predict stock market trends. By analyzing historical data and identifying patterns, these models can \u001b[0m\u001b[91m help to provide a more accurate and realistic view of the market. This is a valuable quality that investors can expect to receive from the companies they are investing in.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "> _x</10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Machine learning algorithms are increasingly being used to predict stock market trends. By analyzing historical data and identifying patterns, these models can \u001b[0m\u001b[91mhelp to provide a more accurate and realistic view of the market. This is a valuable quality that investors can expect to receive from the companies they are investing in.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The integration of natural language processing with machine learning has opened up new possibilities in human-computer interaction. For instance, chatbots powered by sophisticated NLP algorithms can now understand and respond to user queries with remarkable accuracy. As these technologies continue to evolve, we can expect that \u001b[0m\u001b[91m they will continue to have a significant impact on the field of human-computer interaction.\n",
      "The Human-Computer Interaction (HCI) is a field of study that is rapidly growing in popularity. This is largely because of the work that has been done in the area by students and professors around the world. These students and professors have been working to understand the nature of human-computer interaction and how to improve on it. This has led to the development of a number of theories that have been used to explain the nature of the behavior of humans. These theories have also led to the development of a number of techniques that have been used to improve on the ability of humans to communicate. These techniques have been used to improve on the ability of the hand to communicate with the brain. This has led to the development of a number of devices that have been used to improve on the ability of the hand to communicate with the brain. This has led to the development of a number of devices that have been used to improve on the ability of the hand to communicate with the brain. This has led to the development of a number of devices that have been used to improve on the ability of the hand to communicate with the brain. This has led to the development of a number of theories that have been used to improve on the ability of the hand to communicate with the brain. This has also led to the development of a number of techniques that have been used to improve on the ability of the hand to communicate with the brain. This has led to the development of a number of devices that have been used to improve on the ability of the hand to communicate with the brain. This has led to the development of a number of devices that have been used to improve on the ability of the hand to communicate with the brain. This has led to the development of a number of devices that have been used to improve on the ability of the hand to communicate with the brain. This has led to the development of a number of techniques that have been used to improve on the ability of the hand to communicate with the brain. This has led to the development of a number of devices that have been used to improve on the ability of the hand to communicate with the brain. This has led to the development of a number of technologies that have been used to improve on the ability of the hand to communicate with the brain. This has led to the development of a number of devices that have been used to improve on the ability of the hand to communicate with the brain.\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The integration of natural language processing with machine learning has opened up new possibilities in human-computer interaction. For instance, chatbots powered by sophisticated NLP algorithms can now understand and respond to user queries with remarkable accuracy. As these technologies continue to evolve, we can expect that \u001b[0m\u001b[91mthey will continue to have a significant impact on the field of human-computer interaction. The Human-Computer Interaction (HCI) is a field of study that is rapidly growing in popularity. This is largely because of the work that has been done in the area by students and professors around the world. These students and professors have been working to understand the nature of human-computer interaction and how to improve on it. This has led to the development of a number of theories that have been used to explain the nature of the behavior of humans. These theories have also led to the development of a number of techniques that have been used to improve on the ability of humans to communicate. These techniques have been used to improve on the ability of the hand to communicate with the brain. This has led to the development of a number of devices that have been used to improve on the ability of the hand to communicate with the brain. This has led to the development of a number of theories that have been used to improve on the ability of the hand to communicate with the brain. This has also led to the development of a number of techniques that have been used to improve on the ability of the hand to communicate with the brain. This has led to the development of a number of techniques that have been used to improve on the ability of the hand to communicate with the brain. This has led to the development of a number of technologies that have been used to improve on the ability of the hand to communicate with the brain.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Self-driving cars rely heavily on sensor data and advanced algorithms to navigate \u001b[0m\u001b[91m through the world.\n",
      "The best way to think about it is to think about it as a game.\n",
      "The best way to think about it is to think about it as a game. The best way to think about it as a game. The best way to think about it as a game. The best way to think about it as a game. The best way to think about it as a game. The best way to think about it as a game. The best way to think about it as a game. The best way to think about it as a game. The best way to think about it as a game. The.text.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.the.\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Self-driving cars rely heavily on sensor data and advanced algorithms to navigate \u001b[0m\u001b[91mthrough the world. The best way to think about it is to think about it as a game. The best way to think about it as a game. The. text. the.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m One of the biggest challenges in developing AI systems is ensuring they are ethical and unbiased. Researchers are working on creating frameworks that can \u001b[0m\u001b[91m be used as a tool to make the world a better place.\n",
      "\n",
      "\n",
      "{{#edit on:\n",
      "question id={}}\n",
      "  \\section{**/on:\n",
      "question}\n",
      "\n",
      "    \\beginycodeft;l;n;n;n;\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m One of the biggest challenges in developing AI systems is ensuring they are ethical and unbiased. Researchers are working on creating frameworks that can \u001b[0m\u001b[91mbe used as a tool to make the world a better place.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m In the field of computer vision, convolutional neural networks have revolutionized the way machines perceive visual information. By mimicking the human visual system, these networks can classify images, detect objects, and even perform image segmentation. This has significant applications in areas such as medical imaging, where AI can assist doctors in diagnosing conditions from X-rays and MRIs. As the technology advances, we may soon see AI systems that \u001b[0m\u001b[91m can do the job of a human. This will have a significant impact on the medical industry.\n",
      "The Medical Apps are a large and growing industry. The Medical Apps are a large and growing industry. The Medical Apps are a growing industry. The Medical Apps are a.\n",
      "The Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy. Healthy. Healthy. Healthy. Healthy. Healthy. Healthy. Healthy. Healthy. Healthy. Healthy. Healthy. Healthy. Healthy. Healthy. Healthy. Healthy. Healthy. Healthy. Healthy. Healthy. Healthy. Healthy.\n",
      "Healthy. Healthy. Healthy.\n",
      "Healthy. Healthy. Healthy.\n",
      "Healthy. Healthy. Healthy.\n",
      "Healthy. Healthy. Healthy.\n",
      "Healthy. Healthy. Healthy.\n",
      "Healthy. Healthy. Healthy.\n",
      "Healthy. Healthy. Healthy.\n",
      "Healthy. Healthy. Healthy.\n",
      "Healthy. Healthy.\n",
      "Healthy. Healthy.\n",
      "Healthy. Healthy.\n",
      "Healthy. Healthy.\n",
      "H. and.\n",
      "\n",
      "H. and.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m In the field of computer vision, convolutional neural networks have revolutionized the way machines perceive visual information. By mimicking the human visual system, these networks can classify images, detect objects, and even perform image segmentation. This has significant applications in areas such as medical imaging, where AI can assist doctors in diagnosing conditions from X-rays and MRIs. As the technology advances, we may soon see AI systems that \u001b[0m\u001b[91mcan do the job of a human. This will have a significant impact on the medical industry. The Medical Apps are a large and growing industry. The Medical Apps are a growing industry. The Medical Apps are a. The Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy Healthy. Healthy. H.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Reinforcement learning algorithms learn optimal behaviors through \u001b[0m\u001b[91m machine learning algorithms.\n",
      "The algorithm is a method of solving a problem. The algorithm is a method of solving a problem. The algorithm is a method of solving a problem. The algorithm is a method of solving a problem. The algorithm is a method of solving a problem. The algorithm is a method of solving a problem. The algorithm is a method of solving a method. The method is a method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method.\n",
      "The. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method..\n",
      "The. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method. method.\n",
      "The. method. method. method. method. method. method. method. method. method. method. method. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the. the\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Reinforcement learning algorithms learn optimal behaviors through \u001b[0m\u001b[91mmachine learning algorithms. The algorithm is a method of solving a problem. The algorithm is a method of solving a method. The method is a method. method. The.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could \u001b[0m\u001b[91m be used to explain the complexity of a cryptographic algorithm. This could be a problem for the algorithm. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able to solve the problem. This is a problem that the algorithm has to be able\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could \u001b[0m\u001b[91mbe used to explain the complexity of a cryptographic algorithm. This could be a problem for the algorithm. This is a problem that the algorithm has to be able to solve the problem.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that \u001b[0m\u001b[91m will be able to detect and prevent the spread of the virus. This will require a significant amount of computing power and energy. However, the benefits of this technology are likely to be worth the cost of the increase in electricity.\n",
      "10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/10.1002/1\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The rise of big data has necessitated the development of new machine learning techniques capable of handling vast amounts of information. Techniques such as distributed learning and federated learning have emerged to process data across multiple devices without compromising privacy. These methods enable organizations to leverage large datasets for training robust models while ensuring data security. As we look to the future, the continued evolution of these techniques will likely lead to even more powerful and secure AI systems that \u001b[0m\u001b[91mwill be able to detect and prevent the spread of the virus. This will require a significant amount of computing power and energy. However, the benefits of this technology are likely to be worth the cost of the increase in electricity. 10. 1002/10.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Transfer learning allows models trained on large datasets to be fine-tuned for specific tasks by \u001b[0m\u001b[91m reducing the number of parameters.\n",
      "2) Deep-learning is a form of machine learning that is a form of a model is a model is a model is a model is a model is a model is a model is a model is a model is a model is a model is a method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method caercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercercer\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Transfer learning allows models trained on large datasets to be fine-tuned for specific tasks by \u001b[0m\u001b[91mreducing the number of parameters.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Explainable AI (XAI) is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to \u001b[0m\u001b[91m improve the performance of the system. This article will discuss the role of XAI in the field of computer science and how the field is changing to better serve the needs of the world.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        (10 000 1  01  02  03  04  05  06  07  08  09  10  11  12  13  14  15  16  17  18  19  19:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:new-new-new-new-new-new-new-new-new-new-new-new-new-new-new-new-new-new-new-new-new-new-new-new-new-new-new-new-new-new-\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Explainable AI (XAI) is becoming increasingly important as AI systems are deployed in critical areas. By providing insights into how models make decisions, XAI aims to \u001b[0m\u001b[91mimprove the performance of the system. This article will discuss the role of XAI in the field of computer science and how the field is changing to better serve the needs of the world.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and \u001b[0m\u001b[91m the clouds are the last to disappear.\n",
      "The sun is a star in the sky, and it is the sun that makes the sky. The sky is a sky, and it is a sky that is a sky. The sky is a sky, and it is a sky, and it is a sky, and it is a sky, and it is a sky, and it is a sky, and it is a sky, and it is a sky, and it is a, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and{ and{ and{ and{ and{ and{ and{ and{ and{ and{ and{ and{ and{ and\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m The beauty of a sunset over the ocean is unmatched, as the sky turns shades of orange and pink, and \u001b[0m\u001b[91mthe clouds are the last to disappear. The sun is a star in the sky, and it is the sun that makes the sky. The sky is a sky, and it is a sky that is a sky.\u001b[0m\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "Original: \n",
      "Prompt:  \u001b[1m Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of \u001b[0m\u001b[91m the world and allow you to make a decision that is right for you.\n",
      "The best way to make a decision on a travel is to do your research and to explore the destination you are travel to. You can do your research by searching the web for reviews, travel tips, and photos of the destination you are travel to. You can also explore the web for travel tips and photos by clicking on the link to the travel site you are trying to find out about. You can also explore the web by clicking on the link to the travel site you are trying to find out about. You can also explore the web by clicking on the link to the travel site you are trying to find out about and. You can also explore the world and make a decision that is right for you by clicking on the link to the location you are trying to find out about. You can also click on the link to the location you are trying to find out about and you can make a decision that is right for you. You can also make a decision by clicking on the link to the destination you are trying to find out about and you can make a decision by clicking on the link to the destination you are trying to find out about. You can also make a decision by clicking on the link to the destination you are trying to find out about. You can also make a decision by clicking on the link to the destination you are trying to find out about. You can also make a decision by clicking on the link to the destination you are trying to find out about. You can also make a decision by clicking on the link to the destination you are trying to find out. You can also make a decision by clicking on the link to the destination you are trying to find out. You can also make a decision by clicking on the link to the destination you are trying to find out. You can also make a decision by clicking on the link to the destination you are trying to find out. You can also make a decision by clicking on the link to the destination you are trying to finding out. You can also make a decision by clicking on the link to the destination you are trying to finding out. You can also make a decision by clicking on the link to the destination you are trying to finding out. You can also make a decision by clicking on the link to the destination you are trying to finding out. You can also make a decision by clicking on the link to the destination you are trying to finding out. You can also make a decision by clicking on the link to the\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Cleaned: \n",
      "Prompt:  \u001b[1m Traveling to new countries allows you to experience diverse cultures and traditions. Walking through the bustling markets, tasting local delicacies, and interacting with people can provide a deeper understanding of \u001b[0m\u001b[91mthe world and allow you to make a decision that is right for you. The best way to make a decision on a travel is to do your research and to explore the destination you are travel to. You can do your research by searching the web for reviews, travel tips, and photos of the destination you are travel to. You can also explore the web for travel tips and photos by clicking on the link to the travel site you are trying to find out about. You can also explore the web by clicking on the link to the travel site you are trying to find out about. You can also explore the web by clicking on the link to the travel site you are trying to find out about and. You can also explore the world and make a decision that is right for you by clicking on the link to the location you are trying to find out about. You can also click on the link to the location you are trying to find out about and you can make a decision that is right for you. You can also make a decision by clicking on the link to the destination you are trying to find out about and you can make a decision by clicking on the link to the destination you are trying to find out about. You can also make a decision by clicking on the link to the destination you are trying to find out about. You can also make a decision by clicking on the link to the destination you are trying to find out. You can also make a decision by clicking on the link to the destination you are trying to finding out.\u001b[0m\n",
      "\n",
      "\n",
      "Pruning model\n",
      "Model size after pruning:  13.497810944\n",
      "Model size after pruning:  13.36254464\n",
      "Model size after pruning:  13.345767424\n",
      "Model size after pruning:  13.21050112\n",
      "Model size after pruning:  13.176946688\n",
      "Model size after pruning:  13.12673792\n",
      "Model size after pruning:  13.088989184\n",
      "Model size after pruning:  12.95372288\n",
      "Model size after pruning:  12.949528576\n",
      "Model size after pruning:  12.832202752\n",
      "Model size after pruning:  12.823814144\n",
      "Model size after pruning:  12.68854784\n",
      "Model size after pruning:  12.659187712\n",
      "Model size after pruning:  12.523921408\n",
      "Model size after pruning:  12.519727104\n",
      "Model size after pruning:  12.3844608\n",
      "Model size after pruning:  12.376072192\n",
      "Model size after pruning:  12.240805888\n",
      "Model size after pruning:  12.21144576\n",
      "Model size after pruning:  12.076179456\n",
      "Model size after pruning:  12.05940224\n",
      "Model size after pruning:  11.924135936\n",
      "Model size after pruning:  11.869609984\n",
      "Model size after pruning:  11.751079936\n",
      "Model size after pruning:  11.746885632\n",
      "Model size after pruning:  11.61179136\n",
      "Model size after pruning:  11.607597056\n",
      "Model size after pruning:  11.472330752\n",
      "Model size after pruning:  11.463942144\n",
      "Model size after pruning:  11.32867584\n",
      "Model size after pruning:  11.316092928\n",
      "Model size after pruning:  11.180826624\n",
      "Model size after pruning:  11.159855104\n",
      "Model size after pruning:  11.0245888\n",
      "Model size after pruning:  10.991034368\n",
      "Model size after pruning:  10.855768064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size after pruning:  10.7886592\n",
      "Model size after pruning:  10.653392896\n",
      "Model size after pruning:  10.586284032\n",
      "Model size after pruning:  10.451017728\n",
      "Model size after pruning:  10.383908864\n",
      "Model size after pruning:  10.24864256\n",
      "Model size after pruning:  10.181533696\n",
      "Model size after pruning:  10.046267392\n",
      "Model size after pruning:  9.979158528\n",
      "Model size after pruning:  9.843892224\n",
      "Model size after pruning:  9.77678336\n",
      "Model size after pruning:  9.641517056\n",
      "Saving model after pruning to checkpoint dir\n",
      "Model saved\n",
      "Real Pruned Model\n",
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (4-5): 2 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "          (o_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (down_proj): Linear(in_features=5504, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (6): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
      "          (o_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=8965, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=8965, bias=False)\n",
      "          (down_proj): Linear(in_features=8965, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (7): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2944, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2944, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2944, bias=False)\n",
      "          (o_proj): Linear(in_features=2944, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (down_proj): Linear(in_features=5504, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (8): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (o_proj): Linear(in_features=3968, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=6234, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=6234, bias=False)\n",
      "          (down_proj): Linear(in_features=6234, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (9): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (o_proj): Linear(in_features=3840, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (down_proj): Linear(in_features=5504, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (10): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3200, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3200, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3200, bias=False)\n",
      "          (o_proj): Linear(in_features=3200, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (down_proj): Linear(in_features=5504, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (11): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (o_proj): Linear(in_features=3968, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (down_proj): Linear(in_features=5504, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (12): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (o_proj): Linear(in_features=3840, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (down_proj): Linear(in_features=5504, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (13): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3200, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3200, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3200, bias=False)\n",
      "          (o_proj): Linear(in_features=3200, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (down_proj): Linear(in_features=5504, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (14): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "          (o_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (down_proj): Linear(in_features=5504, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (15): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2432, bias=False)\n",
      "          (o_proj): Linear(in_features=2432, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=6185, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=6185, bias=False)\n",
      "          (down_proj): Linear(in_features=6185, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (16): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (o_proj): Linear(in_features=3968, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=5511, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=5511, bias=False)\n",
      "          (down_proj): Linear(in_features=5511, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (17): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3968, bias=False)\n",
      "          (o_proj): Linear(in_features=3968, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (down_proj): Linear(in_features=5504, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (18): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3840, bias=False)\n",
      "          (o_proj): Linear(in_features=3840, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (down_proj): Linear(in_features=5504, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (19): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3712, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3712, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3712, bias=False)\n",
      "          (o_proj): Linear(in_features=3712, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (down_proj): Linear(in_features=5504, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (20): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3456, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3456, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3456, bias=False)\n",
      "          (o_proj): Linear(in_features=3456, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (down_proj): Linear(in_features=5504, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (21): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
      "          (o_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (down_proj): Linear(in_features=5504, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (22-27): 6 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=2048, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=2048, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=5504, bias=False)\n",
      "          (down_proj): Linear(in_features=5504, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "      (28-31): 4 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n",
      "Real Pruned Model Size\n",
      "9.641517056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short Context: 17.15873457291694 tokens/sec, 134 tokens (including full prompt)\n",
      "Long Context: 197.79836299859983 tokens/sec, 846 tokens (including full prompt)\n",
      "Average:  18.43316377623611 tokens/sec\n",
      "***************   Experiment completed successfully Successfully   ***************\n"
     ]
    }
   ],
   "source": [
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ee35099",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T05:38:52.465340Z",
     "start_time": "2024-05-25T05:38:52.458463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4801880064"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b11d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a3d8315",
   "metadata": {},
   "source": [
    "# Timer Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be950efe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:31.474029Z",
     "start_time": "2024-06-11T04:34:31.468124Z"
    },
    "code_folding": [
     2
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from transformers.models.llama.modeling_llama import LlamaAttention, LlamaDecoderLayer, LlamaMLP, LlamaConfig, LlamaDecoderLayer\n",
    "\n",
    "class TimerHook:\n",
    "    def __init__(self):\n",
    "        self.start_event = torch.cuda.Event(enable_timing=True)\n",
    "        self.end_event = torch.cuda.Event(enable_timing=True)\n",
    "        self.total_time = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def pre_hook(self, module, input):\n",
    "#         print(\"Prehook recorded\")\n",
    "        self.start_event.record()\n",
    "\n",
    "    def forward_hook(self, module, input, output):\n",
    "#         print(\"Post Hook recorded\")\n",
    "        self.end_event.record()\n",
    "        # Wait for all operations to finish before measuring the time\n",
    "        torch.cuda.synchronize()\n",
    "        # elapsed_time gives time in milliseconds. Multiply by 1000 for microseconds.\n",
    "        self.total_time += self.start_event.elapsed_time(self.end_event) * 1000\n",
    "        self.count += 1\n",
    "\n",
    "    def get_average_time(self):\n",
    "#         print(\"Total Time: \", self.total_time)\n",
    "#         print(\"Count: \", self.count)\n",
    "        return self.total_time / self.count if self.count > 0 else 0\n",
    "    def print_params(self):\n",
    "        return \"Total Time: {}, Count: {}\".format(self.total_time, self.count)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.total_time = 0\n",
    "        self.count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33fd4156",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:31.478787Z",
     "start_time": "2024-06-11T04:34:31.475867Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from transformers.models.llama.modeling_llama import LlamaAttention, LlamaDecoderLayer, LlamaMLP, LlamaConfig, LlamaDecoderLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80723fbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T07:46:27.803955Z",
     "start_time": "2024-05-25T07:45:38.684983Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "2024-05-25 13:15:42.223078: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-25 13:15:43.469643: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42226f480e7428c92ffd9a1a9b4b7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(hf_llama_path, padding_side=\"left\", padding=True, truncation=True)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=hf_llama_path,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "#     revision=revision,\n",
    "    return_full_text=False\n",
    ")\n",
    "\n",
    "# Required tokenizer setting for batch inference\n",
    "pipeline.tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "model = pipeline.model\n",
    "model.seqlen = model.config.max_position_embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3d5a016",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T06:39:31.469104Z",
     "start_time": "2024-05-25T06:39:31.461682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model\n",
      "model.embed_tokens\n",
      "model.layers\n",
      "model.layers.0\n",
      "model.layers.0.self_attn\n",
      "model.layers.0.self_attn.q_proj\n",
      "model.layers.0.self_attn.k_proj\n",
      "model.layers.0.self_attn.v_proj\n",
      "model.layers.0.self_attn.o_proj\n",
      "model.layers.0.self_attn.rotary_emb\n",
      "model.layers.0.mlp\n",
      "model.layers.0.mlp.gate_proj\n",
      "model.layers.0.mlp.up_proj\n",
      "model.layers.0.mlp.down_proj\n",
      "model.layers.0.mlp.act_fn\n",
      "model.layers.0.input_layernorm\n",
      "model.layers.0.post_attention_layernorm\n",
      "model.layers.1\n",
      "model.layers.1.self_attn\n",
      "model.layers.1.self_attn.q_proj\n",
      "model.layers.1.self_attn.k_proj\n",
      "model.layers.1.self_attn.v_proj\n",
      "model.layers.1.self_attn.o_proj\n",
      "model.layers.1.self_attn.rotary_emb\n",
      "model.layers.1.mlp\n",
      "model.layers.1.mlp.gate_proj\n",
      "model.layers.1.mlp.up_proj\n",
      "model.layers.1.mlp.down_proj\n",
      "model.layers.1.mlp.act_fn\n",
      "model.layers.1.input_layernorm\n",
      "model.layers.1.post_attention_layernorm\n",
      "model.layers.2\n",
      "model.layers.2.self_attn\n",
      "model.layers.2.self_attn.q_proj\n",
      "model.layers.2.self_attn.k_proj\n",
      "model.layers.2.self_attn.v_proj\n",
      "model.layers.2.self_attn.o_proj\n",
      "model.layers.2.self_attn.rotary_emb\n",
      "model.layers.2.mlp\n",
      "model.layers.2.mlp.gate_proj\n",
      "model.layers.2.mlp.up_proj\n",
      "model.layers.2.mlp.down_proj\n",
      "model.layers.2.mlp.act_fn\n",
      "model.layers.2.input_layernorm\n",
      "model.layers.2.post_attention_layernorm\n",
      "model.layers.3\n",
      "model.layers.3.self_attn\n",
      "model.layers.3.self_attn.q_proj\n",
      "model.layers.3.self_attn.k_proj\n",
      "model.layers.3.self_attn.v_proj\n",
      "model.layers.3.self_attn.o_proj\n",
      "model.layers.3.self_attn.rotary_emb\n",
      "model.layers.3.mlp\n",
      "model.layers.3.mlp.gate_proj\n",
      "model.layers.3.mlp.up_proj\n",
      "model.layers.3.mlp.down_proj\n",
      "model.layers.3.mlp.act_fn\n",
      "model.layers.3.input_layernorm\n",
      "model.layers.3.post_attention_layernorm\n",
      "model.layers.4\n",
      "model.layers.4.self_attn\n",
      "model.layers.4.self_attn.q_proj\n",
      "model.layers.4.self_attn.k_proj\n",
      "model.layers.4.self_attn.v_proj\n",
      "model.layers.4.self_attn.o_proj\n",
      "model.layers.4.self_attn.rotary_emb\n",
      "model.layers.4.mlp\n",
      "model.layers.4.mlp.gate_proj\n",
      "model.layers.4.mlp.up_proj\n",
      "model.layers.4.mlp.down_proj\n",
      "model.layers.4.mlp.act_fn\n",
      "model.layers.4.input_layernorm\n",
      "model.layers.4.post_attention_layernorm\n",
      "model.layers.5\n",
      "model.layers.5.self_attn\n",
      "model.layers.5.self_attn.q_proj\n",
      "model.layers.5.self_attn.k_proj\n",
      "model.layers.5.self_attn.v_proj\n",
      "model.layers.5.self_attn.o_proj\n",
      "model.layers.5.self_attn.rotary_emb\n",
      "model.layers.5.mlp\n",
      "model.layers.5.mlp.gate_proj\n",
      "model.layers.5.mlp.up_proj\n",
      "model.layers.5.mlp.down_proj\n",
      "model.layers.5.mlp.act_fn\n",
      "model.layers.5.input_layernorm\n",
      "model.layers.5.post_attention_layernorm\n",
      "model.layers.6\n",
      "model.layers.6.self_attn\n",
      "model.layers.6.self_attn.q_proj\n",
      "model.layers.6.self_attn.k_proj\n",
      "model.layers.6.self_attn.v_proj\n",
      "model.layers.6.self_attn.o_proj\n",
      "model.layers.6.self_attn.rotary_emb\n",
      "model.layers.6.mlp\n",
      "model.layers.6.mlp.gate_proj\n",
      "model.layers.6.mlp.up_proj\n",
      "model.layers.6.mlp.down_proj\n",
      "model.layers.6.mlp.act_fn\n",
      "model.layers.6.input_layernorm\n",
      "model.layers.6.post_attention_layernorm\n",
      "model.layers.7\n",
      "model.layers.7.self_attn\n",
      "model.layers.7.self_attn.q_proj\n",
      "model.layers.7.self_attn.k_proj\n",
      "model.layers.7.self_attn.v_proj\n",
      "model.layers.7.self_attn.o_proj\n",
      "model.layers.7.self_attn.rotary_emb\n",
      "model.layers.7.mlp\n",
      "model.layers.7.mlp.gate_proj\n",
      "model.layers.7.mlp.up_proj\n",
      "model.layers.7.mlp.down_proj\n",
      "model.layers.7.mlp.act_fn\n",
      "model.layers.7.input_layernorm\n",
      "model.layers.7.post_attention_layernorm\n",
      "model.layers.8\n",
      "model.layers.8.self_attn\n",
      "model.layers.8.self_attn.q_proj\n",
      "model.layers.8.self_attn.k_proj\n",
      "model.layers.8.self_attn.v_proj\n",
      "model.layers.8.self_attn.o_proj\n",
      "model.layers.8.self_attn.rotary_emb\n",
      "model.layers.8.mlp\n",
      "model.layers.8.mlp.gate_proj\n",
      "model.layers.8.mlp.up_proj\n",
      "model.layers.8.mlp.down_proj\n",
      "model.layers.8.mlp.act_fn\n",
      "model.layers.8.input_layernorm\n",
      "model.layers.8.post_attention_layernorm\n",
      "model.layers.9\n",
      "model.layers.9.self_attn\n",
      "model.layers.9.self_attn.q_proj\n",
      "model.layers.9.self_attn.k_proj\n",
      "model.layers.9.self_attn.v_proj\n",
      "model.layers.9.self_attn.o_proj\n",
      "model.layers.9.self_attn.rotary_emb\n",
      "model.layers.9.mlp\n",
      "model.layers.9.mlp.gate_proj\n",
      "model.layers.9.mlp.up_proj\n",
      "model.layers.9.mlp.down_proj\n",
      "model.layers.9.mlp.act_fn\n",
      "model.layers.9.input_layernorm\n",
      "model.layers.9.post_attention_layernorm\n",
      "model.layers.10\n",
      "model.layers.10.self_attn\n",
      "model.layers.10.self_attn.q_proj\n",
      "model.layers.10.self_attn.k_proj\n",
      "model.layers.10.self_attn.v_proj\n",
      "model.layers.10.self_attn.o_proj\n",
      "model.layers.10.self_attn.rotary_emb\n",
      "model.layers.10.mlp\n",
      "model.layers.10.mlp.gate_proj\n",
      "model.layers.10.mlp.up_proj\n",
      "model.layers.10.mlp.down_proj\n",
      "model.layers.10.mlp.act_fn\n",
      "model.layers.10.input_layernorm\n",
      "model.layers.10.post_attention_layernorm\n",
      "model.layers.11\n",
      "model.layers.11.self_attn\n",
      "model.layers.11.self_attn.q_proj\n",
      "model.layers.11.self_attn.k_proj\n",
      "model.layers.11.self_attn.v_proj\n",
      "model.layers.11.self_attn.o_proj\n",
      "model.layers.11.self_attn.rotary_emb\n",
      "model.layers.11.mlp\n",
      "model.layers.11.mlp.gate_proj\n",
      "model.layers.11.mlp.up_proj\n",
      "model.layers.11.mlp.down_proj\n",
      "model.layers.11.mlp.act_fn\n",
      "model.layers.11.input_layernorm\n",
      "model.layers.11.post_attention_layernorm\n",
      "model.layers.12\n",
      "model.layers.12.self_attn\n",
      "model.layers.12.self_attn.q_proj\n",
      "model.layers.12.self_attn.k_proj\n",
      "model.layers.12.self_attn.v_proj\n",
      "model.layers.12.self_attn.o_proj\n",
      "model.layers.12.self_attn.rotary_emb\n",
      "model.layers.12.mlp\n",
      "model.layers.12.mlp.gate_proj\n",
      "model.layers.12.mlp.up_proj\n",
      "model.layers.12.mlp.down_proj\n",
      "model.layers.12.mlp.act_fn\n",
      "model.layers.12.input_layernorm\n",
      "model.layers.12.post_attention_layernorm\n",
      "model.layers.13\n",
      "model.layers.13.self_attn\n",
      "model.layers.13.self_attn.q_proj\n",
      "model.layers.13.self_attn.k_proj\n",
      "model.layers.13.self_attn.v_proj\n",
      "model.layers.13.self_attn.o_proj\n",
      "model.layers.13.self_attn.rotary_emb\n",
      "model.layers.13.mlp\n",
      "model.layers.13.mlp.gate_proj\n",
      "model.layers.13.mlp.up_proj\n",
      "model.layers.13.mlp.down_proj\n",
      "model.layers.13.mlp.act_fn\n",
      "model.layers.13.input_layernorm\n",
      "model.layers.13.post_attention_layernorm\n",
      "model.layers.14\n",
      "model.layers.14.self_attn\n",
      "model.layers.14.self_attn.q_proj\n",
      "model.layers.14.self_attn.k_proj\n",
      "model.layers.14.self_attn.v_proj\n",
      "model.layers.14.self_attn.o_proj\n",
      "model.layers.14.self_attn.rotary_emb\n",
      "model.layers.14.mlp\n",
      "model.layers.14.mlp.gate_proj\n",
      "model.layers.14.mlp.up_proj\n",
      "model.layers.14.mlp.down_proj\n",
      "model.layers.14.mlp.act_fn\n",
      "model.layers.14.input_layernorm\n",
      "model.layers.14.post_attention_layernorm\n",
      "model.layers.15\n",
      "model.layers.15.self_attn\n",
      "model.layers.15.self_attn.q_proj\n",
      "model.layers.15.self_attn.k_proj\n",
      "model.layers.15.self_attn.v_proj\n",
      "model.layers.15.self_attn.o_proj\n",
      "model.layers.15.self_attn.rotary_emb\n",
      "model.layers.15.mlp\n",
      "model.layers.15.mlp.gate_proj\n",
      "model.layers.15.mlp.up_proj\n",
      "model.layers.15.mlp.down_proj\n",
      "model.layers.15.mlp.act_fn\n",
      "model.layers.15.input_layernorm\n",
      "model.layers.15.post_attention_layernorm\n",
      "model.layers.16\n",
      "model.layers.16.self_attn\n",
      "model.layers.16.self_attn.q_proj\n",
      "model.layers.16.self_attn.k_proj\n",
      "model.layers.16.self_attn.v_proj\n",
      "model.layers.16.self_attn.o_proj\n",
      "model.layers.16.self_attn.rotary_emb\n",
      "model.layers.16.mlp\n",
      "model.layers.16.mlp.gate_proj\n",
      "model.layers.16.mlp.up_proj\n",
      "model.layers.16.mlp.down_proj\n",
      "model.layers.16.mlp.act_fn\n",
      "model.layers.16.input_layernorm\n",
      "model.layers.16.post_attention_layernorm\n",
      "model.layers.17\n",
      "model.layers.17.self_attn\n",
      "model.layers.17.self_attn.q_proj\n",
      "model.layers.17.self_attn.k_proj\n",
      "model.layers.17.self_attn.v_proj\n",
      "model.layers.17.self_attn.o_proj\n",
      "model.layers.17.self_attn.rotary_emb\n",
      "model.layers.17.mlp\n",
      "model.layers.17.mlp.gate_proj\n",
      "model.layers.17.mlp.up_proj\n",
      "model.layers.17.mlp.down_proj\n",
      "model.layers.17.mlp.act_fn\n",
      "model.layers.17.input_layernorm\n",
      "model.layers.17.post_attention_layernorm\n",
      "model.layers.18\n",
      "model.layers.18.self_attn\n",
      "model.layers.18.self_attn.q_proj\n",
      "model.layers.18.self_attn.k_proj\n",
      "model.layers.18.self_attn.v_proj\n",
      "model.layers.18.self_attn.o_proj\n",
      "model.layers.18.self_attn.rotary_emb\n",
      "model.layers.18.mlp\n",
      "model.layers.18.mlp.gate_proj\n",
      "model.layers.18.mlp.up_proj\n",
      "model.layers.18.mlp.down_proj\n",
      "model.layers.18.mlp.act_fn\n",
      "model.layers.18.input_layernorm\n",
      "model.layers.18.post_attention_layernorm\n",
      "model.layers.19\n",
      "model.layers.19.self_attn\n",
      "model.layers.19.self_attn.q_proj\n",
      "model.layers.19.self_attn.k_proj\n",
      "model.layers.19.self_attn.v_proj\n",
      "model.layers.19.self_attn.o_proj\n",
      "model.layers.19.self_attn.rotary_emb\n",
      "model.layers.19.mlp\n",
      "model.layers.19.mlp.gate_proj\n",
      "model.layers.19.mlp.up_proj\n",
      "model.layers.19.mlp.down_proj\n",
      "model.layers.19.mlp.act_fn\n",
      "model.layers.19.input_layernorm\n",
      "model.layers.19.post_attention_layernorm\n",
      "model.layers.20\n",
      "model.layers.20.self_attn\n",
      "model.layers.20.self_attn.q_proj\n",
      "model.layers.20.self_attn.k_proj\n",
      "model.layers.20.self_attn.v_proj\n",
      "model.layers.20.self_attn.o_proj\n",
      "model.layers.20.self_attn.rotary_emb\n",
      "model.layers.20.mlp\n",
      "model.layers.20.mlp.gate_proj\n",
      "model.layers.20.mlp.up_proj\n",
      "model.layers.20.mlp.down_proj\n",
      "model.layers.20.mlp.act_fn\n",
      "model.layers.20.input_layernorm\n",
      "model.layers.20.post_attention_layernorm\n",
      "model.layers.21\n",
      "model.layers.21.self_attn\n",
      "model.layers.21.self_attn.q_proj\n",
      "model.layers.21.self_attn.k_proj\n",
      "model.layers.21.self_attn.v_proj\n",
      "model.layers.21.self_attn.o_proj\n",
      "model.layers.21.self_attn.rotary_emb\n",
      "model.layers.21.mlp\n",
      "model.layers.21.mlp.gate_proj\n",
      "model.layers.21.mlp.up_proj\n",
      "model.layers.21.mlp.down_proj\n",
      "model.layers.21.mlp.act_fn\n",
      "model.layers.21.input_layernorm\n",
      "model.layers.21.post_attention_layernorm\n",
      "model.layers.22\n",
      "model.layers.22.self_attn\n",
      "model.layers.22.self_attn.q_proj\n",
      "model.layers.22.self_attn.k_proj\n",
      "model.layers.22.self_attn.v_proj\n",
      "model.layers.22.self_attn.o_proj\n",
      "model.layers.22.self_attn.rotary_emb\n",
      "model.layers.22.mlp\n",
      "model.layers.22.mlp.gate_proj\n",
      "model.layers.22.mlp.up_proj\n",
      "model.layers.22.mlp.down_proj\n",
      "model.layers.22.mlp.act_fn\n",
      "model.layers.22.input_layernorm\n",
      "model.layers.22.post_attention_layernorm\n",
      "model.layers.23\n",
      "model.layers.23.self_attn\n",
      "model.layers.23.self_attn.q_proj\n",
      "model.layers.23.self_attn.k_proj\n",
      "model.layers.23.self_attn.v_proj\n",
      "model.layers.23.self_attn.o_proj\n",
      "model.layers.23.self_attn.rotary_emb\n",
      "model.layers.23.mlp\n",
      "model.layers.23.mlp.gate_proj\n",
      "model.layers.23.mlp.up_proj\n",
      "model.layers.23.mlp.down_proj\n",
      "model.layers.23.mlp.act_fn\n",
      "model.layers.23.input_layernorm\n",
      "model.layers.23.post_attention_layernorm\n",
      "model.layers.24\n",
      "model.layers.24.self_attn\n",
      "model.layers.24.self_attn.q_proj\n",
      "model.layers.24.self_attn.k_proj\n",
      "model.layers.24.self_attn.v_proj\n",
      "model.layers.24.self_attn.o_proj\n",
      "model.layers.24.self_attn.rotary_emb\n",
      "model.layers.24.mlp\n",
      "model.layers.24.mlp.gate_proj\n",
      "model.layers.24.mlp.up_proj\n",
      "model.layers.24.mlp.down_proj\n",
      "model.layers.24.mlp.act_fn\n",
      "model.layers.24.input_layernorm\n",
      "model.layers.24.post_attention_layernorm\n",
      "model.layers.25\n",
      "model.layers.25.self_attn\n",
      "model.layers.25.self_attn.q_proj\n",
      "model.layers.25.self_attn.k_proj\n",
      "model.layers.25.self_attn.v_proj\n",
      "model.layers.25.self_attn.o_proj\n",
      "model.layers.25.self_attn.rotary_emb\n",
      "model.layers.25.mlp\n",
      "model.layers.25.mlp.gate_proj\n",
      "model.layers.25.mlp.up_proj\n",
      "model.layers.25.mlp.down_proj\n",
      "model.layers.25.mlp.act_fn\n",
      "model.layers.25.input_layernorm\n",
      "model.layers.25.post_attention_layernorm\n",
      "model.layers.26\n",
      "model.layers.26.self_attn\n",
      "model.layers.26.self_attn.q_proj\n",
      "model.layers.26.self_attn.k_proj\n",
      "model.layers.26.self_attn.v_proj\n",
      "model.layers.26.self_attn.o_proj\n",
      "model.layers.26.self_attn.rotary_emb\n",
      "model.layers.26.mlp\n",
      "model.layers.26.mlp.gate_proj\n",
      "model.layers.26.mlp.up_proj\n",
      "model.layers.26.mlp.down_proj\n",
      "model.layers.26.mlp.act_fn\n",
      "model.layers.26.input_layernorm\n",
      "model.layers.26.post_attention_layernorm\n",
      "model.layers.27\n",
      "model.layers.27.self_attn\n",
      "model.layers.27.self_attn.q_proj\n",
      "model.layers.27.self_attn.k_proj\n",
      "model.layers.27.self_attn.v_proj\n",
      "model.layers.27.self_attn.o_proj\n",
      "model.layers.27.self_attn.rotary_emb\n",
      "model.layers.27.mlp\n",
      "model.layers.27.mlp.gate_proj\n",
      "model.layers.27.mlp.up_proj\n",
      "model.layers.27.mlp.down_proj\n",
      "model.layers.27.mlp.act_fn\n",
      "model.layers.27.input_layernorm\n",
      "model.layers.27.post_attention_layernorm\n",
      "model.layers.28\n",
      "model.layers.28.self_attn\n",
      "model.layers.28.self_attn.q_proj\n",
      "model.layers.28.self_attn.k_proj\n",
      "model.layers.28.self_attn.v_proj\n",
      "model.layers.28.self_attn.o_proj\n",
      "model.layers.28.self_attn.rotary_emb\n",
      "model.layers.28.mlp\n",
      "model.layers.28.mlp.gate_proj\n",
      "model.layers.28.mlp.up_proj\n",
      "model.layers.28.mlp.down_proj\n",
      "model.layers.28.mlp.act_fn\n",
      "model.layers.28.input_layernorm\n",
      "model.layers.28.post_attention_layernorm\n",
      "model.layers.29\n",
      "model.layers.29.self_attn\n",
      "model.layers.29.self_attn.q_proj\n",
      "model.layers.29.self_attn.k_proj\n",
      "model.layers.29.self_attn.v_proj\n",
      "model.layers.29.self_attn.o_proj\n",
      "model.layers.29.self_attn.rotary_emb\n",
      "model.layers.29.mlp\n",
      "model.layers.29.mlp.gate_proj\n",
      "model.layers.29.mlp.up_proj\n",
      "model.layers.29.mlp.down_proj\n",
      "model.layers.29.mlp.act_fn\n",
      "model.layers.29.input_layernorm\n",
      "model.layers.29.post_attention_layernorm\n",
      "model.layers.30\n",
      "model.layers.30.self_attn\n",
      "model.layers.30.self_attn.q_proj\n",
      "model.layers.30.self_attn.k_proj\n",
      "model.layers.30.self_attn.v_proj\n",
      "model.layers.30.self_attn.o_proj\n",
      "model.layers.30.self_attn.rotary_emb\n",
      "model.layers.30.mlp\n",
      "model.layers.30.mlp.gate_proj\n",
      "model.layers.30.mlp.up_proj\n",
      "model.layers.30.mlp.down_proj\n",
      "model.layers.30.mlp.act_fn\n",
      "model.layers.30.input_layernorm\n",
      "model.layers.30.post_attention_layernorm\n",
      "model.layers.31\n",
      "model.layers.31.self_attn\n",
      "model.layers.31.self_attn.q_proj\n",
      "model.layers.31.self_attn.k_proj\n",
      "model.layers.31.self_attn.v_proj\n",
      "model.layers.31.self_attn.o_proj\n",
      "model.layers.31.self_attn.rotary_emb\n",
      "model.layers.31.mlp\n",
      "model.layers.31.mlp.gate_proj\n",
      "model.layers.31.mlp.up_proj\n",
      "model.layers.31.mlp.down_proj\n",
      "model.layers.31.mlp.act_fn\n",
      "model.layers.31.input_layernorm\n",
      "model.layers.31.post_attention_layernorm\n",
      "model.norm\n",
      "lm_head\n"
     ]
    }
   ],
   "source": [
    "for name, _ in model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64d44163",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T06:39:31.475693Z",
     "start_time": "2024-05-25T06:39:31.471113Z"
    }
   },
   "outputs": [],
   "source": [
    "hooks = {name: TimerHook() for name, _ in model.named_modules() if isinstance(_, LlamaDecoderLayer)}\n",
    "hook_handles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a24e231",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T06:39:31.485507Z",
     "start_time": "2024-05-25T06:39:31.478557Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29717c16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T06:39:31.496910Z",
     "start_time": "2024-05-25T06:39:31.487636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458db80>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458db80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d1f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d3d0>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458db80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d1f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d7f0>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458db80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d1f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d7f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dc40>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458db80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d1f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d7f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dc40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dca0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dee0>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458db80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d1f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d7f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dc40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dca0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458df40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dac0>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458db80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d1f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d7f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dc40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dca0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458df40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045702b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045706d0>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458db80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d1f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d7f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dc40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dca0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458df40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045702b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045706d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570670>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570c70>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458db80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d1f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d7f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dc40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dca0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458df40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045702b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045706d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570670>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570c70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c1b2f5550>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fd0>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458db80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d1f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d7f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dc40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dca0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458df40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045702b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045706d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570670>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570c70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c1b2f5550>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8eb0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fa0>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458db80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d1f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d7f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dc40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dca0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458df40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045702b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045706d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570670>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570c70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c1b2f5550>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8eb0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fa0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9040>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c90a0>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458db80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d1f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d7f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dc40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dca0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458df40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045702b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045706d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570670>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570c70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c1b2f5550>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8eb0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fa0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9040>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c90a0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9100>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9160>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458db80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d1f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d7f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dc40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dca0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458df40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045702b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045706d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570670>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570c70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c1b2f5550>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8eb0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fa0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9040>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c90a0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9100>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9160>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c91c0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9220>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458db80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d1f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d7f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dc40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dca0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458df40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045702b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045706d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570670>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570c70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c1b2f5550>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8eb0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fa0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9040>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c90a0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9100>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9160>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c91c0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9220>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9280>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c92e0>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458db80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d1f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d7f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dc40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dca0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458df40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045702b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045706d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570670>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570c70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c1b2f5550>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8eb0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fa0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9040>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c90a0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9100>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9160>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c91c0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9220>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9280>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c92e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9340>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c93a0>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458db80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d1f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d7f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dc40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dca0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458df40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045702b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045706d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570670>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570c70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c1b2f5550>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8eb0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fa0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9040>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c90a0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9100>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9160>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c91c0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9220>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9280>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c92e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9340>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c93a0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9400>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9460>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458db80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d1f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d7f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dc40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dca0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458df40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045702b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045706d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570670>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570c70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c1b2f5550>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8eb0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fa0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9040>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c90a0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9100>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9160>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c91c0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9220>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9280>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c92e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9340>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c93a0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9400>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9460>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c94c0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9520>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458db80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d1f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d7f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dc40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dca0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458df40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045702b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045706d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570670>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570c70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c1b2f5550>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8eb0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fa0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9040>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c90a0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9100>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9160>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c91c0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9220>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9280>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c92e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9340>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c93a0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9400>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9460>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c94c0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c95e0>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458db80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d1f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d7f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dc40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dca0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458df40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045702b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045706d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570670>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570c70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c1b2f5550>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8eb0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fa0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9040>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c90a0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9100>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9160>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c91c0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9220>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9280>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c92e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9340>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c93a0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9400>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9460>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c94c0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c95e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c96a0>]\n",
      "[<torch.utils.hooks.RemovableHandle object at 0x7f8c045ddbe0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd30>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd2b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddd90>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd190>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd8e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045dd520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddcd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045ddc70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052904f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290c10>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290dc0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e50>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290e20>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290f70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c05290ac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dd60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da00>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d850>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458db80>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d1f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d3d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458d7f0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458da60>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dc40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dca0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dee0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458df40>, <torch.utils.hooks.RemovableHandle object at 0x7f8c0458dac0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045702b0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c045706d0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570670>, <torch.utils.hooks.RemovableHandle object at 0x7f8c04570c70>, <torch.utils.hooks.RemovableHandle object at 0x7f8c1b2f5550>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fd0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8eb0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c980a8fa0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9040>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c90a0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9100>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9160>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c91c0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9220>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9280>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c92e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9340>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c93a0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9400>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9460>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c94c0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9520>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9580>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c95e0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9640>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c96a0>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9700>, <torch.utils.hooks.RemovableHandle object at 0x7f8c052c9760>]\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, LlamaDecoderLayer):\n",
    "        pre_hook_handle = module.register_forward_pre_hook(hooks[name].pre_hook)\n",
    "        forward_hook_handle = module.register_forward_hook(hooks[name].forward_hook)\n",
    "        hook_handles.extend([pre_hook_handle, forward_hook_handle])\n",
    "        print(hook_handles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db63ad66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T06:39:31.506751Z",
     "start_time": "2024-05-25T06:39:31.499108Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module: model.layers.0\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c1b2f5520>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c1b2f5520>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.1\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c1b2f53a0>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c1b2f53a0>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.2\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c1b2f5760>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c1b2f5760>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.3\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c1b3bf700>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c1b3bf700>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.4\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c1b3bf4c0>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c1b3bf4c0>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.5\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c82577130>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c82577130>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.6\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c82577790>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c82577790>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.7\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c980a8af0>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c980a8af0>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.8\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c980a8a90>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c980a8a90>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.9\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c980a8940>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c980a8940>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.10\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c980a89a0>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c980a89a0>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.11\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c980a8e80>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c980a8e80>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.12\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c980a8be0>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c980a8be0>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.13\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c980a8730>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c980a8730>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.14\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c980a8700>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c980a8700>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.15\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c980a8d00>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c980a8d00>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.16\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c980a87f0>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c980a87f0>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.17\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c980a87c0>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c980a87c0>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.18\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c980a8760>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c980a8760>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.19\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c980a8c40>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c980a8c40>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.20\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c980a86d0>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c980a86d0>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.21\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c980a8b80>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c980a8b80>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.22\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c980a8c10>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c980a8c10>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.23\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c980a8b50>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c980a8b50>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.24\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c9846d0a0>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c9846d0a0>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.25\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c831a0130>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c831a0130>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.26\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c831a00d0>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c831a00d0>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.27\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c1c375a90>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c1c375a90>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.28\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c8318dac0>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c8318dac0>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.29\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c8318dbb0>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c8318dbb0>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.30\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c045700d0>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c045700d0>>\n",
      "Backward Hooks:\n",
      "Module: model.layers.31\n",
      "Forward Hooks:\n",
      "<bound method TimerHook.forward_hook of <__main__.TimerHook object at 0x7f8c04570df0>>\n",
      "Forward Pre Hooks:\n",
      "<bound method TimerHook.pre_hook of <__main__.TimerHook object at 0x7f8c04570df0>>\n",
      "Backward Hooks:\n"
     ]
    }
   ],
   "source": [
    "def print_hooks(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if module._forward_hooks or module._forward_pre_hooks or module._backward_hooks:\n",
    "            print(f'Module: {name}')\n",
    "            print('Forward Hooks:')\n",
    "            for hook in module._forward_hooks.values():\n",
    "                print(hook)\n",
    "            print('Forward Pre Hooks:')\n",
    "            for hook in module._forward_pre_hooks.values():\n",
    "                print(hook)\n",
    "            print('Backward Hooks:')\n",
    "            for hook in module._backward_hooks.values():\n",
    "                print(hook)\n",
    "print_hooks(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e5b6a62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T06:40:10.757089Z",
     "start_time": "2024-05-25T06:39:31.508748Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "Prehook recorded\n",
      "Post Hook recorded\n",
      "\n",
      "A large language model (LLM) is a type of artificial intelligence (AI) model that is trained on a large amount of text data to generate human-like text. LLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation.\n",
      "What is the difference between a large language model and a small language model?\n",
      "A large language model is a type of artificial intelligence (AI) model that is trained on a large amount of text data to generate human-like text. LLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation. A small language model is a type of artificial intelligence (AI) model that is trained on a small amount of text data to generate human-like text. SLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation.\n",
      "What are the benefits of using a large language model?\n",
      "The benefits of using a large language model include:\n",
      "1. Improved accuracy: LLMs are trained on a large amount of text data, which allows them to generate more accurate text than smaller models.\n",
      "2. Increased efficiency: LLMs are typically faster than smaller models, which can save time and resources.\n",
      "3. Greater flexibility: LLMs can be used for a variety of tasks, such as natural language processing (NLP), machine translation, and text generation.\n",
      "4. Improved scalability: LLMs can be easily scaled up to handle larger amounts of text data.\n",
      "5. Greater versatility: LLMs can be used for a variety of tasks, such as natural language processing (NLP), machine translation, and text generation.\n",
      "What are the challenges of using a large language model?\n",
      "The challenges of using a large language model include:\n",
      "1. Increased complexity: LLMs are typically more complex than smaller models, which can make them more difficult to use.\n",
      "2. Increased cost: LLMs are typically more expensive to train and maintain than smaller models.\n",
      "3. Increased time: LLMs are typically slower than smaller models, which can increase the time required to complete tasks.\n",
      "4. Increased resources: LLMs require more resources, such as memory and processing power, than smaller models.\n",
      "5. Increased risk: LLMs are typically more pr\n",
      "Elapsed time: 39247.08984375 ms\n"
     ]
    }
   ],
   "source": [
    "# Create events for the start and end times\n",
    "start_event = torch.cuda.Event(enable_timing=True)\n",
    "end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start_event.record()\n",
    "\n",
    "# Your code here\n",
    "results = gen_text([\"What is a large language model?\"], pipeline, tokenizer, temperature=0.5, max_new_tokens=512, use_template=use_template)\n",
    "print(results[0])\n",
    "\n",
    "end_event.record()\n",
    "\n",
    "# Wait for all operations to finish before measuring the time\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# Calculate and print the elapsed time\n",
    "elapsed_time = start_event.elapsed_time(end_event)  # Time in milliseconds\n",
    "print(f'Elapsed time: {elapsed_time} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a2bc7f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T06:40:10.765219Z",
     "start_time": "2024-05-25T06:40:10.759973Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time:  1592082.4680924416\n",
      "Count:  512\n",
      "Average time for model.layers.0: 3109.53607049305 milliseconds\n",
      "Total Time:  1146662.913262844\n",
      "Count:  512\n",
      "Average time for model.layers.1: 2239.5760024664924 milliseconds\n",
      "Total Time:  1125716.9921398163\n",
      "Count:  512\n",
      "Average time for model.layers.2: 2198.6660002730787 milliseconds\n",
      "Total Time:  1106977.7913689613\n",
      "Count:  512\n",
      "Average time for model.layers.3: 2162.0659987675026 milliseconds\n",
      "Total Time:  1103168.5115098953\n",
      "Count:  512\n",
      "Average time for model.layers.4: 2154.6259990427643 milliseconds\n",
      "Total Time:  1113137.1515393257\n",
      "Count:  512\n",
      "Average time for model.layers.5: 2174.0959991002455 milliseconds\n",
      "Total Time:  1096453.0888795853\n",
      "Count:  512\n",
      "Average time for model.layers.6: 2141.50993921794 milliseconds\n",
      "Total Time:  1086970.878958702\n",
      "Count:  512\n",
      "Average time for model.layers.7: 2122.989997966215 milliseconds\n",
      "Total Time:  1131537.4071598053\n",
      "Count:  512\n",
      "Average time for model.layers.8: 2210.0339983589947 milliseconds\n",
      "Total Time:  1117086.7201685905\n",
      "Count:  512\n",
      "Average time for model.layers.9: 2181.8100003292784 milliseconds\n",
      "Total Time:  1117239.294409752\n",
      "Count:  512\n",
      "Average time for model.layers.10: 2182.1079968940467 milliseconds\n",
      "Total Time:  1107898.3662724495\n",
      "Count:  512\n",
      "Average time for model.layers.11: 2163.863996625878 milliseconds\n",
      "Total Time:  1119809.5059394836\n",
      "Count:  512\n",
      "Average time for model.layers.12: 2187.127941288054 milliseconds\n",
      "Total Time:  1117336.5743756294\n",
      "Count:  512\n",
      "Average time for model.layers.13: 2182.297996827401 milliseconds\n",
      "Total Time:  1116991.4897084236\n",
      "Count:  512\n",
      "Average time for model.layers.14: 2181.624003336765 milliseconds\n",
      "Total Time:  1130707.9667448997\n",
      "Count:  512\n",
      "Average time for model.layers.15: 2208.4139975486323 milliseconds\n",
      "Total Time:  1112558.5909485817\n",
      "Count:  512\n",
      "Average time for model.layers.16: 2172.9659979464486 milliseconds\n",
      "Total Time:  1110204.4141888618\n",
      "Count:  512\n",
      "Average time for model.layers.17: 2168.367996462621 milliseconds\n",
      "Total Time:  1108492.2904968262\n",
      "Count:  512\n",
      "Average time for model.layers.18: 2165.0240048766136 milliseconds\n",
      "Total Time:  1126699.0082859993\n",
      "Count:  512\n",
      "Average time for model.layers.19: 2200.5840005585924 milliseconds\n",
      "Total Time:  1106388.9907598495\n",
      "Count:  512\n",
      "Average time for model.layers.20: 2160.915997577831 milliseconds\n",
      "Total Time:  1124902.913570404\n",
      "Count:  512\n",
      "Average time for model.layers.21: 2197.0760030671954 milliseconds\n",
      "Total Time:  1105214.4613862038\n",
      "Count:  512\n",
      "Average time for model.layers.22: 2158.6219948949292 milliseconds\n",
      "Total Time:  1099462.6879096031\n",
      "Count:  512\n",
      "Average time for model.layers.23: 2147.3880623234436 milliseconds\n",
      "Total Time:  1133058.0498576164\n",
      "Count:  512\n",
      "Average time for model.layers.24: 2213.004003628157 milliseconds\n",
      "Total Time:  1101160.4440808296\n",
      "Count:  512\n",
      "Average time for model.layers.25: 2150.7039923453704 milliseconds\n",
      "Total Time:  1123123.2029795647\n",
      "Count:  512\n",
      "Average time for model.layers.26: 2193.6000058194622 milliseconds\n",
      "Total Time:  1122945.0229406357\n",
      "Count:  512\n",
      "Average time for model.layers.27: 2193.251997930929 milliseconds\n",
      "Total Time:  1137968.1290984154\n",
      "Count:  512\n",
      "Average time for model.layers.28: 2222.5940021453425 milliseconds\n",
      "Total Time:  1107702.783048153\n",
      "Count:  512\n",
      "Average time for model.layers.29: 2163.4819981409237 milliseconds\n",
      "Total Time:  1129124.86410141\n",
      "Count:  512\n",
      "Average time for model.layers.30: 2205.3220001980662 milliseconds\n",
      "Total Time:  1161721.8565940857\n",
      "Count:  512\n",
      "Average time for model.layers.31: 2268.9880011603236 milliseconds\n"
     ]
    }
   ],
   "source": [
    "layers = []\n",
    "for name, hook in hooks.items():\n",
    "    avg = hook.get_average_time()\n",
    "    print(f'Average time for {name}: {avg} milliseconds')\n",
    "    layers.append(avg)\n",
    "print(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e33170be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T06:36:48.096364Z",
     "start_time": "2024-05-25T06:36:48.093218Z"
    }
   },
   "outputs": [],
   "source": [
    "# When you're done, you can remove the hooks like this:\n",
    "for handle in hook_handles:\n",
    "    handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "571ca926",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T06:47:58.302618Z",
     "start_time": "2024-05-25T06:47:58.290971Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "514"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode(results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9844bf75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T06:37:56.427255Z",
     "start_time": "2024-05-25T06:37:56.421440Z"
    }
   },
   "outputs": [],
   "source": [
    "print_hooks(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9528e5ca",
   "metadata": {},
   "source": [
    "# Layer time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a88e9eac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:31.486641Z",
     "start_time": "2024-06-11T04:34:31.480682Z"
    },
    "code_folding": [
     2
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from transformers.models.llama.modeling_llama import LlamaAttention, LlamaDecoderLayer, LlamaMLP, LlamaConfig, LlamaDecoderLayer\n",
    "\n",
    "class TimerHook:\n",
    "    def __init__(self):\n",
    "        self.start_event = torch.cuda.Event(enable_timing=True)\n",
    "        self.end_event = torch.cuda.Event(enable_timing=True)\n",
    "        self.total_time = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def pre_hook(self, module, input):\n",
    "#         print(\"Prehook recorded\")\n",
    "        self.start_event.record()\n",
    "\n",
    "    def forward_hook(self, module, input, output):\n",
    "#         print(\"Post Hook recorded\")\n",
    "        self.end_event.record()\n",
    "        # Wait for all operations to finish before measuring the time\n",
    "        torch.cuda.synchronize()\n",
    "        # elapsed_time gives time in milliseconds. Multiply by 1000 for microseconds.\n",
    "        self.total_time += self.start_event.elapsed_time(self.end_event) * 1000\n",
    "        self.count += 1\n",
    "\n",
    "    def get_average_time(self):\n",
    "#         print(\"Total Time: \", self.total_time)\n",
    "#         print(\"Count: \", self.count)\n",
    "        return self.total_time / self.count if self.count > 0 else 0\n",
    "    def print_params(self):\n",
    "        return \"Total Time: {}, Count: {}\".format(self.total_time, self.count)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.total_time = 0\n",
    "        self.count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea66d0f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T04:34:31.504986Z",
     "start_time": "2024-06-11T04:34:31.488449Z"
    },
    "code_folding": [],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "class LayerAnalysis:\n",
    "    def __init__(self, pipeline, tokenizer, pruning_dict, \n",
    "                 inputs=None, save_dir=None, output_dir=None, \n",
    "                 ignore_layers=None, use_template=False):\n",
    "        self.pipeline = pipeline\n",
    "        self.model = pipeline.model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pruning_dict = pruning_dict\n",
    "        \n",
    "        ### Hooks\n",
    "        self.hooks = None\n",
    "        self.hook_handles = None\n",
    "        \n",
    "        \n",
    "        self.experiment =  ExperimentRunner(pipeline, \n",
    "                                            tokenizer, pruning_dict, \n",
    "                                            save_dir=save_dir, \n",
    "                                            output_dir=output_dir, \n",
    "                                            ignored_layers=None, \n",
    "                                            use_template=use_template)\n",
    "        \n",
    "        ### Generation Inputs\n",
    "        if inputs is not None:\n",
    "            self.inputs = inputs \n",
    "            print(\"Received {} inputs\".format(len(self.inputs)))\n",
    "        else:\n",
    "            self.inputs = [\"What is a large language model?\"]\n",
    "        \n",
    "        self.layers = {i:[] for i in range(32)}\n",
    "        \n",
    "    def register_layer_hooks(self):\n",
    "        self.hooks = {name: TimerHook() for name, _ in self.model.named_modules() if isinstance(_, LlamaDecoderLayer)}\n",
    "        self.hook_handles = []\n",
    "        \n",
    "        for name, module in self.model.named_modules():\n",
    "            if isinstance(module, LlamaDecoderLayer):\n",
    "                pre_hook_handle = module.register_forward_pre_hook(self.hooks[name].pre_hook)\n",
    "                forward_hook_handle = module.register_forward_hook(self.hooks[name].forward_hook)\n",
    "                self.hook_handles.extend([pre_hook_handle, forward_hook_handle])\n",
    "        print(\"Total Hooks registerd: \", self.num_hooks_registered())\n",
    "        \n",
    "    def num_hooks_registered(self):\n",
    "        return len(self.hook_handles)\n",
    "    \n",
    "    def remove_hooks(self):\n",
    "        for handle in self.hook_handles:\n",
    "            handle.remove()\n",
    "            \n",
    "    def print_layers(self):\n",
    "        for key, val in self.layers.items():\n",
    "            print(\"| Layer {}: {}\".format(key, \"\\t|\".join(str(round(i,2)) for i in val)))\n",
    "                \n",
    "                \n",
    "    def update_layers_stats(self):\n",
    "        i = 0\n",
    "        for name, hook in self.hooks.items():\n",
    "            avg = hook.get_average_time()\n",
    "            self.layers[i].append(avg)\n",
    "            i += 1\n",
    "    \n",
    "    def print_summary(self):\n",
    "        self.print_layers()\n",
    "\n",
    "    def prune_model(self):\n",
    "        self.experiment.prune_model(real=True)\n",
    "    \n",
    "    def reset_hooks(self):\n",
    "        for name, hook in self.hooks.items():\n",
    "            hook.reset()\n",
    "        \n",
    "        ## Test\n",
    "        for name, hook in self.hooks.items():\n",
    "            hook.print_params()\n",
    "        \n",
    "        \n",
    "    def generate(self, inp):\n",
    "        # Create events for the start and end times\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "        # Your code here\n",
    "        print(\"-----\" * 10, \"\\n\")\n",
    "        print(\"Prompt: {}\".format(inp))\n",
    "        \n",
    "        start_event.record()\n",
    "        results = gen_text([inp], self.pipeline, self.tokenizer, temperature=0.5, max_new_tokens=512, use_template=use_template)\n",
    "        print(\"=> \", results[0])\n",
    "        \n",
    "        \n",
    "\n",
    "        end_event.record()\n",
    "        # Wait for all operations to finish before measuring the time\n",
    "        torch.cuda.synchronize()\n",
    "        print(\"-----\" * 10, \"\\n\\n\")\n",
    "        # Calculate and print the elapsed time\n",
    "        elapsed_time = start_event.elapsed_time(end_event)  # Time in milliseconds\n",
    "        print(f'Elapsed time: {elapsed_time} ms')\n",
    "        \n",
    "        \n",
    "    \n",
    "    def print_hooks(self):\n",
    "        for name, module in self.model.named_modules():\n",
    "            if module._forward_hooks or module._forward_pre_hooks or module._backward_hooks:\n",
    "                print(f'Module: {name}')\n",
    "                print('Forward Hooks:')\n",
    "                for hook in module._forward_hooks.values():\n",
    "                    print(hook)\n",
    "                print('Forward Pre Hooks:')\n",
    "                for hook in module._forward_pre_hooks.values():\n",
    "                    print(hook)\n",
    "                print('Backward Hooks:')\n",
    "                for hook in module._backward_hooks.values():\n",
    "                    print(hook)\n",
    "    def run(self):\n",
    "        self.register_layer_hooks()\n",
    "        print(\"Hooks Registered: \", self.num_hooks_registered())\n",
    "        if len(self.inputs) > 1:\n",
    "            for inp in self.inputs:\n",
    "                for i in range(6):\n",
    "                    self.generate(inp)\n",
    "                    self.update_layers_stats()\n",
    "                    self.reset_hooks()\n",
    "        else:\n",
    "            self.generate(self.inputs[0])\n",
    "            self.update_layers_stats()\n",
    "            self.reset_hooks()\n",
    "        self.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "747bf708",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T06:25:01.490863Z",
     "start_time": "2024-06-05T06:24:33.553549Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 11:54:34.775376: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-05 11:54:35.875349: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ba5087b13d42aaa3659ac2a9db13f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(hf_llama_path, padding_side=\"left\", padding=True, truncation=True)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=hf_llama_path,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "#     revision=revision,\n",
    "    return_full_text=False\n",
    ")\n",
    "\n",
    "# Required tokenizer setting for batch inference\n",
    "pipeline.tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "model = pipeline.model\n",
    "model.seqlen = model.config.max_position_embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a56f850d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T06:27:20.824867Z",
     "start_time": "2024-06-05T06:27:20.816283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "11 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "19 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "25 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "33 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "39 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "47 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "53 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "61 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "67 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "75 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "81 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "89 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "95 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "103 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "109 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "117 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "123 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "131 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "137 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "145 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "151 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "159 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "165 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "173 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "179 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "187 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "193 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "201 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "207 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "215 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "221 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "229 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "235 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "243 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "249 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "257 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "263 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "271 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "277 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "285 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "291 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "299 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "305 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "313 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "319 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "327 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "333 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "341 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "347 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "355 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "361 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "369 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "375 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "383 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "389 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "397 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "403 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "411 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "417 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "425 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "431 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "439 \t LlamaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "445 \t LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for i, mod in enumerate(pipeline.model.modules()):\n",
    "    if isinstance(mod, LlamaMLP) or isinstance(mod, LlamaAttention):\n",
    "        print(i, \"\\t\", mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bea178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad95853f",
   "metadata": {},
   "source": [
    "## Unpruned Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9183d38d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T08:50:10.999214Z",
     "start_time": "2024-05-25T08:50:10.995128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received 3 inputs\n"
     ]
    }
   ],
   "source": [
    "pruning_dict = None\n",
    "\n",
    "inputs = [\"What is a large language model?\",\n",
    "          \"Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could\", \n",
    "          \"The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future\"]\n",
    "\n",
    "unpruned = LayerAnalysis(pipeline, tokenizer, pruning_dict, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c937ea77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T09:02:26.857830Z",
     "start_time": "2024-05-25T08:50:11.537072Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Hooks registerd:  64\n",
      "Hooks Registered:  64\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: What is a large language model?\n",
      "=>  \n",
      "A large language model (LLM) is a type of artificial intelligence (AI) model that is trained on a large amount of text data to generate human-like text. LLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation.\n",
      "What is the difference between a large language model and a small language model?\n",
      "A large language model is a type of artificial intelligence (AI) model that is trained on a large amount of text data to generate human-like text. LLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation. A small language model is a type of artificial intelligence (AI) model that is trained on a small amount of text data to generate human-like text. SLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation.\n",
      "What are the benefits of using a large language model?\n",
      "The benefits of using a large language model include:\n",
      "1. Improved accuracy: LLMs are trained on a large amount of text data, which allows them to generate more accurate text than smaller models.\n",
      "2. Increased efficiency: LLMs are typically faster than smaller models, which can save time and resources.\n",
      "3. Greater flexibility: LLMs can be used for a variety of tasks, such as natural language processing (NLP), machine translation, and text generation.\n",
      "4. Improved scalability: LLMs can be easily scaled up to handle larger amounts of text data.\n",
      "5. Greater versatility: LLMs can be used for a variety of tasks, such as natural language processing (NLP), machine translation, and text generation.\n",
      "What are the challenges of using a large language model?\n",
      "The challenges of using a large language model include:\n",
      "1. Increased complexity: LLMs are typically more complex than smaller models, which can make them more difficult to use.\n",
      "2. Increased cost: LLMs are typically more expensive to train and maintain than smaller models.\n",
      "3. Increased time: LLMs are typically slower than smaller models, which can increase the time required to complete tasks.\n",
      "4. Increased resources: LLMs require more resources, such as memory and processing power, than smaller models.\n",
      "5. Increased risk: LLMs are typically more pr\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 40836.18359375 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: What is a large language model?\n",
      "=>  \n",
      "A large language model (LLM) is a type of artificial intelligence (AI) model that is trained on a large amount of text data to generate human-like text. LLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation.\n",
      "What is the difference between a large language model and a small language model?\n",
      "A large language model is a type of artificial intelligence (AI) model that is trained on a large amount of text data to generate human-like text. LLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation. A small language model is a type of artificial intelligence (AI) model that is trained on a small amount of text data to generate human-like text. SLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation.\n",
      "What are the benefits of using a large language model?\n",
      "The benefits of using a large language model include:\n",
      "1. Improved accuracy: LLMs are trained on a large amount of text data, which allows them to generate more accurate text than smaller models.\n",
      "2. Increased efficiency: LLMs are typically faster than smaller models, which can save time and resources.\n",
      "3. Greater flexibility: LLMs can be used for a variety of tasks, such as natural language processing (NLP), machine translation, and text generation.\n",
      "4. Improved scalability: LLMs can be easily scaled up to handle larger amounts of text data.\n",
      "5. Greater versatility: LLMs can be used for a variety of tasks, such as natural language processing (NLP), machine translation, and text generation.\n",
      "What are the challenges of using a large language model?\n",
      "The challenges of using a large language model include:\n",
      "1. Increased complexity: LLMs are typically more complex than smaller models, which can make them more difficult to use.\n",
      "2. Increased cost: LLMs are typically more expensive to train and maintain than smaller models.\n",
      "3. Increased time: LLMs are typically slower than smaller models, which can increase the time required to complete tasks.\n",
      "4. Increased resources: LLMs require more resources, such as memory and processing power, than smaller models.\n",
      "5. Increased risk: LLMs are typically more pr\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 40893.234375 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: What is a large language model?\n",
      "=>  \n",
      "A large language model (LLM) is a type of artificial intelligence (AI) model that is trained on a large amount of text data to generate human-like text. LLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation.\n",
      "What is the difference between a large language model and a small language model?\n",
      "A large language model is a type of artificial intelligence (AI) model that is trained on a large amount of text data to generate human-like text. LLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation. A small language model is a type of artificial intelligence (AI) model that is trained on a small amount of text data to generate human-like text. SLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation.\n",
      "What are the benefits of using a large language model?\n",
      "The benefits of using a large language model include:\n",
      "1. Improved accuracy: LLMs are trained on a large amount of text data, which allows them to generate more accurate text than smaller models.\n",
      "2. Increased efficiency: LLMs are typically faster than smaller models, which can save time and resources.\n",
      "3. Greater flexibility: LLMs can be used for a variety of tasks, such as natural language processing (NLP), machine translation, and text generation.\n",
      "4. Improved scalability: LLMs can be easily scaled up to handle larger amounts of text data.\n",
      "5. Greater versatility: LLMs can be used for a variety of tasks, such as natural language processing (NLP), machine translation, and text generation.\n",
      "What are the challenges of using a large language model?\n",
      "The challenges of using a large language model include:\n",
      "1. Increased complexity: LLMs are typically more complex than smaller models, which can make them more difficult to use.\n",
      "2. Increased cost: LLMs are typically more expensive to train and maintain than smaller models.\n",
      "3. Increased time: LLMs are typically slower than smaller models, which can increase the time required to complete tasks.\n",
      "4. Increased resources: LLMs require more resources, such as memory and processing power, than smaller models.\n",
      "5. Increased risk: LLMs are typically more pr\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 41561.1640625 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: What is a large language model?\n",
      "=>  \n",
      "A large language model (LLM) is a type of artificial intelligence (AI) model that is trained on a large amount of text data to generate human-like text. LLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation.\n",
      "What is the difference between a large language model and a small language model?\n",
      "A large language model is a type of artificial intelligence (AI) model that is trained on a large amount of text data to generate human-like text. LLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation. A small language model is a type of artificial intelligence (AI) model that is trained on a small amount of text data to generate human-like text. SLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation.\n",
      "What are the benefits of using a large language model?\n",
      "The benefits of using a large language model include:\n",
      "1. Improved accuracy: LLMs are trained on a large amount of text data, which allows them to generate more accurate text than smaller models.\n",
      "2. Increased efficiency: LLMs are typically faster than smaller models, which can save time and resources.\n",
      "3. Greater flexibility: LLMs can be used for a variety of tasks, such as natural language processing (NLP), machine translation, and text generation.\n",
      "4. Improved scalability: LLMs can be easily scaled up to handle larger amounts of text data.\n",
      "5. Greater versatility: LLMs can be used for a variety of tasks, such as natural language processing (NLP), machine translation, and text generation.\n",
      "What are the challenges of using a large language model?\n",
      "The challenges of using a large language model include:\n",
      "1. Increased complexity: LLMs are typically more complex than smaller models, which can make them more difficult to use.\n",
      "2. Increased cost: LLMs are typically more expensive to train and maintain than smaller models.\n",
      "3. Increased time: LLMs are typically slower than smaller models, which can increase the time required to complete tasks.\n",
      "4. Increased resources: LLMs require more resources, such as memory and processing power, than smaller models.\n",
      "5. Increased risk: LLMs are typically more pr\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 39325.39453125 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: What is a large language model?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>  \n",
      "A large language model (LLM) is a type of artificial intelligence (AI) model that is trained on a large amount of text data to generate human-like text. LLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation.\n",
      "What is the difference between a large language model and a small language model?\n",
      "A large language model is a type of artificial intelligence (AI) model that is trained on a large amount of text data to generate human-like text. LLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation. A small language model is a type of artificial intelligence (AI) model that is trained on a small amount of text data to generate human-like text. SLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation.\n",
      "What are the benefits of using a large language model?\n",
      "The benefits of using a large language model include:\n",
      "1. Improved accuracy: LLMs are trained on a large amount of text data, which allows them to generate more accurate text than smaller models.\n",
      "2. Increased efficiency: LLMs are typically faster than smaller models, which can save time and resources.\n",
      "3. Greater flexibility: LLMs can be used for a variety of tasks, such as natural language processing (NLP), machine translation, and text generation.\n",
      "4. Improved scalability: LLMs can be easily scaled up to handle larger amounts of text data.\n",
      "5. Greater versatility: LLMs can be used for a variety of tasks, such as natural language processing (NLP), machine translation, and text generation.\n",
      "What are the challenges of using a large language model?\n",
      "The challenges of using a large language model include:\n",
      "1. Increased complexity: LLMs are typically more complex than smaller models, which can make them more difficult to use.\n",
      "2. Increased cost: LLMs are typically more expensive to train and maintain than smaller models.\n",
      "3. Increased time: LLMs are typically slower than smaller models, which can increase the time required to complete tasks.\n",
      "4. Increased resources: LLMs require more resources, such as memory and processing power, than smaller models.\n",
      "5. Increased risk: LLMs are typically more pr\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 38918.71484375 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: What is a large language model?\n",
      "=>  \n",
      "A large language model (LLM) is a type of artificial intelligence (AI) model that is trained on a large amount of text data to generate human-like text. LLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation.\n",
      "What is the difference between a large language model and a small language model?\n",
      "A large language model is a type of artificial intelligence (AI) model that is trained on a large amount of text data to generate human-like text. LLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation. A small language model is a type of artificial intelligence (AI) model that is trained on a small amount of text data to generate human-like text. SLMs are typically used for tasks such as natural language processing (NLP), machine translation, and text generation.\n",
      "What are the benefits of using a large language model?\n",
      "The benefits of using a large language model include:\n",
      "1. Improved accuracy: LLMs are trained on a large amount of text data, which allows them to generate more accurate text than smaller models.\n",
      "2. Increased efficiency: LLMs are typically faster than smaller models, which can save time and resources.\n",
      "3. Greater flexibility: LLMs can be used for a variety of tasks, such as natural language processing (NLP), machine translation, and text generation.\n",
      "4. Improved scalability: LLMs can be easily scaled up to handle larger amounts of text data.\n",
      "5. Greater versatility: LLMs can be used for a variety of tasks, such as natural language processing (NLP), machine translation, and text generation.\n",
      "What are the challenges of using a large language model?\n",
      "The challenges of using a large language model include:\n",
      "1. Increased complexity: LLMs are typically more complex than smaller models, which can make them more difficult to use.\n",
      "2. Increased cost: LLMs are typically more expensive to train and maintain than smaller models.\n",
      "3. Increased time: LLMs are typically slower than smaller models, which can increase the time required to complete tasks.\n",
      "4. Increased resources: LLMs require more resources, such as memory and processing power, than smaller models.\n",
      "5. Increased risk: LLMs are typically more pr\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 40321.23046875 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could\n",
      "=>   potentially break many of the cryptographic algorithms currently in use.\n",
      "However, there are also potential benefits to quantum computing for cryptography. For example, quantum algorithms could be used to create more secure cryptographic algorithms that are resistant to quantum attacks. Additionally, quantum computing could be used to create more efficient cryptographic protocols that require less computation and energy.\n",
      "Overall, the impact of quantum computing on cryptography is still uncertain. However, it is clear that quantum computing has the potential to revolutionize the field of cryptography and could have a significant impact on the security of our digital communications.\n",
      "The Impact of Quantum Computing on Cryptography\n",
      "Quantum computing is a rapidly developing field of computer science that has the potential to revolutionize the way we think about computing. One of the most exciting applications of quantum computing is its potential to revolutionize cryptography.\n",
      "Cryptography is the practice of securing communications and data by encrypting them so that only authorized parties can read them. It is a critical component of modern security systems, and it is essential for protecting sensitive information from unauthorized access.\n",
      "Quantum computing has the potential to revolutionize cryptography in several ways. First, it can enable the development of more secure cryptographic algorithms. Quantum computers are capable of performing complex calculations much faster than classical computers, and this speed advantage can be used to create more secure cryptographic algorithms.\n",
      "Second, quantum computing can enable the development of more efficient cryptographic protocols. Quantum computers are capable of performing complex calculations much faster than classical computers, and this speed advantage can be used to create more efficient cryptographic protocols.\n",
      "Third, quantum computing can enable the development of more secure cryptographic systems. Quantum computers are capable of performing complex calculations much faster than classical computers, and this speed advantage can be used to create more secure cryptographic systems.\n",
      "Overall, quantum computing has the potential to revolutionize cryptography in several ways. It can enable the development of more secure cryptographic algorithms, more efficient cryptographic protocols, and more secure cryptographic systems. As quantum computing continues to develop, it is likely that it will have a significant impact on the field of cryptography.\n",
      "The Impact of Quantum Computing on Cryptography: A Comprehensive Overview\n",
      "Quantum computing is a rapidly developing field of computer science that has the potential to revolutionize the way we think about computing. One of the most exciting applications\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 41044.09765625 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>   potentially break many of the cryptographic algorithms currently in use.\n",
      "However, there are also potential benefits to quantum computing for cryptography. For example, quantum algorithms could be used to create more secure cryptographic algorithms that are resistant to quantum attacks. Additionally, quantum computing could be used to create more efficient cryptographic protocols that require less computation and energy.\n",
      "Overall, the impact of quantum computing on cryptography is still uncertain. However, it is clear that quantum computing has the potential to revolutionize the field of cryptography and could have a significant impact on the security of our digital communications.\n",
      "The Impact of Quantum Computing on Cryptography\n",
      "Quantum computing is a rapidly developing field of computer science that has the potential to revolutionize the way we think about computing. One of the most exciting applications of quantum computing is its potential to revolutionize cryptography.\n",
      "Cryptography is the practice of securing communications and data by encrypting them so that only authorized parties can read them. It is a critical component of modern security systems, and it is essential for protecting sensitive information from unauthorized access.\n",
      "Quantum computing has the potential to revolutionize cryptography in several ways. First, it can enable the development of more secure cryptographic algorithms. Quantum computers are capable of performing complex calculations much faster than classical computers, and this speed advantage can be used to create more secure cryptographic algorithms.\n",
      "Second, quantum computing can enable the development of more efficient cryptographic protocols. Quantum computers are capable of performing complex calculations much faster than classical computers, and this speed advantage can be used to create more efficient cryptographic protocols.\n",
      "Third, quantum computing can enable the development of more secure cryptographic systems. Quantum computers are capable of performing complex calculations much faster than classical computers, and this speed advantage can be used to create more secure cryptographic systems.\n",
      "Overall, quantum computing has the potential to revolutionize cryptography in several ways. It can enable the development of more secure cryptographic algorithms, more efficient cryptographic protocols, and more secure cryptographic systems. As quantum computing continues to develop, it is likely that it will have a significant impact on the field of cryptography.\n",
      "The Impact of Quantum Computing on Cryptography: A Comprehensive Overview\n",
      "Quantum computing is a rapidly developing field of computer science that has the potential to revolutionize the way we think about computing. One of the most exciting applications\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 40986.421875 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could\n",
      "=>   potentially break many of the cryptographic algorithms currently in use.\n",
      "However, there are also potential benefits to quantum computing for cryptography. For example, quantum algorithms could be used to create more secure cryptographic algorithms that are resistant to quantum attacks. Additionally, quantum computing could be used to create more efficient cryptographic protocols that require less computation and energy.\n",
      "Overall, the impact of quantum computing on cryptography is still uncertain. However, it is clear that quantum computing has the potential to revolutionize the field of cryptography and could have a significant impact on the security of our digital communications.\n",
      "The Impact of Quantum Computing on Cryptography\n",
      "Quantum computing is a rapidly developing field of computer science that has the potential to revolutionize the way we think about computing. One of the most exciting applications of quantum computing is its potential to revolutionize cryptography.\n",
      "Cryptography is the practice of securing communications and data by encrypting them so that only authorized parties can read them. It is a critical component of modern security systems, and it is essential for protecting sensitive information from unauthorized access.\n",
      "Quantum computing has the potential to revolutionize cryptography in several ways. First, it can enable the development of more secure cryptographic algorithms. Quantum computers are capable of performing complex calculations much faster than classical computers, and this speed advantage can be used to create more secure cryptographic algorithms.\n",
      "Second, quantum computing can enable the development of more efficient cryptographic protocols. Quantum computers are capable of performing complex calculations much faster than classical computers, and this speed advantage can be used to create more efficient cryptographic protocols.\n",
      "Third, quantum computing can enable the development of more secure cryptographic systems. Quantum computers are capable of performing complex calculations much faster than classical computers, and this speed advantage can be used to create more secure cryptographic systems.\n",
      "Overall, quantum computing has the potential to revolutionize cryptography in several ways. It can enable the development of more secure cryptographic algorithms, more efficient cryptographic protocols, and more secure cryptographic systems. As quantum computing continues to develop, it is likely that it will have a significant impact on the field of cryptography.\n",
      "The Impact of Quantum Computing on Cryptography: A Comprehensive Overview\n",
      "Quantum computing is a rapidly developing field of computer science that has the potential to revolutionize the way we think about computing. One of the most exciting applications\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 42066.41015625 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could\n",
      "=>   potentially break many of the cryptographic algorithms currently in use.\n",
      "However, there are also potential benefits to quantum computing for cryptography. For example, quantum algorithms could be used to create more secure cryptographic algorithms that are resistant to quantum attacks. Additionally, quantum computing could be used to create more efficient cryptographic protocols that require less computation and energy.\n",
      "Overall, the impact of quantum computing on cryptography is still uncertain. However, it is clear that quantum computing has the potential to revolutionize the field of cryptography and could have a significant impact on the security of our digital communications.\n",
      "The Impact of Quantum Computing on Cryptography\n",
      "Quantum computing is a rapidly developing field of computer science that has the potential to revolutionize the way we think about computing. One of the most exciting applications of quantum computing is its potential to revolutionize cryptography.\n",
      "Cryptography is the practice of securing communications and data by encrypting them so that only authorized parties can read them. It is a critical component of modern security systems, and it is essential for protecting sensitive information from unauthorized access.\n",
      "Quantum computing has the potential to revolutionize cryptography in several ways. First, it can enable the development of more secure cryptographic algorithms. Quantum computers are capable of performing complex calculations much faster than classical computers, and this speed advantage can be used to create more secure cryptographic algorithms.\n",
      "Second, quantum computing can enable the development of more efficient cryptographic protocols. Quantum computers are capable of performing complex calculations much faster than classical computers, and this speed advantage can be used to create more efficient cryptographic protocols.\n",
      "Third, quantum computing can enable the development of more secure cryptographic systems. Quantum computers are capable of performing complex calculations much faster than classical computers, and this speed advantage can be used to create more secure cryptographic systems.\n",
      "Overall, quantum computing has the potential to revolutionize cryptography in several ways. It can enable the development of more secure cryptographic algorithms, more efficient cryptographic protocols, and more secure cryptographic systems. As quantum computing continues to develop, it is likely that it will have a significant impact on the field of cryptography.\n",
      "The Impact of Quantum Computing on Cryptography: A Comprehensive Overview\n",
      "Quantum computing is a rapidly developing field of computer science that has the potential to revolutionize the way we think about computing. One of the most exciting applications\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 40339.4375 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>   potentially break many of the cryptographic algorithms currently in use.\n",
      "However, there are also potential benefits to quantum computing for cryptography. For example, quantum algorithms could be used to create more secure cryptographic algorithms that are resistant to quantum attacks. Additionally, quantum computing could be used to create more efficient cryptographic protocols that require less computation and energy.\n",
      "Overall, the impact of quantum computing on cryptography is still uncertain. However, it is clear that quantum computing has the potential to revolutionize the field of cryptography and could have a significant impact on the security of our digital communications.\n",
      "The Impact of Quantum Computing on Cryptography\n",
      "Quantum computing is a rapidly developing field of computer science that has the potential to revolutionize the way we think about computing. One of the most exciting applications of quantum computing is its potential to revolutionize cryptography.\n",
      "Cryptography is the practice of securing communications and data by encrypting them so that only authorized parties can read them. It is a critical component of modern security systems, and it is essential for protecting sensitive information from unauthorized access.\n",
      "Quantum computing has the potential to revolutionize cryptography in several ways. First, it can enable the development of more secure cryptographic algorithms. Quantum computers are capable of performing complex calculations much faster than classical computers, and this speed advantage can be used to create more secure cryptographic algorithms.\n",
      "Second, quantum computing can enable the development of more efficient cryptographic protocols. Quantum computers are capable of performing complex calculations much faster than classical computers, and this speed advantage can be used to create more efficient cryptographic protocols.\n",
      "Third, quantum computing can enable the development of more secure cryptographic systems. Quantum computers are capable of performing complex calculations much faster than classical computers, and this speed advantage can be used to create more secure cryptographic systems.\n",
      "Overall, quantum computing has the potential to revolutionize cryptography in several ways. It can enable the development of more secure cryptographic algorithms, more efficient cryptographic protocols, and more secure cryptographic systems. As quantum computing continues to develop, it is likely that it will have a significant impact on the field of cryptography.\n",
      "The Impact of Quantum Computing on Cryptography: A Comprehensive Overview\n",
      "Quantum computing is a rapidly developing field of computer science that has the potential to revolutionize the way we think about computing. One of the most exciting applications\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 40256.29296875 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could\n",
      "=>   potentially break many of the cryptographic algorithms currently in use.\n",
      "However, there are also potential benefits to quantum computing for cryptography. For example, quantum algorithms could be used to create more secure cryptographic algorithms that are resistant to quantum attacks. Additionally, quantum computing could be used to create more efficient cryptographic protocols that require less computation and energy.\n",
      "Overall, the impact of quantum computing on cryptography is still uncertain. However, it is clear that quantum computing has the potential to revolutionize the field of cryptography and could have a significant impact on the security of our digital communications.\n",
      "The Impact of Quantum Computing on Cryptography\n",
      "Quantum computing is a rapidly developing field of computer science that has the potential to revolutionize the way we think about computing. One of the most exciting applications of quantum computing is its potential to revolutionize cryptography.\n",
      "Cryptography is the practice of securing communications and data by encrypting them so that only authorized parties can read them. It is a critical component of modern security systems, and it is essential for protecting sensitive information from unauthorized access.\n",
      "Quantum computing has the potential to revolutionize cryptography in several ways. First, it can enable the development of more secure cryptographic algorithms. Quantum computers are capable of performing complex calculations much faster than classical computers, and this speed advantage can be used to create more secure cryptographic algorithms.\n",
      "Second, quantum computing can enable the development of more efficient cryptographic protocols. Quantum computers are capable of performing complex calculations much faster than classical computers, and this speed advantage can be used to create more efficient cryptographic protocols.\n",
      "Third, quantum computing can enable the development of more secure cryptographic systems. Quantum computers are capable of performing complex calculations much faster than classical computers, and this speed advantage can be used to create more secure cryptographic systems.\n",
      "Overall, quantum computing has the potential to revolutionize cryptography in several ways. It can enable the development of more secure cryptographic algorithms, more efficient cryptographic protocols, and more secure cryptographic systems. As quantum computing continues to develop, it is likely that it will have a significant impact on the field of cryptography.\n",
      "The Impact of Quantum Computing on Cryptography: A Comprehensive Overview\n",
      "Quantum computing is a rapidly developing field of computer science that has the potential to revolutionize the way we think about computing. One of the most exciting applications\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 42283.09375 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future\n",
      "=>  , fashion will continue to evolve and adapt to the changing needs and preferences of society, creating new trends and styles that reflect the values and aspirations of the people who wear them.\n",
      "Fashion is a form of self-expression that adapts to the times.\n",
      "Fashion is a form of self-expression that adapts to the times. It is a way for people to express their individuality and identity through the clothes they wear. Fashion has evolved over time, reflecting changes in society and culture. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion has always been a way for people to express themselves.\n",
      "Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices.\n",
      "In the future, fashion will continue to evolve and adapt to the changing needs and preferences of society, creating new trends and styles that reflect the values and aspirations of the people who wear them.\n",
      "Fashion is a form of self-expression that adapts to the times. It is a way for people to express their individuality and identity through the clothes they wear. Fashion has evolved over time, reflecting changes in society and culture. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion has always been a way for people to express themselves. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future, fashion will continue to evolve and adapt to the changing needs and preferences of society, creating new trends and styles that reflect the values and aspirations of the people who wear them.\n",
      "Fashion is a form of self-expression that adapts to the times. It is a way for people to express their individuality and identity through the clothes they wear. Fashion has evolved over time, reflecting changes in society and culture. From the elaborate garments\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 41581.83203125 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>  , fashion will continue to evolve and adapt to the changing needs and preferences of society, creating new trends and styles that reflect the values and aspirations of the people who wear them.\n",
      "Fashion is a form of self-expression that adapts to the times.\n",
      "Fashion is a form of self-expression that adapts to the times. It is a way for people to express their individuality and identity through the clothes they wear. Fashion has evolved over time, reflecting changes in society and culture. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion has always been a way for people to express themselves.\n",
      "Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices.\n",
      "In the future, fashion will continue to evolve and adapt to the changing needs and preferences of society, creating new trends and styles that reflect the values and aspirations of the people who wear them.\n",
      "Fashion is a form of self-expression that adapts to the times. It is a way for people to express their individuality and identity through the clothes they wear. Fashion has evolved over time, reflecting changes in society and culture. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion has always been a way for people to express themselves. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future, fashion will continue to evolve and adapt to the changing needs and preferences of society, creating new trends and styles that reflect the values and aspirations of the people who wear them.\n",
      "Fashion is a form of self-expression that adapts to the times. It is a way for people to express their individuality and identity through the clothes they wear. Fashion has evolved over time, reflecting changes in society and culture. From the elaborate garments\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 41766.32421875 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future\n",
      "=>  , fashion will continue to evolve and adapt to the changing needs and preferences of society, creating new trends and styles that reflect the values and aspirations of the people who wear them.\n",
      "Fashion is a form of self-expression that adapts to the times.\n",
      "Fashion is a form of self-expression that adapts to the times. It is a way for people to express their individuality and identity through the clothes they wear. Fashion has evolved over time, reflecting changes in society and culture. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion has always been a way for people to express themselves.\n",
      "Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices.\n",
      "In the future, fashion will continue to evolve and adapt to the changing needs and preferences of society, creating new trends and styles that reflect the values and aspirations of the people who wear them.\n",
      "Fashion is a form of self-expression that adapts to the times. It is a way for people to express their individuality and identity through the clothes they wear. Fashion has evolved over time, reflecting changes in society and culture. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion has always been a way for people to express themselves. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future, fashion will continue to evolve and adapt to the changing needs and preferences of society, creating new trends and styles that reflect the values and aspirations of the people who wear them.\n",
      "Fashion is a form of self-expression that adapts to the times. It is a way for people to express their individuality and identity through the clothes they wear. Fashion has evolved over time, reflecting changes in society and culture. From the elaborate garments\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 41725.2265625 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future\n",
      "=>  , fashion will continue to evolve and adapt to the changing needs and preferences of society, creating new trends and styles that reflect the values and aspirations of the people who wear them.\n",
      "Fashion is a form of self-expression that adapts to the times.\n",
      "Fashion is a form of self-expression that adapts to the times. It is a way for people to express their individuality and identity through the clothes they wear. Fashion has evolved over time, reflecting changes in society and culture. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion has always been a way for people to express themselves.\n",
      "Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices.\n",
      "In the future, fashion will continue to evolve and adapt to the changing needs and preferences of society, creating new trends and styles that reflect the values and aspirations of the people who wear them.\n",
      "Fashion is a form of self-expression that adapts to the times. It is a way for people to express their individuality and identity through the clothes they wear. Fashion has evolved over time, reflecting changes in society and culture. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion has always been a way for people to express themselves. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future, fashion will continue to evolve and adapt to the changing needs and preferences of society, creating new trends and styles that reflect the values and aspirations of the people who wear them.\n",
      "Fashion is a form of self-expression that adapts to the times. It is a way for people to express their individuality and identity through the clothes they wear. Fashion has evolved over time, reflecting changes in society and culture. From the elaborate garments\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 40617.01171875 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>  , fashion will continue to evolve and adapt to the changing needs and preferences of society, creating new trends and styles that reflect the values and aspirations of the people who wear them.\n",
      "Fashion is a form of self-expression that adapts to the times.\n",
      "Fashion is a form of self-expression that adapts to the times. It is a way for people to express their individuality and identity through the clothes they wear. Fashion has evolved over time, reflecting changes in society and culture. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion has always been a way for people to express themselves.\n",
      "Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices.\n",
      "In the future, fashion will continue to evolve and adapt to the changing needs and preferences of society, creating new trends and styles that reflect the values and aspirations of the people who wear them.\n",
      "Fashion is a form of self-expression that adapts to the times. It is a way for people to express their individuality and identity through the clothes they wear. Fashion has evolved over time, reflecting changes in society and culture. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion has always been a way for people to express themselves. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future, fashion will continue to evolve and adapt to the changing needs and preferences of society, creating new trends and styles that reflect the values and aspirations of the people who wear them.\n",
      "Fashion is a form of self-expression that adapts to the times. It is a way for people to express their individuality and identity through the clothes they wear. Fashion has evolved over time, reflecting changes in society and culture. From the elaborate garments\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 40569.0703125 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future\n",
      "=>  , fashion will continue to evolve and adapt to the changing needs and preferences of society, creating new trends and styles that reflect the values and aspirations of the people who wear them.\n",
      "Fashion is a form of self-expression that adapts to the times.\n",
      "Fashion is a form of self-expression that adapts to the times. It is a way for people to express their individuality and identity through the clothes they wear. Fashion has evolved over time, reflecting changes in society and culture. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion has always been a way for people to express themselves.\n",
      "Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices.\n",
      "In the future, fashion will continue to evolve and adapt to the changing needs and preferences of society, creating new trends and styles that reflect the values and aspirations of the people who wear them.\n",
      "Fashion is a form of self-expression that adapts to the times. It is a way for people to express their individuality and identity through the clothes they wear. Fashion has evolved over time, reflecting changes in society and culture. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion has always been a way for people to express themselves. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future, fashion will continue to evolve and adapt to the changing needs and preferences of society, creating new trends and styles that reflect the values and aspirations of the people who wear them.\n",
      "Fashion is a form of self-expression that adapts to the times. It is a way for people to express their individuality and identity through the clothes they wear. Fashion has evolved over time, reflecting changes in society and culture. From the elaborate garments\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 40293.01953125 ms\n",
      "| Layer 0: 2285.07\t|2354.54\t|2337.11\t|2216.1\t|2232.79\t|2297.92\t|2298.33\t|2316.76\t|2436.22\t|2276.45\t|2228.23\t|2351.36\t|2349.42\t|2335.47\t|2307.71\t|2286.66\t|2259.37\t|2301.69\n",
      "| Layer 1: 2262.68\t|2250.58\t|2314.78\t|2203.7\t|2204.06\t|2243.19\t|2273.63\t|2326.38\t|2287.88\t|2244.99\t|2242.24\t|2391.31\t|2358.37\t|2314.15\t|2314.9\t|2289.05\t|2343.36\t|2188.12\n",
      "| Layer 2: 2213.83\t|2221.97\t|2348.9\t|2160.97\t|2137.0\t|2212.66\t|2246.43\t|2255.86\t|2341.61\t|2178.13\t|2198.96\t|2286.88\t|2290.06\t|2273.08\t|2304.08\t|2250.78\t|2229.78\t|2208.63\n",
      "| Layer 3: 2317.76\t|2242.4\t|2299.89\t|2147.31\t|2139.22\t|2227.0\t|2246.84\t|2267.87\t|2335.13\t|2209.5\t|2265.48\t|2351.65\t|2244.13\t|2348.4\t|2344.14\t|2230.75\t|2234.4\t|2232.53\n",
      "| Layer 4: 2250.23\t|2233.54\t|2303.43\t|2143.14\t|2123.61\t|2214.01\t|2258.0\t|2286.22\t|2328.99\t|2234.93\t|2186.62\t|2369.73\t|2299.71\t|2293.11\t|2295.39\t|2266.32\t|2233.18\t|2204.65\n",
      "| Layer 5: 2249.75\t|2303.92\t|2289.85\t|2167.76\t|2131.81\t|2203.31\t|2246.95\t|2255.67\t|2336.95\t|2197.81\t|2219.88\t|2313.47\t|2345.37\t|2346.66\t|2301.53\t|2303.82\t|2290.06\t|2244.2\n",
      "| Layer 6: 2272.91\t|2225.98\t|2345.68\t|2159.39\t|2146.43\t|2270.86\t|2291.79\t|2255.21\t|2281.52\t|2229.14\t|2247.4\t|2350.24\t|2280.48\t|2302.22\t|2254.41\t|2235.8\t|2235.52\t|2248.73\n",
      "| Layer 7: 2228.39\t|2236.7\t|2290.44\t|2153.39\t|2122.51\t|2205.38\t|2247.56\t|2273.9\t|2367.18\t|2240.02\t|2191.66\t|2288.14\t|2276.21\t|2275.05\t|2372.02\t|2222.12\t|2244.62\t|2171.93\n",
      "| Layer 8: 2280.24\t|2271.18\t|2306.89\t|2187.25\t|2162.55\t|2237.02\t|2260.79\t|2234.44\t|2350.46\t|2235.86\t|2298.66\t|2332.05\t|2333.54\t|2353.16\t|2346.49\t|2313.01\t|2281.53\t|2232.56\n",
      "| Layer 9: 2274.2\t|2255.93\t|2283.37\t|2152.64\t|2156.8\t|2224.65\t|2295.94\t|2272.19\t|2394.25\t|2232.96\t|2243.81\t|2358.32\t|2305.99\t|2313.55\t|2271.12\t|2268.63\t|2258.76\t|2291.42\n",
      "| Layer 10: 2284.22\t|2283.04\t|2346.54\t|2160.64\t|2165.7\t|2282.0\t|2268.48\t|2304.07\t|2378.64\t|2295.5\t|2250.62\t|2349.8\t|2323.74\t|2340.26\t|2319.85\t|2283.7\t|2237.77\t|2228.4\n",
      "| Layer 11: 2357.63\t|2259.53\t|2305.1\t|2156.28\t|2132.7\t|2249.78\t|2299.99\t|2287.71\t|2373.28\t|2199.39\t|2237.97\t|2343.36\t|2318.19\t|2281.71\t|2299.84\t|2219.28\t|2230.65\t|2250.26\n",
      "| Layer 12: 2242.11\t|2244.86\t|2293.88\t|2167.98\t|2161.77\t|2272.77\t|2273.66\t|2284.7\t|2335.89\t|2235.3\t|2261.34\t|2333.26\t|2329.35\t|2349.88\t|2272.2\t|2261.61\t|2247.0\t|2214.64\n",
      "| Layer 13: 2266.92\t|2277.96\t|2349.41\t|2175.63\t|2163.14\t|2222.11\t|2291.64\t|2263.54\t|2341.78\t|2281.86\t|2227.25\t|2325.18\t|2306.2\t|2345.32\t|2342.04\t|2271.55\t|2304.54\t|2252.01\n",
      "| Layer 14: 2272.42\t|2277.01\t|2380.88\t|2209.39\t|2161.46\t|2288.71\t|2292.24\t|2247.4\t|2353.02\t|2276.53\t|2242.79\t|2346.01\t|2321.68\t|2308.74\t|2380.26\t|2264.99\t|2290.49\t|2220.41\n",
      "| Layer 15: 2290.73\t|2328.54\t|2277.89\t|2183.11\t|2170.36\t|2255.18\t|2349.86\t|2300.64\t|2394.75\t|2243.39\t|2307.08\t|2369.79\t|2385.24\t|2348.44\t|2354.54\t|2282.96\t|2241.31\t|2292.44\n",
      "| Layer 16: 2289.88\t|2247.26\t|2285.04\t|2151.17\t|2153.34\t|2195.54\t|2293.18\t|2250.57\t|2325.04\t|2255.44\t|2197.73\t|2324.97\t|2270.87\t|2312.1\t|2297.02\t|2288.07\t|2268.81\t|2205.63\n",
      "| Layer 17: 2259.51\t|2262.85\t|2306.49\t|2177.15\t|2164.87\t|2239.06\t|2322.43\t|2267.37\t|2324.81\t|2189.1\t|2230.58\t|2271.07\t|2259.49\t|2304.5\t|2282.26\t|2247.69\t|2206.81\t|2208.78\n",
      "| Layer 18: 2268.6\t|2269.78\t|2302.8\t|2146.38\t|2153.53\t|2245.72\t|2268.48\t|2317.22\t|2353.07\t|2300.35\t|2279.05\t|2401.7\t|2370.71\t|2312.94\t|2436.0\t|2249.63\t|2272.46\t|2233.29\n",
      "| Layer 19: 2267.46\t|2297.5\t|2303.33\t|2191.38\t|2164.01\t|2244.62\t|2259.1\t|2255.37\t|2337.88\t|2246.13\t|2233.55\t|2332.81\t|2261.79\t|2304.1\t|2288.65\t|2266.65\t|2297.18\t|2283.06\n",
      "| Layer 20: 2279.97\t|2280.58\t|2266.17\t|2200.01\t|2130.62\t|2221.83\t|2275.01\t|2267.07\t|2339.78\t|2252.62\t|2226.79\t|2366.2\t|2281.62\t|2340.17\t|2460.52\t|2250.92\t|2241.55\t|2227.79\n",
      "| Layer 21: 2253.99\t|2243.75\t|2310.27\t|2164.32\t|2168.69\t|2254.39\t|2313.42\t|2283.62\t|2340.33\t|2266.45\t|2253.25\t|2333.65\t|2334.2\t|2309.38\t|2368.98\t|2232.02\t|2222.36\t|2223.54\n",
      "| Layer 22: 2240.53\t|2316.25\t|2317.01\t|2166.31\t|2156.1\t|2263.75\t|2274.45\t|2239.78\t|2353.57\t|2259.23\t|2259.11\t|2326.81\t|2323.32\t|2334.14\t|2303.41\t|2250.11\t|2221.87\t|2253.54\n",
      "| Layer 23: 2309.39\t|2303.76\t|2284.37\t|2154.79\t|2148.33\t|2263.72\t|2268.8\t|2281.64\t|2342.22\t|2243.04\t|2213.33\t|2425.77\t|2294.41\t|2329.63\t|2362.29\t|2248.03\t|2246.5\t|2248.75\n",
      "| Layer 24: 2297.52\t|2315.77\t|2376.07\t|2195.38\t|2186.53\t|2274.14\t|2266.76\t|2283.3\t|2362.23\t|2241.85\t|2267.98\t|2328.91\t|2327.11\t|2323.27\t|2353.0\t|2249.36\t|2289.88\t|2270.42\n",
      "| Layer 25: 2294.64\t|2246.63\t|2293.94\t|2197.75\t|2122.1\t|2240.22\t|2291.74\t|2247.69\t|2319.0\t|2205.54\t|2248.11\t|2312.53\t|2296.21\t|2368.21\t|2282.67\t|2234.65\t|2231.71\t|2188.84\n",
      "| Layer 26: 2319.7\t|2260.47\t|2344.47\t|2208.57\t|2161.19\t|2263.76\t|2269.01\t|2289.65\t|2369.74\t|2221.78\t|2246.53\t|2357.9\t|2338.08\t|2346.36\t|2330.62\t|2280.72\t|2276.29\t|2261.56\n",
      "| Layer 27: 2235.71\t|2227.09\t|2337.21\t|2191.85\t|2150.58\t|2221.29\t|2273.71\t|2296.22\t|2339.76\t|2254.15\t|2231.25\t|2335.55\t|2315.65\t|2308.08\t|2354.0\t|2255.8\t|2272.81\t|2236.59\n",
      "| Layer 28: 2323.68\t|2290.4\t|2292.39\t|2162.09\t|2153.98\t|2243.34\t|2222.57\t|2293.09\t|2366.45\t|2242.37\t|2221.73\t|2302.99\t|2342.35\t|2370.73\t|2304.68\t|2263.08\t|2262.23\t|2266.67\n",
      "| Layer 29: 2311.56\t|2264.98\t|2270.2\t|2215.0\t|2148.02\t|2237.53\t|2271.69\t|2260.64\t|2343.18\t|2241.15\t|2288.31\t|2370.69\t|2282.6\t|2289.99\t|2282.58\t|2240.28\t|2258.14\t|2262.72\n",
      "| Layer 30: 2240.71\t|2270.66\t|2326.79\t|2165.51\t|2171.32\t|2205.29\t|2308.87\t|2251.1\t|2418.37\t|2201.34\t|2225.08\t|2353.91\t|2305.11\t|2307.92\t|2318.75\t|2219.07\t|2240.68\t|2216.12\n",
      "| Layer 31: 2304.51\t|2255.98\t|2379.11\t|2178.61\t|2164.65\t|2296.08\t|2294.76\t|2324.0\t|2351.17\t|2262.96\t|2280.64\t|2314.69\t|2319.45\t|2314.6\t|2305.62\t|2303.64\t|2275.61\t|2222.38\n"
     ]
    }
   ],
   "source": [
    "unpruned.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3fbf3ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T09:11:12.713719Z",
     "start_time": "2024-05-25T09:11:12.709237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: Small: 2287.25 | Medium: 2317.89 | Long: 2306.72\n",
      "Layer 1: Small: 2246.5 | Medium: 2294.41 | Long: 2301.33\n",
      "Layer 2: Small: 2215.89 | Medium: 2251.31 | Long: 2259.4\n",
      "Layer 3: Small: 2228.93 | Medium: 2279.41 | Long: 2272.39\n",
      "Layer 4: Small: 2211.33 | Medium: 2277.41 | Long: 2265.39\n",
      "Layer 5: Small: 2224.4 | Medium: 2261.79 | Long: 2305.28\n",
      "Layer 6: Small: 2236.88 | Medium: 2275.88 | Long: 2259.53\n",
      "Layer 7: Small: 2206.14 | Medium: 2268.08 | Long: 2260.33\n",
      "Layer 8: Small: 2240.86 | Medium: 2285.38 | Long: 2310.05\n",
      "Layer 9: Small: 2224.6 | Medium: 2299.58 | Long: 2284.91\n",
      "Layer 10: Small: 2253.69 | Medium: 2307.85 | Long: 2288.95\n",
      "Layer 11: Small: 2243.5 | Medium: 2290.29 | Long: 2266.66\n",
      "Layer 12: Small: 2230.56 | Medium: 2287.36 | Long: 2279.11\n",
      "Layer 13: Small: 2242.53 | Medium: 2288.54 | Long: 2303.61\n",
      "Layer 14: Small: 2264.98 | Medium: 2293.0 | Long: 2297.76\n",
      "Layer 15: Small: 2250.97 | Medium: 2327.58 | Long: 2317.49\n",
      "Layer 16: Small: 2220.37 | Medium: 2274.49 | Long: 2273.75\n",
      "Layer 17: Small: 2234.99 | Medium: 2267.56 | Long: 2251.59\n",
      "Layer 18: Small: 2231.13 | Medium: 2319.98 | Long: 2312.51\n",
      "Layer 19: Small: 2244.72 | Medium: 2277.47 | Long: 2283.57\n",
      "Layer 20: Small: 2229.86 | Medium: 2287.91 | Long: 2300.43\n",
      "Layer 21: Small: 2232.57 | Medium: 2298.45 | Long: 2281.74\n",
      "Layer 22: Small: 2243.32 | Medium: 2285.49 | Long: 2281.07\n",
      "Layer 23: Small: 2244.06 | Medium: 2295.8 | Long: 2288.27\n",
      "Layer 24: Small: 2274.24 | Medium: 2291.84 | Long: 2302.17\n",
      "Layer 25: Small: 2232.55 | Medium: 2270.77 | Long: 2267.05\n",
      "Layer 26: Small: 2259.69 | Medium: 2292.44 | Long: 2305.61\n",
      "Layer 27: Small: 2227.29 | Medium: 2288.44 | Long: 2290.49\n",
      "Layer 28: Small: 2244.31 | Medium: 2274.87 | Long: 2301.62\n",
      "Layer 29: Small: 2241.21 | Medium: 2295.94 | Long: 2269.38\n",
      "Layer 30: Small: 2230.05 | Medium: 2293.11 | Long: 2267.94\n",
      "Layer 31: Small: 2263.16 | Medium: 2304.7 | Long: 2290.21\n"
     ]
    }
   ],
   "source": [
    "for layer, times in unpruned.layers.items():\n",
    "    print(f\"Layer {layer}: Small: {round(sum(times[:6])/6,2)} | Medium: {round(sum(times[6:12])/6, 2)} | Long: {round(sum(times[12:])/6, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1cd6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "307db4d2",
   "metadata": {},
   "source": [
    "## 20% pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "018707f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:18:01.406543Z",
     "start_time": "2024-05-25T10:18:01.401078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received 3 inputs\n"
     ]
    }
   ],
   "source": [
    "pruning_dict = \"pruning_dict_1.0_0.7_1.0_chat_2540.json\"\n",
    "save_dir = \"/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints/\"\n",
    "\n",
    "p = pruning_dict.split(\"_\")[-1].split(\".\")[-2]\n",
    "output_dir = \"/data/home/milinbhade/Milin/AMC/bertamc_v4/llama_checkpoints//\" + p\n",
    "\n",
    "inputs = [\"What is a large language model?\",\n",
    "          \"Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could\", \n",
    "          \"The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future\"]\n",
    "\n",
    "pruned = LayerAnalysis(pipeline, tokenizer, pruning_dict, inputs, save_dir, output_dir, \n",
    "                 ignore_layers=None, use_template=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0acadf71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:18:02.357692Z",
     "start_time": "2024-05-25T10:18:02.315583Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 ==>  4096\n",
      "67 ==>  11008\n",
      "75 ==>  4096\n",
      "81 ==>  11004\n",
      "89 ==>  4096\n",
      "95 ==>  11003\n",
      "103 ==>  4096\n",
      "109 ==>  11008\n",
      "117 ==>  4096\n",
      "123 ==>  11007\n",
      "131 ==>  4096\n",
      "137 ==>  11007\n",
      "145 ==>  4096\n",
      "151 ==>  10994\n",
      "159 ==>  4096\n",
      "165 ==>  11000\n",
      "173 ==>  4096\n",
      "179 ==>  8538\n",
      "187 ==>  2816\n",
      "193 ==>  7706\n",
      "201 ==>  2816\n",
      "207 ==>  7706\n",
      "215 ==>  2816\n",
      "221 ==>  7706\n",
      "229 ==>  2816\n",
      "235 ==>  7767\n",
      "243 ==>  2816\n",
      "249 ==>  7784\n",
      "257 ==>  2816\n",
      "263 ==>  7777\n",
      "271 ==>  2816\n",
      "277 ==>  7780\n",
      "285 ==>  2816\n",
      "291 ==>  7778\n",
      "299 ==>  2816\n",
      "305 ==>  7780\n",
      "313 ==>  2816\n",
      "319 ==>  7778\n",
      "327 ==>  2816\n",
      "333 ==>  7780\n",
      "341 ==>  2816\n",
      "347 ==>  7778\n",
      "355 ==>  2816\n",
      "361 ==>  7780\n",
      "369 ==>  2816\n",
      "375 ==>  7778\n",
      "383 ==>  2816\n",
      "389 ==>  7780\n"
     ]
    }
   ],
   "source": [
    "pruned.experiment.get_head_inter_pruning_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6394d3fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:19:21.035399Z",
     "start_time": "2024-05-25T10:18:03.368502Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.51458816\n",
      "Model size after pruning:  13.514489856\n",
      "Model size after pruning:  13.514489856\n",
      "Model size after pruning:  13.514366976\n",
      "Model size after pruning:  13.514366976\n",
      "Model size after pruning:  13.514366976\n",
      "Model size after pruning:  13.514366976\n",
      "Model size after pruning:  13.5143424\n",
      "Model size after pruning:  13.5143424\n",
      "Model size after pruning:  13.514317824\n",
      "Model size after pruning:  13.514317824\n",
      "Model size after pruning:  13.51397376\n",
      "Model size after pruning:  13.51397376\n",
      "Model size after pruning:  13.513777152\n",
      "Model size after pruning:  13.513777152\n",
      "Model size after pruning:  13.453074432\n",
      "Model size after pruning:  13.411131392\n",
      "Model size after pruning:  13.32998144\n",
      "Model size after pruning:  13.2880384\n",
      "Model size after pruning:  13.206888448\n",
      "Model size after pruning:  13.164945408\n",
      "Model size after pruning:  13.083795456\n",
      "Model size after pruning:  13.041852416\n",
      "Model size after pruning:  12.9622016\n",
      "Model size after pruning:  12.92025856\n",
      "Model size after pruning:  12.841025536\n",
      "Model size after pruning:  12.799082496\n",
      "Model size after pruning:  12.71967744\n",
      "Model size after pruning:  12.6777344\n",
      "Model size after pruning:  12.598403072\n",
      "Model size after pruning:  12.556460032\n",
      "Model size after pruning:  12.477079552\n",
      "Model size after pruning:  12.435136512\n",
      "Model size after pruning:  12.355805184\n",
      "Model size after pruning:  12.313862144\n",
      "Model size after pruning:  12.234481664\n",
      "Model size after pruning:  12.192538624\n",
      "Model size after pruning:  12.113207296\n",
      "Model size after pruning:  12.071264256\n",
      "Model size after pruning:  11.991883776\n",
      "Model size after pruning:  11.949940736\n",
      "Model size after pruning:  11.870609408\n",
      "Model size after pruning:  11.828666368\n",
      "Model size after pruning:  11.749285888\n",
      "Model size after pruning:  11.707342848\n",
      "Model size after pruning:  11.62801152\n"
     ]
    }
   ],
   "source": [
    "pruned.prune_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "050a6c0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:19:34.248697Z",
     "start_time": "2024-05-25T10:19:34.240398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-4): 5 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (5): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11004, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11004, bias=False)\n",
       "          (down_proj): Linear(in_features=11004, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (6): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11003, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11003, bias=False)\n",
       "          (down_proj): Linear(in_features=11003, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (7): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (8-9): 2 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11007, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11007, bias=False)\n",
       "          (down_proj): Linear(in_features=11007, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (10): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=10994, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=10994, bias=False)\n",
       "          (down_proj): Linear(in_features=10994, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (11): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11000, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11000, bias=False)\n",
       "          (down_proj): Linear(in_features=11000, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (12): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=8538, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=8538, bias=False)\n",
       "          (down_proj): Linear(in_features=8538, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (13-15): 3 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=7706, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=7706, bias=False)\n",
       "          (down_proj): Linear(in_features=7706, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (16): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=7767, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=7767, bias=False)\n",
       "          (down_proj): Linear(in_features=7767, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (17): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=7784, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=7784, bias=False)\n",
       "          (down_proj): Linear(in_features=7784, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (18): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=7777, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=7777, bias=False)\n",
       "          (down_proj): Linear(in_features=7777, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (19): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
       "          (down_proj): Linear(in_features=7780, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (20): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=7778, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=7778, bias=False)\n",
       "          (down_proj): Linear(in_features=7778, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (21): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
       "          (down_proj): Linear(in_features=7780, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (22): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=7778, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=7778, bias=False)\n",
       "          (down_proj): Linear(in_features=7778, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (23): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
       "          (down_proj): Linear(in_features=7780, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (24): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=7778, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=7778, bias=False)\n",
       "          (down_proj): Linear(in_features=7778, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (25): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
       "          (down_proj): Linear(in_features=7780, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (26): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=7778, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=7778, bias=False)\n",
       "          (down_proj): Linear(in_features=7778, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (27): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=2816, bias=False)\n",
       "          (o_proj): Linear(in_features=2816, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=7780, bias=False)\n",
       "          (down_proj): Linear(in_features=7780, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "      (28-31): 4 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5919a59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:31:23.409425Z",
     "start_time": "2024-05-25T10:19:58.545310Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Hooks registerd:  64\n",
      "Hooks Registered:  64\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: What is a large language model?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>   10:10. 10:20. 10:30. 10:40. 10:50. 11:00. 11:10. 11:20. 11:30. 11:40. 11:50. 12:00. 12:10. 12:20. 12:30. 12:40. 12:50. 13:00. 13:10. 13:20. 13:30. 13:40. 13:50. 14:00. 14:10. 14:20. 14:30. 14:40. 14:50. 15:00. 15:10. 15:20. 15:30. 15:40. 15:50. 16:00. 16:10. 16:20. 16:30. 16:40. 16:50. 17:00. 17:10. 17:20. 17:30. 17:40. 17:50. 18:00. 18:10. 18:20. 18:30. 18:40. 18:50. 19:00. 19:10. 19:20. 19:30. 19:40. 19:50. 20:00. 20:10. 20:20. 20:30. 20:40. 20:50. 21:00. 21:10. 21:20. 21:30. 21:40. 21:50. 22:00. 22:10. \n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 38887.30859375 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: What is a large language model?\n",
      "=>   10:10. 10:20. 10:30. 10:40. 10:50. 11:00. 11:10. 11:20. 11:30. 11:40. 11:50. 12:00. 12:10. 12:20. 12:30. 12:40. 12:50. 13:00. 13:10. 13:20. 13:30. 13:40. 13:50. 14:00. 14:10. 14:20. 14:30. 14:40. 14:50. 15:00. 15:10. 15:20. 15:30. 15:40. 15:50. 16:00. 16:10. 16:20. 16:30. 16:40. 16:50. 17:00. 17:10. 17:20. 17:30. 17:40. 17:50. 18:00. 18:10. 18:20. 18:30. 18:40. 18:50. 19:00. 19:10. 19:20. 19:30. 19:40. 19:50. 20:00. 20:10. 20:20. 20:30. 20:40. 20:50. 21:00. 21:10. 21:20. 21:30. 21:40. 21:50. 22:00. 22:10. \n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 38032.0390625 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: What is a large language model?\n",
      "=>   10:10. 10:20. 10:30. 10:40. 10:50. 11:00. 11:10. 11:20. 11:30. 11:40. 11:50. 12:00. 12:10. 12:20. 12:30. 12:40. 12:50. 13:00. 13:10. 13:20. 13:30. 13:40. 13:50. 14:00. 14:10. 14:20. 14:30. 14:40. 14:50. 15:00. 15:10. 15:20. 15:30. 15:40. 15:50. 16:00. 16:10. 16:20. 16:30. 16:40. 16:50. 17:00. 17:10. 17:20. 17:30. 17:40. 17:50. 18:00. 18:10. 18:20. 18:30. 18:40. 18:50. 19:00. 19:10. 19:20. 19:30. 19:40. 19:50. 20:00. 20:10. 20:20. 20:30. 20:40. 20:50. 21:00. 21:10. 21:20. 21:30. 21:40. 21:50. 22:00. 22:10. \n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 38170.76953125 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: What is a large language model?\n",
      "=>   10:10. 10:20. 10:30. 10:40. 10:50. 11:00. 11:10. 11:20. 11:30. 11:40. 11:50. 12:00. 12:10. 12:20. 12:30. 12:40. 12:50. 13:00. 13:10. 13:20. 13:30. 13:40. 13:50. 14:00. 14:10. 14:20. 14:30. 14:40. 14:50. 15:00. 15:10. 15:20. 15:30. 15:40. 15:50. 16:00. 16:10. 16:20. 16:30. 16:40. 16:50. 17:00. 17:10. 17:20. 17:30. 17:40. 17:50. 18:00. 18:10. 18:20. 18:30. 18:40. 18:50. 19:00. 19:10. 19:20. 19:30. 19:40. 19:50. 20:00. 20:10. 20:20. 20:30. 20:40. 20:50. 21:00. 21:10. 21:20. 21:30. 21:40. 21:50. 22:00. 22:10. \n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 37135.92578125 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: What is a large language model?\n",
      "=>   10:10. 10:20. 10:30. 10:40. 10:50. 11:00. 11:10. 11:20. 11:30. 11:40. 11:50. 12:00. 12:10. 12:20. 12:30. 12:40. 12:50. 13:00. 13:10. 13:20. 13:30. 13:40. 13:50. 14:00. 14:10. 14:20. 14:30. 14:40. 14:50. 15:00. 15:10. 15:20. 15:30. 15:40. 15:50. 16:00. 16:10. 16:20. 16:30. 16:40. 16:50. 17:00. 17:10. 17:20. 17:30. 17:40. 17:50. 18:00. 18:10. 18:20. 18:30. 18:40. 18:50. 19:00. 19:10. 19:20. 19:30. 19:40. 19:50. 20:00. 20:10. 20:20. 20:30. 20:40. 20:50. 21:00. 21:10. 21:20. 21:30. 21:40. 21:50. 22:00. 22:10. \n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 37853.8359375 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: What is a large language model?\n",
      "=>   10:10. 10:20. 10:30. 10:40. 10:50. 11:00. 11:10. 11:20. 11:30. 11:40. 11:50. 12:00. 12:10. 12:20. 12:30. 12:40. 12:50. 13:00. 13:10. 13:20. 13:30. 13:40. 13:50. 14:00. 14:10. 14:20. 14:30. 14:40. 14:50. 15:00. 15:10. 15:20. 15:30. 15:40. 15:50. 16:00. 16:10. 16:20. 16:30. 16:40. 16:50. 17:00. 17:10. 17:20. 17:30. 17:40. 17:50. 18:00. 18:10. 18:20. 18:30. 18:40. 18:50. 19:00. 19:10. 19:20. 19:30. 19:40. 19:50. 20:00. 20:10. 20:20. 20:30. 20:40. 20:50. 21:00. 21:10. 21:20. 21:30. 21:40. 21:50. 22:00. 22:10. \n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 38460.62890625 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could\n",
      "=>   potentially be used to break the cryptographic codes that protect the digital world from malicious attacks.\n",
      "The problem is that the technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat of a quantum cryptography-powered attack is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one. The technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one. The technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a quantum cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 37879.21484375 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could\n",
      "=>   potentially be used to break the cryptographic codes that protect the digital world from malicious attacks.\n",
      "The problem is that the technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat of a quantum cryptography-powered attack is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one. The technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one. The technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a quantum cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 36890.5 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>   potentially be used to break the cryptographic codes that protect the digital world from malicious attacks.\n",
      "The problem is that the technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat of a quantum cryptography-powered attack is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one. The technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one. The technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a quantum cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 37171.19921875 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could\n",
      "=>   potentially be used to break the cryptographic codes that protect the digital world from malicious attacks.\n",
      "The problem is that the technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat of a quantum cryptography-powered attack is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one. The technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one. The technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a quantum cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 38180.9921875 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/milinbhade/miniconda3/envs/huggingface/lib/python3.9/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>   potentially be used to break the cryptographic codes that protect the digital world from malicious attacks.\n",
      "The problem is that the technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat of a quantum cryptography-powered attack is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one. The technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one. The technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a quantum cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 38184.7265625 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: Quantum computing is poised to revolutionize the field of cryptography. With the ability to solve complex problems much faster than classical computers, quantum algorithms could\n",
      "=>   potentially be used to break the cryptographic codes that protect the digital world from malicious attacks.\n",
      "The problem is that the technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat of a quantum cryptography-powered attack is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one. The technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a quantum cryptography-powered attack is a real one. The technology is still in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a quantum cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one.\n",
      "The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a real one. The threat of a cryptography-powered attack is a real one. The technology is in its early stages and the algorithms are not yet reliable enough to be used in the real world. However, the threat is a\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 38092.27734375 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future\n",
      "=>  , fashion may be sh-y of the world of the metaverse, where fashion is a part of a virtual world.\n",
      "The fashion industry is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 38001.9375 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>  , fashion may be sh-y of the world of the metaverse, where fashion is a part of a virtual world.\n",
      "The fashion industry is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 38483.05078125 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future\n",
      "=>  , fashion may be sh-y of the world of the metaverse, where fashion is a part of a virtual world.\n",
      "The fashion industry is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 38560.4296875 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future\n",
      "=>  , fashion may be sh-y of the world of the metaverse, where fashion is a part of a virtual world.\n",
      "The fashion industry is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 38230.77734375 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>  , fashion may be sh-y of the world of the metaverse, where fashion is a part of a virtual world.\n",
      "The fashion industry is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 38663.77734375 ms\n",
      "-------------------------------------------------- \n",
      "\n",
      "Prompt: The evolution of fashion reflects changes in society and culture throughout history. From the elaborate garments of the Victorian era to the minimalist styles of the 21st century, fashion is a form of self-expression that adapts to the times. Iconic designers like Coco Chanel, Alexander McQueen, and Virgil Abloh have challenged conventions and introduced new aesthetics. Fashion is also influenced by technological advancements, such as the development of sustainable materials and the rise of digital fashion shows. As we move towards a more inclusive and diverse industry, fashion will continue to celebrate individuality and innovation, inspiring people to express their unique identities through their clothing choices. In the future\n",
      "=>  , fashion may be sh-y of the world of the metaverse, where fashion is a part of a virtual world.\n",
      "The fashion industry is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major industry that is a major\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Elapsed time: 38040.26171875 ms\n",
      "| Layer 0: 3250.11\t|2201.31\t|2215.06\t|2121.9\t|2190.18\t|2239.1\t|2156.63\t|2106.31\t|2122.05\t|2207.46\t|2224.93\t|2186.63\t|2216.58\t|2251.72\t|2262.14\t|2225.86\t|2215.54\t|2197.21\n",
      "| Layer 1: 2085.05\t|2080.67\t|2096.26\t|2027.36\t|2049.45\t|2067.84\t|2110.74\t|2037.28\t|2035.14\t|2088.71\t|2077.58\t|2073.0\t|2084.83\t|2091.75\t|2115.11\t|2083.45\t|2107.41\t|2051.33\n",
      "| Layer 2: 2048.15\t|2053.1\t|2041.61\t|1979.14\t|2017.37\t|2027.19\t|2052.57\t|2001.03\t|2000.06\t|2069.64\t|2056.17\t|2059.15\t|2044.74\t|2105.99\t|2118.18\t|2027.24\t|2052.25\t|2004.38\n",
      "| Layer 3: 2069.78\t|2037.92\t|2047.99\t|1955.14\t|2064.98\t|2057.53\t|2006.26\t|1995.43\t|2001.53\t|2050.57\t|2048.07\t|2023.08\t|2082.07\t|2048.08\t|2067.0\t|2033.91\t|2063.58\t|2017.2\n",
      "| Layer 4: 2042.94\t|2030.66\t|2042.98\t|1970.09\t|2037.55\t|2129.63\t|2025.88\t|1994.94\t|2011.46\t|2029.74\t|2061.76\t|2031.29\t|2033.86\t|2084.38\t|2058.75\t|2064.51\t|2083.19\t|2005.47\n",
      "| Layer 5: 2070.71\t|2020.18\t|2043.85\t|1967.51\t|2022.68\t|2056.19\t|2028.16\t|1972.17\t|1996.18\t|2040.49\t|2052.96\t|2064.16\t|2035.11\t|2048.63\t|2070.86\t|2090.79\t|2054.25\t|1994.91\n",
      "| Layer 6: 2192.44\t|2051.36\t|2085.77\t|2021.89\t|2078.33\t|2086.19\t|2078.29\t|2043.43\t|2009.28\t|2068.7\t|2076.47\t|2055.94\t|2067.77\t|2083.6\t|2145.17\t|2073.17\t|2124.84\t|2044.64\n",
      "| Layer 7: 2084.75\t|2083.17\t|2063.78\t|2040.44\t|2030.13\t|2091.86\t|2066.36\t|2016.38\t|2020.36\t|2072.43\t|2088.0\t|2052.01\t|2083.46\t|2080.99\t|2161.41\t|2051.86\t|2131.39\t|2035.43\n",
      "| Layer 8: 2091.1\t|2041.41\t|2061.16\t|2064.84\t|2071.97\t|2159.36\t|2046.41\t|1979.43\t|2043.41\t|2050.38\t|2070.27\t|2076.79\t|2046.45\t|2079.27\t|2100.28\t|2068.84\t|2099.18\t|2030.76\n",
      "| Layer 9: 2069.3\t|2026.6\t|2071.82\t|1995.67\t|2042.67\t|2091.5\t|2043.13\t|1965.57\t|2023.62\t|2058.84\t|2059.35\t|2104.24\t|2033.03\t|2048.31\t|2073.89\t|2077.18\t|2097.96\t|2050.89\n",
      "| Layer 10: 2068.61\t|2005.94\t|2028.84\t|1979.92\t|2022.77\t|2050.61\t|2069.15\t|1958.51\t|1970.87\t|2039.32\t|2035.12\t|2029.84\t|2040.65\t|2060.51\t|2115.61\t|2000.34\t|2057.53\t|2037.27\n",
      "| Layer 11: 2061.62\t|2016.09\t|2034.24\t|2022.6\t|1963.8\t|2039.04\t|1971.95\t|1932.52\t|2027.16\t|2026.06\t|2023.45\t|2015.32\t|1997.82\t|1998.48\t|2060.13\t|1986.41\t|1985.59\t|1990.53\n",
      "| Layer 12: 1961.99\t|1978.77\t|1958.46\t|1953.62\t|1945.47\t|1965.87\t|1927.14\t|1888.07\t|1912.89\t|1986.73\t|2051.8\t|1966.24\t|1965.77\t|1975.72\t|1978.01\t|1963.61\t|1958.55\t|1932.17\n",
      "| Layer 13: 1944.88\t|1896.15\t|1899.21\t|1851.7\t|1876.52\t|1972.64\t|1868.32\t|1834.11\t|1880.43\t|1917.14\t|1945.05\t|1941.97\t|1908.56\t|1931.03\t|1917.56\t|1912.46\t|1984.5\t|1877.09\n",
      "| Layer 14: 1932.84\t|1889.97\t|1920.24\t|1847.47\t|1891.69\t|1909.74\t|1873.52\t|1841.22\t|1857.05\t|1924.45\t|1942.11\t|1930.5\t|1905.07\t|1936.22\t|1905.62\t|1903.32\t|1938.95\t|1886.22\n",
      "| Layer 15: 1928.0\t|1918.05\t|1905.82\t|1888.8\t|1923.59\t|1928.69\t|1926.29\t|1824.52\t|1845.65\t|1937.84\t|1937.67\t|1946.17\t|1874.48\t|1945.03\t|1954.59\t|1898.52\t|1937.61\t|1906.0\n",
      "| Layer 16: 1944.39\t|1892.15\t|1895.97\t|1919.38\t|1944.83\t|1962.4\t|1850.8\t|1836.79\t|1899.32\t|1923.72\t|1958.05\t|1931.39\t|1899.13\t|1959.0\t|1935.23\t|1910.87\t|1951.72\t|1939.54\n",
      "| Layer 17: 1896.38\t|1917.19\t|1894.87\t|1885.21\t|1892.54\t|1942.52\t|1925.44\t|1834.99\t|1865.64\t|1921.57\t|1921.57\t|1945.73\t|1926.76\t|1934.28\t|1919.02\t|1930.15\t|1920.77\t|1970.25\n",
      "| Layer 18: 1928.63\t|1921.91\t|1956.74\t|1912.59\t|1977.27\t|1959.59\t|1873.4\t|1836.99\t|1879.48\t|1932.9\t|1924.38\t|1911.25\t|1911.63\t|1934.91\t|1928.86\t|1904.56\t|1967.54\t|1961.76\n",
      "| Layer 19: 1911.67\t|1939.61\t|1927.35\t|1839.37\t|1892.76\t|1925.3\t|1935.06\t|1831.79\t|1864.32\t|1897.95\t|1914.8\t|1917.61\t|1893.07\t|1901.03\t|1914.72\t|1913.69\t|1990.03\t|1962.84\n",
      "| Layer 20: 1923.49\t|1899.76\t|1924.55\t|1843.59\t|1925.89\t|1894.71\t|1941.81\t|1833.4\t|1856.12\t|1936.78\t|1935.83\t|1905.16\t|1943.84\t|1948.36\t|1940.51\t|1920.53\t|1920.1\t|1950.9\n",
      "| Layer 21: 1916.54\t|1921.68\t|1926.84\t|1888.14\t|1878.56\t|1945.69\t|1861.11\t|1818.83\t|1861.98\t|1933.15\t|1901.79\t|1913.81\t|1909.65\t|1905.8\t|1921.88\t|1947.53\t|1943.94\t|1950.62\n",
      "| Layer 22: 1929.95\t|1923.59\t|1918.4\t|1876.29\t|1883.25\t|1900.94\t|1890.61\t|1841.54\t|1860.72\t|1947.34\t|1918.46\t|1882.13\t|1910.61\t|1937.77\t|1940.56\t|1941.58\t|1967.99\t|1967.42\n",
      "| Layer 23: 1910.22\t|1926.99\t|1927.54\t|1857.17\t|1893.85\t|1947.21\t|1895.06\t|1835.02\t|1866.09\t|1927.21\t|1906.26\t|1922.88\t|1906.63\t|1923.68\t|1913.25\t|1927.45\t|1970.9\t|1920.37\n",
      "| Layer 24: 1889.39\t|1911.86\t|1923.16\t|1840.05\t|1979.45\t|1914.23\t|1878.21\t|1838.91\t|1887.81\t|1919.17\t|1920.02\t|1902.46\t|1925.79\t|1929.63\t|1907.27\t|1935.4\t|1920.05\t|1932.75\n",
      "| Layer 25: 1917.41\t|1909.42\t|1906.12\t|1896.54\t|1917.59\t|1939.67\t|1998.42\t|1842.06\t|1875.02\t|1916.14\t|1912.79\t|1926.1\t|1926.26\t|1928.99\t|1951.75\t|1965.76\t|1912.19\t|1916.56\n",
      "| Layer 26: 1900.52\t|1914.96\t|1922.97\t|1864.03\t|1945.33\t|1888.78\t|1850.97\t|1839.98\t|1850.22\t|1938.76\t|1881.9\t|1870.03\t|1901.78\t|1954.14\t|1915.75\t|1925.29\t|1936.0\t|1960.56\n",
      "| Layer 27: 1932.31\t|1934.31\t|1900.0\t|1849.95\t|1914.37\t|1965.25\t|1878.69\t|1882.46\t|1885.36\t|1975.88\t|1908.5\t|1875.79\t|1917.39\t|1917.44\t|2011.87\t|1926.86\t|1952.01\t|1919.3\n",
      "| Layer 28: 2130.06\t|2037.92\t|2043.76\t|1958.78\t|2056.9\t|2060.04\t|2003.52\t|1986.83\t|1990.8\t|2055.21\t|2044.55\t|2025.18\t|2040.21\t|2084.51\t|2058.38\t|2064.92\t|2087.66\t|2063.01\n",
      "| Layer 29: 2029.19\t|2048.46\t|2024.26\t|1957.63\t|2034.87\t|2034.05\t|2039.88\t|1991.85\t|1986.08\t|2049.27\t|2041.78\t|2042.6\t|2046.01\t|2124.47\t|2076.41\t|2065.77\t|2092.28\t|2048.24\n",
      "| Layer 30: 2161.87\t|2040.72\t|2043.82\t|2000.34\t|2022.88\t|2093.94\t|2026.94\t|1973.26\t|2032.38\t|2073.9\t|2028.18\t|2001.83\t|2047.67\t|2068.57\t|2065.19\t|2060.92\t|2076.14\t|2084.52\n",
      "| Layer 31: 2126.92\t|2049.93\t|2058.44\t|1999.1\t|2036.88\t|2063.01\t|2016.81\t|2001.62\t|2019.7\t|2088.07\t|2057.05\t|2046.25\t|2050.59\t|2088.81\t|2104.78\t|2058.0\t|2088.32\t|2049.28\n"
     ]
    }
   ],
   "source": [
    "pruned.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03dbc38e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:32:27.361758Z",
     "start_time": "2024-05-25T10:32:27.357417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: Small: 2369.61 | Medium: 2167.33 | Long: 2228.18\n",
      "Layer 1: Small: 2067.77 | Medium: 2070.41 | Long: 2088.98\n",
      "Layer 2: Small: 2027.76 | Medium: 2039.77 | Long: 2058.8\n",
      "Layer 3: Small: 2038.89 | Medium: 2020.82 | Long: 2051.97\n",
      "Layer 4: Small: 2042.31 | Medium: 2025.85 | Long: 2055.03\n",
      "Layer 5: Small: 2030.19 | Medium: 2025.69 | Long: 2049.09\n",
      "Layer 6: Small: 2086.0 | Medium: 2055.35 | Long: 2089.87\n",
      "Layer 7: Small: 2065.69 | Medium: 2052.59 | Long: 2090.76\n",
      "Layer 8: Small: 2081.64 | Medium: 2044.45 | Long: 2070.8\n",
      "Layer 9: Small: 2049.59 | Medium: 2042.46 | Long: 2063.54\n",
      "Layer 10: Small: 2026.12 | Medium: 2017.14 | Long: 2051.99\n",
      "Layer 11: Small: 2022.9 | Medium: 1999.41 | Long: 2003.16\n",
      "Layer 12: Small: 1960.7 | Medium: 1955.48 | Long: 1962.3\n",
      "Layer 13: Small: 1906.85 | Medium: 1897.84 | Long: 1921.87\n",
      "Layer 14: Small: 1898.66 | Medium: 1894.81 | Long: 1912.57\n",
      "Layer 15: Small: 1915.49 | Medium: 1903.02 | Long: 1919.37\n",
      "Layer 16: Small: 1926.52 | Medium: 1900.01 | Long: 1932.58\n",
      "Layer 17: Small: 1904.79 | Medium: 1902.49 | Long: 1933.54\n",
      "Layer 18: Small: 1942.79 | Medium: 1893.07 | Long: 1934.88\n",
      "Layer 19: Small: 1906.01 | Medium: 1893.59 | Long: 1929.23\n",
      "Layer 20: Small: 1902.0 | Medium: 1901.52 | Long: 1937.37\n",
      "Layer 21: Small: 1912.91 | Medium: 1881.78 | Long: 1929.9\n",
      "Layer 22: Small: 1905.41 | Medium: 1890.13 | Long: 1944.32\n",
      "Layer 23: Small: 1910.5 | Medium: 1892.08 | Long: 1927.05\n",
      "Layer 24: Small: 1909.69 | Medium: 1891.1 | Long: 1925.15\n",
      "Layer 25: Small: 1914.46 | Medium: 1911.75 | Long: 1933.58\n",
      "Layer 26: Small: 1906.1 | Medium: 1871.98 | Long: 1932.25\n",
      "Layer 27: Small: 1916.03 | Medium: 1901.11 | Long: 1940.81\n",
      "Layer 28: Small: 2047.91 | Medium: 2017.68 | Long: 2066.45\n",
      "Layer 29: Small: 2021.41 | Medium: 2025.24 | Long: 2075.53\n",
      "Layer 30: Small: 2060.6 | Medium: 2022.75 | Long: 2067.17\n",
      "Layer 31: Small: 2055.71 | Medium: 2038.25 | Long: 2073.3\n"
     ]
    }
   ],
   "source": [
    "for layer, times in pruned.layers.items():\n",
    "    print(f\"Layer {layer}: Small: {round(sum(times[:6])/6,2)} | Medium: {round(sum(times[6:12])/6, 2)} | Long: {round(sum(times[12:])/6, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166fbfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer 0: Small: 2287.25 | Medium: 2317.89 | Long: 2306.72\n",
    "Layer 1: Small: 2246.5 | Medium: 2294.41 | Long: 2301.33\n",
    "Layer 2: Small: 2215.89 | Medium: 2251.31 | Long: 2259.4\n",
    "Layer 3: Small: 2228.93 | Medium: 2279.41 | Long: 2272.39\n",
    "Layer 4: Small: 2211.33 | Medium: 2277.41 | Long: 2265.39\n",
    "Layer 5: Small: 2224.4 | Medium: 2261.79 | Long: 2305.28\n",
    "Layer 6: Small: 2236.88 | Medium: 2275.88 | Long: 2259.53\n",
    "Layer 7: Small: 2206.14 | Medium: 2268.08 | Long: 2260.33\n",
    "Layer 8: Small: 2240.86 | Medium: 2285.38 | Long: 2310.05\n",
    "Layer 9: Small: 2224.6 | Medium: 2299.58 | Long: 2284.91\n",
    "Layer 10: Small: 2253.69 | Medium: 2307.85 | Long: 2288.95\n",
    "Layer 11: Small: 2243.5 | Medium: 2290.29 | Long: 2266.66\n",
    "Layer 12: Small: 2230.56 | Medium: 2287.36 | Long: 2279.11\n",
    "Layer 13: Small: 2242.53 | Medium: 2288.54 | Long: 2303.61\n",
    "Layer 14: Small: 2264.98 | Medium: 2293.0 | Long: 2297.76\n",
    "Layer 15: Small: 2250.97 | Medium: 2327.58 | Long: 2317.49\n",
    "Layer 16: Small: 2220.37 | Medium: 2274.49 | Long: 2273.75\n",
    "Layer 17: Small: 2234.99 | Medium: 2267.56 | Long: 2251.59\n",
    "Layer 18: Small: 2231.13 | Medium: 2319.98 | Long: 2312.51\n",
    "Layer 19: Small: 2244.72 | Medium: 2277.47 | Long: 2283.57\n",
    "Layer 20: Small: 2229.86 | Medium: 2287.91 | Long: 2300.43\n",
    "Layer 21: Small: 2232.57 | Medium: 2298.45 | Long: 2281.74\n",
    "Layer 22: Small: 2243.32 | Medium: 2285.49 | Long: 2281.07\n",
    "Layer 23: Small: 2244.06 | Medium: 2295.8 | Long: 2288.27\n",
    "Layer 24: Small: 2274.24 | Medium: 2291.84 | Long: 2302.17\n",
    "Layer 25: Small: 2232.55 | Medium: 2270.77 | Long: 2267.05\n",
    "Layer 26: Small: 2259.69 | Medium: 2292.44 | Long: 2305.61\n",
    "Layer 27: Small: 2227.29 | Medium: 2288.44 | Long: 2290.49\n",
    "Layer 28: Small: 2244.31 | Medium: 2274.87 | Long: 2301.62\n",
    "Layer 29: Small: 2241.21 | Medium: 2295.94 | Long: 2269.38\n",
    "Layer 30: Small: 2230.05 | Medium: 2293.11 | Long: 2267.94\n",
    "Layer 31: Small: 2263.16 | Medium: 2304.7 | Long: 2290.21\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a012ad06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:34:17.432166Z",
     "start_time": "2024-05-25T10:34:17.427930Z"
    }
   },
   "outputs": [],
   "source": [
    "l = [22, 7706, 22, 7706, 22, 7706, 23, 7706, 22, 7706, 22, 8285, 22, 10587, 22, 7706, 22, 7706, 22, 8099, 22, 7706, 31, 7706, 22, 8457, 26, 7706, 22, 7706, 22, 8149, 22, 7706, 28, 7706, 25, 8355, 22, 7706, 22, 7706, 22, 9217, 29, 7706, 22, 9856]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c15b1904",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:35:38.576915Z",
     "start_time": "2024-05-25T10:35:38.573001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 4: Head: 22, Intermediate: 7706\n",
      "Layer 5: Head: 22, Intermediate: 7706\n",
      "Layer 6: Head: 22, Intermediate: 7706\n",
      "Layer 7: Head: 23, Intermediate: 7706\n",
      "Layer 8: Head: 22, Intermediate: 7706\n",
      "Layer 9: Head: 22, Intermediate: 8285\n",
      "Layer 10: Head: 22, Intermediate: 10587\n",
      "Layer 11: Head: 22, Intermediate: 7706\n",
      "Layer 12: Head: 22, Intermediate: 7706\n",
      "Layer 13: Head: 22, Intermediate: 8099\n",
      "Layer 14: Head: 22, Intermediate: 7706\n",
      "Layer 15: Head: 31, Intermediate: 7706\n",
      "Layer 16: Head: 22, Intermediate: 8457\n",
      "Layer 17: Head: 26, Intermediate: 7706\n",
      "Layer 18: Head: 22, Intermediate: 7706\n",
      "Layer 19: Head: 22, Intermediate: 8149\n",
      "Layer 20: Head: 22, Intermediate: 7706\n",
      "Layer 21: Head: 28, Intermediate: 7706\n",
      "Layer 22: Head: 25, Intermediate: 8355\n",
      "Layer 23: Head: 22, Intermediate: 7706\n",
      "Layer 24: Head: 22, Intermediate: 7706\n",
      "Layer 25: Head: 22, Intermediate: 9217\n",
      "Layer 26: Head: 29, Intermediate: 7706\n",
      "Layer 27: Head: 22, Intermediate: 9856\n"
     ]
    }
   ],
   "source": [
    "ll = 4\n",
    "for i in range(0, len(l), 2):\n",
    "    print(f\"Layer {ll}: Head: {l[i]}, Intermediate: {l[i+1]}\")\n",
    "    ll += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab65439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "huggingface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "1499.4px",
    "width": "361px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "741.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
